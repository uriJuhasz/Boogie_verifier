\showboxdepth=\maxdimen
\showboxbreadth=\maxdimen

\chapter{Ground First Order Logic with Equality}
	\tikzset{every picture/.style = semithick,node distance=1.5cm}
	\tikzstyle{hist}     = [gray,text=gray,densely dotted]
	\tikzstyle{rejected} = [gray,text=gray]
	\tikzstyle{missing}  = [red,text=red]
	\tikzstyle{potential}= [gray,text=gray,dashed]

  \tikzstyle{every node}=[text=black,font=\tiny]
  \tikzstyle{gtn}  =[draw,ellipse,  text=black,font=\scriptsize,align=center,inner sep=1pt]
  \tikzstyle{rgtn} =[gtn,rejected]
  \tikzstyle{mgtn} =[gtn,missing]
  \tikzstyle{hgtn} =[gtn,hist]
  \tikzstyle{pgtn} =[gtn,potential]
  
	\tikzstyle{gttn} =[draw,rectangle,text=black,font=\scriptsize,align=center,inner sep=1pt]
  \tikzstyle{rgttn}=[gttn,rejected]
	\tikzstyle{mgttn}=[gttn,missing]
	\tikzstyle{hgttn}=[gttn,hist]
	\tikzstyle{pgttn}=[gttn,potential]
  
	\tikzstyle{el}   =[font=\tiny,pos=0.5,anchor=east] %,anchor=south east]
  \tikzstyle{rl}   =[el,rejected]
  \tikzstyle{ml}   =[el,missing]
  \tikzstyle{hl}   =[el,hist]
  \tikzstyle{pl}   =[el,potential]
  
	\tikzstyle{gl}   =[text=black,font=\small]

	\tikzstyle{gfa}   =[->,>=stealth] %,out=-90,in=90]
	\tikzstyle{rgfa}  =[gfa,rejected]
	\tikzstyle{mgfa}  =[gfa,missing]
	\tikzstyle{hgfa}  =[gfa,hist]
	\tikzstyle{pgfa}  =[gfa,potential]
  
	\tikzstyle{sgtt} =[->,>=stealth,double] %,out=-90,in=90]
  \tikzstyle{rgtt} =[sgtt,rejected]
  \tikzstyle{msgtt}=[sgtt,missing]
  \tikzstyle{hsgtt}=[sgtt,hist]
  \tikzstyle{psgtt}=[sgtt,potential]
  
	\tikzstyle{ie}   =[<->,dashed,font=\tiny]

  \tikzstyle{ee}   =[->,dashed,dash pattern = on 2pt off 1pt,out=180,in=0]
  \tikzstyle{se}   =[ee,color=blue]
  \tikzstyle{hse}  =[ee,hist]
  \tikzstyle{re}   =[ee,rejected]
  \tikzstyle{me}   =[ee,missing]
  \tikzstyle{pe}   =[ee,potential]

	\tikzstyle{he}   =[->,hist]

	\tikzstyle{separator} = [dashed,color=gray,very thin,dash pattern=on \pgflinewidth off \pgflinewidth]
	\lstset{tabsize=3}
In this section we will discuss the fragment of ground first order logic with equality - GFOLE,
also called the ground theory of equality over uninterpreted functions and the theory of Herbrand equalities.
This fragment is important as it forms the basis for most other interesting fragments in FOL,
and with the addition of even simple theory reasoning (such as arrays or linear arithmetic)
can be used to prove many interesting properties about programs.

We will start by defining the fragments of unit and non-unit ground equalities
and then present several examples for programs and properties that can or cannot be handled by these fragments.

We will then discuss some complexity issues for these fragments and then present our algorithm for deciding it.

We will begin with only functions symbols and the equality predicate, and later add also predicate symbols.
We will use unsorted logic, and later show some optimizations possible with multi sorted logic.

\section{Preliminaries}

\subsection{Sets}
A multiset \m{m} over a set \m{S} is a function \m{m : S \rightarrow \mathbb{N}_0}.
We use 0 for the empty multiset.
Singleton multisets are defined as:\\
 \m{[x \mapsto n](y) \triangleq \ite{x\equiv y}{n}{0}}.\\
Multiset union is defined as:\\
 \m{(m \cup n)(x) \triangleq m(x)+n(x)}.
Sub multiset relation is defined as follows:\\
 \m{m \subseteq n \equivdef \forall i \in \mathbb{N}_0 \cdot m(i) \leq n(i)}
 \m{m \subseteq n \equivdef \forall i \in \mathbb{N}_0 \cdot m(i) \leq n(i)}

An equivalence relation \m{\approx} over a set \m{S} is a subset of \m{S^2} s.t.\\
\m{\forall ~(x,y)\in\approx \cdot (y,x) \in \approx}\\
\m{\forall (x,y),(y,z) \in \approx \cdot (x,z) \in \approx}\\
\m{\forall x \in S \cdot (x,x) \in \approx}\\
For an equivalence relation \m{\approx} over \m{S}, and a term \m{x \in S} we denote by 
\m{\ECOf{x}{\approx}} the equivalence class of \m{x} in \m{S} with respect to \m{\approx}:\\
\m{\ECOf{x}{\approx} \triangleq \s{y \in S \mid x \approx y}}

A \emph{partition} of a set \m{S},\m{P \subseteq P(S)} satisfies:\\
\m{\forall S_1,S_2 \in P \cdot S_1 \cap S_2 = \emptyset}\\
\m{\cup P = S}

The \emph{quotient set} of a set \m{S} for the equivalence relation \m{\approx}, \m{S/\approx} is the set:\\
\s{ \ECOf{x}{\approx} \mid x \in S}\\
And is a partition of \m{S}, and similarly a partition defines an equivalence relation.



\subsection{Logic}

\subsubsection{Syntax and notation}

The language is defined formally as follows:\\
A function or predicate symbol (denoted \func{f},\func{g},\func{h}) has a fixed arity ($\arity{f}\geq 0$).\\
A signature \m{\Sigma=\Fs{\Sigma} \cup \Ps{\Sigma} \cup \Vs{\Sigma}}
is a set of function symbols \Fs{\sig}, predicate symbols \Ps{\sig} and variables \Vs{\sig}
(We will mention non-ground defintions here to be consistent with later chapters, but assume for this chapter that \m{\Ps{\sig}=\Vs{\sig}==\emptyset}).\\
The set of constants is \m{\consts{}=\s{\func{f} \in \funcs{} \mid \arity{f}=0 }}, we assume $\|\consts{}\|>0$ (otherwise the ground fragment is trivial).\\
We will denote a (possible empty) tuple by an overline - detailed in the following.\\
We use a standard definition for the language:\\
$
\begin{array}{llllll}
	\mathbf{function}  & \mbox{f,g,h}   &     &                                & \in \Fs{\sig} & \textrm{functions}\\
	\mathbf{predicate} & \mbox{P,Q,R}   &     &                                & \in \Ps{\sig} & \textrm{predicates}\\
	\mathbf{variable}  & \mbox{x,y,z}   &     &                                & \in \Vs{\sig} & \textrm{variables}\\
	\mathbf{term}      & \mbox{t,s,u,v} & ::= & \m{\fa{f}{t} \mid x}           & \in \Ts{\sig} & \textrm{free term algebra over } \Sigma\\
	\mathbf{atom}      & \mbox{a}       & ::= & \m{t = t \mid \fa{P}{t}}       & \in \As{\sig} & \textrm{the atoms over } \Sigma\\
	\mathbf{literal}   & \mbox{A,B}     & ::= & \mbox{a} \mid \lnot \mbox{a}   & \in \Ls{\sig} & \textrm{the literals over } \Sigma\\
	\mathbf{clause}    & \mbox{C,D}     & ::= & \m{\emptyClause \mid C \lor A} & \in \Cs{\sig} & \textrm{the clauses over } \Sigma\\
\end{array}
$

We use \term{s,t,u,v} for terms, \term{\tup{s},\tup{t},\tup{u},\tup{v}} for term tuples,
we also construct tuples from terms using parenthesis - e.g. \term{(t,s)}.\\
We occasionally treat an n-tuple as a sequence of n ground terms.\\
\tupAt{t}{i} is the i-th element of the tuple \tup{t} and \tupL{t} for the number of terms (size or length) in a tuple. \\
We treat an equality atom as an unordered set and so $\term{(s=t)} \equiv \term{(t=s)}$.\\
We use $\term{s \neq t}$ to denote \term{\lnot s = t}.\\
As we do not manipulate negations in syntactically, we consider \m{\lnot \lnot a \equiv a}.\\
We treat clauses as sets of literals whose semantics is the disjunction of these literals.\\
We denote the empty clause by \emptyClause.\\
We use \term{\bowtie} to denote either \term{=} or \term{\neq}.

We define the set of terms of a set of clauses:\\
$
\begin{array}{llll}
\terms{S}           & \triangleq & \bigcup\limits_{\m{C} \in \m{S}} \terms{C} \\ 
\terms{C}           & \triangleq & \bigcup\limits_{\m{l} \in \m{C}} \terms{l} \\ 
\terms{s \bowtie t} & \triangleq & \terms{s} \cup \terms{t} \\ 
\terms{\fa{P}{s}}   & \triangleq & \terms{\tup{s}} \\ 
\terms{\tup{s}}     & \triangleq & \m{\bigcup\limits_{i} \tupAt{s}{i}} \\ 
\terms{\fa{f}{s}}   & \triangleq & \s{\fa{f}{s}} \cup \terms{\tup{s}} \\
\end{array}
$

For a set $\mathrm{S}$ we denote by $\mathrm{F_n(S)} = \mathrm{S^n} \rightarrow \mathrm{S}$ the set of all functions of arity $\mathrm{n}$ over $\mathrm{S}$ and $\mathrm{F(S)} = \bigcup\limits_{n \in \mathbb{Z}+} \mathrm{F_n(S)}$ the set of all functions over $\mathrm{S}$.

For the semantics we use functions from terms to the domain \term{S}, $\function{f} : \Ts{\sig} \rightarrow \term{S}$.
When applying such a function to a tuple \tup{t} we mean the pointwise application of the function that returns a tuple in
$\term{S}^{\tupL{t}}$ - so $\term{f}(\tup{t})_{\m{i}} = \term{f}(\tupAt{t}{i})$.

An interpretation \m{\mathbf{I}=(D_I,F_I,P_I)} over a signature $\mathbf{\Sigma}$
has a domain $\mathrm{D_I}$ which is a non empty set,\\
a mapping from each function of \sig{} to a function of the corresponding arity over $\mathrm{D_I}$ -
namely $\mathbf{F_I} \in \mathbf{F_{\sig{}}} \rightarrow \mathrm{F(D_I)}$ such that
$\forall \m{f} \in \mathbf{\sig} \cdot \m{F_I}(\m{f}) \in \m{F_{\arity{f}}(S)}$, \\
and an interpretation for predicate symbols\\
 \m{P_I : \Ps{\Sigma} \in \s{\fa{P}{e} \mid P \in \Ps{\Sigma} \land \tup{e} \in D_I^{\arity{P}}}}.

\subsubsection{Semantics}
For a ground term \term{t} and interpretation $\mathbf{I}$ we denote by $\den{t}{I} \in \mathrm{D_I}$ the interpretation of \term{t} in $\mathbf{I}$ in the standard way, as defined below:\\
$
\begin{array}{lll}

	\den{\fa{f}{t}} {I} & \triangleq & \den{\term{f}}{I}(\den{\tup{t}}{I}) \\
	\den{t=s}       {I} & \triangleq & \den{t}{I}=\den{s}{I}  \\
	\den{\fa{P}{t}} {I} & \triangleq & \m{P(\den{\tup{t}}{I}) \in \m{A_I}} \\
	\den{\lnot a}   {I} & \triangleq & \lnot \den{a}{I} \\
	\den{C}         {I} & \triangleq & \m{\forall A \in C \cdot \den{A}{I}} \\
\end{array}
$

Where we extend  $\den{\cdot}{I}$ pointwise to tuples, and use $\den{f}{I}$ for $\mathrm{F_I}(f)$.
Satisfiability in this language is decidable and NP-complete ~\cite{} :\\
We can reduce (in linear time and space) a propositional problem to our fragment by replacing each propositional atom \term{A} with the GFOLE atom \term{f_A()=T} where \term{f_A} is a constant function and \term{T} is a specially designated (fresh) true symbol.
In the other direction we have a polynomial reduction using the Ackermann transfromation - basically encode every term $\fa{f}{t}$ by a fresh variable  $\m{v_\fa{f}{t}}$, for any pair of terms \fa{f}{t_i}, \fa{f}{s_i} with the same function symbol we add the the clause \\
$ \bigvee\limits_{\m{i}} \m{\m{v}_{t_i} \neq \m{v}_{s_i}} \lor \m{v}_{\fa{f}{t_i}=\fa{f}{s_i}}$. We are left with a set of CNF clauses over the fresh variables, with no non-constant functions symbols, of at most square size.
We replace each atom $\m{v=u}$ by a propositional atom \term{A_{v=u}}, and for each triple of constants \m{a,b,c} we add the clause 
\m{\lnot A_{a=b} \lor \lnot A_{b=c} \lor A_{a=c}} to encode transitivity - we end up with an equisatisfiable propositional set of clauses.
There are more efficient transformations that achieve the same, however we are interested mostly in the fact that the reduction is polynomial, as the best known algorithm for propositional CNF is exponential.


\textbf{Substitutions}
We denote by \emptySeq the empty (integer) sequence and by \lstinline{i++s} the sequence constructed by prepending the integer \term{i} before the sequence \lstinline{s}.

We denote a subterm of the term \term{u} at position \term{p} by
\term{u\mid_p}.
A position is a sequence of integers, and \term{u\mid_p} is defined recursively (partially) as follows :\\
$
\begin{array}{lll}
	\termAt{u}{\emptySeq}    & \triangleq & \term{u} \\
	\termAt{f(\tup{r})}{i.s} & \triangleq & \termAt{\tupAt{r}{i}}{s}
\end{array}
$

For example, for  $\term{t=f(g(a),h(b,g(a)))}$, \\
$\termAt{f(g(a),h(b,g(a)))}{\emptySeq}=\term{f(g(a),h(b,g(a)))}$, \\
$\termAt{f(g(a),h(b,g(a)))}{0}        =\termAt{f(g(a),h(b,g(a)))}{1.1}=\term{g(a)}$, \\
$\termAt{f(g(a),h(b,g(a)))}{0.0}      =\termAt{f(g(a),h(b,g(a)))}{1.1.1}=\term{a}$ \\
etc.

For a term \m{t} The set \m{\poss{t}} is the set of all positions of \m{t} defined as follows:\\
$
\begin{array}{lll}
	\poss{\fa{f}{s}} & \triangleq & \s{\emptySeq} \cup \s{i.p \mid p \in \poss{s_i}} \\
\end{array}
$
We also use all positions of a term \m{s} in a term \m{t}:\\
$
\begin{array}{lll}
	\posss{\fa{f}{s}}{t} & \triangleq & \s{\emptySeq \mid \fa{f}{s}\equiv t} \cup \s{i.p \mid p \in \posss{s_i}{t}} \\
\end{array}
$
We say that two positions \m{p,q} are \emph{disjoint} iff:\\
\m{\disj{p}{q} \equivdef p=i.p' \land q=j.q' \land i\neq j \lor \disj{p'}{q'}}\\
The sets \poss{t} and \posss{t}{s} are pairwise disjoint.\\
By \termRepAt{u}{t}{p} we denote \emph{replacing} \termAt{u}{p} by \term{t} at the position \term{p} in term \term{u} - formally:\\
$
\begin{array}{lll}
	\termRepAt{s        }{t}{\emptySeq} & \triangleq & \term{t} \\
	\termRepAt{\fa{f}{s}}{t}{i.p      } & \triangleq & \term{f}\left(\tupRepAt{s}{i}{\termRepAt{(\tupAt{s}{i})}{t}{p}}\right) \\
\end{array}
$
We extend this notion to simultaneous replacement on a pairwise disjoint set of positions \m{P}:\\
$
\begin{array}{lll}
	\termRepAt{s        }{t}{\emptyset}     & \triangleq & \term{s} \\
	\termRepAt{s        }{t}{\s{\emptySeq}} & \triangleq & \term{t} \\
	\termRepAt{\fa{f}{s}}{t}{P            } & \triangleq & \m{f(i \mapsto \termRepAt{s_i}{t}{\s{p \mid i.p \in P}})} \\
\end{array}
$

A term \m{s} is a \emph{proper sub-term} of a term \m{t} if:\\
\m{s \rhd t \equivdef \exists p \neq \emptySeq \cdot t = \termAt{s}{p} }
And a non-proper subterm if:\\
\m{s \unrhd t \equivdef s=t \lor s \rhd t }\\
We extend the sub-term relation to tuples, literals, clauses and sets of clauses:\\
$
\begin{array}{lll}
\m{s \rhd \tup{t}}    & \equivdef & \m{\exists i \mid t \rhd t_i}\\
\m{s \rhd u \bowtie v} & \equivdef & \m{s \rhd (u,v)}\\
\m{s \rhd \fa{P}{t}}   & \equivdef & \m{s \rhd \tup{t}}\\
\m{s \rhd C}           & \equivdef & \m{\exists l \in C \cdot s \rhd l}\\
\end{array}{lll}
$


A \emph{substitution} on a signature \m{\Sigma(X,F)} is a total function \m{\sigma : \m{X} \rightarrow \mathbf{Ts}(X,F)}.\\
The substitution \m{[x \mapsto t]} is defined as \\
\m{[x \mapsto t](y) \triangleq \ite{x\equiv y}{t}{y}}
A composition of substitutions \m{\sigma_1\sigma_2} is functional composition defined as:\\
\m{(\sigma_1\sigma_2)(x) \triangleq \sigma_1(\sigma_2(x))}

\textbf{Orders}
For a set \m{S}, a \emph{strict partial order} \m{\succ \in S^2} on \m{S} is a binary relation on \m{S} satisfying:
\begin{itemize}
	\item Irreflexive: \m{\forall x \in S \cdot x \not\succ x}
	\item Transitivity: \m{\forall x,y,z \in S \cdot x \succ y \land y \succ z \rightarrow x \succ z}
	\item Assymetric: \m{\forall x,y \in S \cdot x\succ y \rightarrow y \not\succ x }
\end{itemize}
For any strict partial order \m{\succ}, the corresponding \emph{non-strict partial order} \m{\succeq} is defined as:\\
\m{\forall x,y \in S \cdot x\succeq y \Leftrightarrow (x=y \lor x \succ y)}
A \emph{total strict order} is a strict partial order where \\
\m{\forall x,y \in S  \cdot x=y \lor x \succ y \lor y \succ x} \\
and correspondingly a \emph{total non-strict order} satisfies:\\
\m{\forall x,y \in S  \cdot x \succeq y \lor y \succeq x}
A \emph{well founded} strict partial order \m{\succ} on \m{S} has no infinite descending chains - formally:\\
\m{\lnot \exists f : \mathbb{N} \Rightarrow S \cdot \forall i \in \mathbb{N} f(i) \succ f(i+1)} \\
An equivalent definition is that each subset has a minimum:\\
\m{\forall S' \subseteq S \cdot S' \neq \emptyset \Rightarrow \exists t \in S' \cdot \forall s \in S' s \succeq t}
A simplification ordering \m{\succ} on a term algebra \Ts{\sig} is a strict partial order on \Ts{\sig} that satisfies:
\begin{itemize}
	\item Compatible with contexts (monotonic):\\
	\m{\forall s,t,c \in \Ts{\sig},p \cdot s \succ t \Rightarrow \termRepAt{c}{s}{p} \succ \termRepAt{c}{t}{p}}
	\item Stable under substitution: \m{\forall s,t \in \Ts{\sig},\sig \cdot s \succ t \Rightarrow s\sigma \succ t\sigma}
	\item Subterm compatible: \m{\rhd \subseteq \succ}
\end{itemize}
A \emph{reduction ordering} is a well founded simplification ordering.
We denote the lexicographic extension of an ordering on a \m{S} to an ordering on \m{S^n} for \m{n>1}:\\
\m{\tup{s} \succ \tup{t} \equivdef \exists i \geq 0 \cdot s_i \succ t_i \land (\forall j<i \cdot s_j=t_j)}
For an ordering \m{\succ} on \m{S}, we use the multiset extension of \m{\succ}:\\
For a pair of finite multisets on \m{S} \m{m,n}:\\
\m{m \succ n \equivdef \forall x \in S \cdot m(x) > n(x) \lor \exists y \succ x \cdot m(y) \succ n(y) }.\\
For a multiset \m{m} and an element \m{x \in S} we use:\\
\m{x \succ m \equivdef \forall y \in S \mid m(y)=0 \lor x \succ y}


We will use a form of \emph{transfinite Knuth Bendix order} ~\cite{WinklerZanklMiddeldorp12},~\cite{KovacsMoserVoronkov11}.\\
We use \ords for the set of ordinal numbers and $\bigoplus,\bigotimes$ for natural addition and multiplication on ordinals, respectively.

The transfinite Knuth Bendix term ordering \m{\succ_{tkbo}} has two parameters:\\
A strict partial(potentially total) order \m{\succ} on the signature \m{F_\Sigma} (sometimes called a \emph{precedence}).\\
A \emph{weight function} \m{w:F_\Sigma \cup X_\Sigma \rightarrow \ords} that satisfies \m{\forall f \in F_\Sigma \cdot w(f) > 0} and  \m{\forall x \in X_\Sigma \cdot w(x) = 1}.\\
Unless otherwise noted we will use \m{w} s.t. \\
\m{\forall f \cdot \arity{f}>0  \Rightarrow \exists m \in \mathbb{N} \cdot w(f) = \omega\cdot m + 1}\\
\m{\forall f \cdot \arity{f}=0  \Rightarrow w(f) = 1}\\
that is, the function maps all non-constants to 1 and all constants only to direct successors of limit ordinals less than \m{\omega^\omega}. 
Note that it is not required that the precedence on function symbols agrees with the ordinal order on their weights.

The weight of a term is defined recursively as:\\
\m{w(\fa{f}{s}) \triangleq w(f) + \bigoplus\limits_i w(s_i)}


We define the multiset of variables of a term \m{t}, \m{\Vars{t}} recursively as follows:\\
$ 
\begin{array}{lll}
	\Vars{x}         & \triangleq & [x \mapsto 1]\\
	\Vars{\fa{f}{s}} & \triangleq & \bigcup\limits_\m{i} \Vars{s_i}\\
\end{array} 
$\\
\bigskip
The transfinite Knuth Bendix ordering (tkbo) for terms we use is defined as follows:\\
\m{s \succ t} iff \m{\Vars{s} \supseteq \Vars{t}} and
\begin{itemize}
	\item \m{w(s) > w(t)} or
	\item \m{w(s) = w(t), s\equiv\fa{f}{s}, t\equiv\fa{g}{t}} and
		\subitem \m{f \succ g} or
		\subitem \m{f \equiv g} and \m{\tup{s} \succ \tup{t}}
\end{itemize}

In order to extend it to literals and clauses, we extend the weight function to predicate symbols, and assume a we have a total order \m{succ} also on predicate symbols including the equality symbol.\\
This extension is total if $\succ$ is.\\
tkbo for literals is:\\
\m{l \succ l'} iff \m{\Vars{l} \supseteq \Vars{l'}} and
\begin{itemize}
	\item \m{w(l) > w(l')} or
	\item \m{w(l) = w(l'), l\equiv\fa{P}{s}, l'\equiv\fa{Q}{t}} and
		\subitem l is negative and \m{l\equiv \lnot l'} or
		\subitem \m{P \succ Q} or
		\subitem \m{P \equiv Q} and \m{\tup{s} \succ \tup{t}}
\end{itemize}
For clauses we treat each clause as a multiset of literals and then use the multiset extension of \m{succ}.\\
tkbo is total on ground terms.\\
tkbo also has the desirable property that it is \emph{separating} for constants - 
that is, given a constant indexing function \m{ci(c):\mathbf{const} \rightarrow \mathbb{N}} we can assign \\
\m{\forall c \in \mathbf{const} \cdot w(c) = \omega\cdot \mathbf{ci}(c)+1}\\
Where any two term \m{s,t}, if the maximal constant index of \m{s} is greater than that of \m{t} then \m{s \succ t} regardless of size.
This will be important for completeness under scoping (for the ground fragment) as in ~\cite{KovacsVoronkov09},~\cite{McMillan08}.

Our underlying logical calculus would be, instead of propositional ground resolution, ground resolution with superposition
, for a reduction ordering \m{\succ}:

$
\begin{array}[c]{llll}
\vspace{10pt}
\mbox{res} & \vcenter{\infer[]{\m{C \lor D}                               }{\m{C \lor s=t } & \m{s \neq t \lor D}}} & 
\parbox[c][2cm]{2cm}{\m{s=t \succ C}\\\m{s \neq t \succ D}}\\
\vspace{10pt}
\mathrm{res_{=}} &\vcenter{\infer[]{\m{C       }                               }{\m{C \lor s\neq s}                   }} & 
\\
\vspace{10pt}
\mathrm{sup_{=}} &\vcenter{\infer[]{\m{C \lor \termRepAt{s}{r}{p} =    t \lor D}}{\m{C \lor l=r} & \m{\termRepAt{s}{l}{p} =    t \lor D}}} & 
\parbox[c][2cm]{3cm}{\m{l \succ r,l=r \succ C}\\\m{s \succ t,s=t \succ D}\\\m{s=t \succ l=r}}\\
\vspace{10pt}
\mathrm{sup_{\neq}} &\vcenter{\infer[]{\m{C \lor \termRepAt{s}{r}{p} \neq t \lor D}}{\m{C \lor l=r} & \m{\termRepAt{s}{l}{p} \neq t \lor D}}} & 
\parbox[c][2cm]{3cm}{\m{l \succ r,l=r \succ C}\\\m{s \succ t,s \neq t \succ D}}\\
\vspace{10pt}
\mathrm{fact} & \vcenter{\infer[]{\m{C \lor s=t \lor t \neq r}                }{\m{C \lor s = t \lor s = r}}} & 
\parbox[c][2cm]{3cm}{\m{s \succ t,t \succ r}\\\m{s=t \succ C}}\\
\vspace{10pt}
\end{array}
$

This calculus was shown sound and complete in ~\cite{BachmairGanzinger94}.

We use the following simplifying deductions:\\
$
\begin{array}[c]{llll}
\vspace{10pt}
\m{unit} & \vcenter{\infer[]{\m{C}                            }{\m{\lnot A}  & \cancel{\m{C \lor A}}}} \\
\vspace{10pt}
\m{taut} & \vcenter{\infer[]{\m{}                             }{\cancel{\m{C \lor A \lor \lnot A}}}} \\
\vspace{10pt}
\m{taut2} & \vcenter{\infer[]{\m{}                             }{\cancel{\m{C \lor s=s}}}} \\
\vspace{10pt}
\m{sub} & \vcenter{\infer[]  {\m{}                             }{\m{C} & \cancel{\m{C \lor D}}}} \\
\vspace{10pt}
\m{simp_{res}} & \vcenter{\infer[]{\m{C}                      }{\cancel{\m{C \lor A }} & \cancel{\m{C \lor \lnot A}}}} \\
\vspace{10pt}
\m{simp_{res2}} & \vcenter{\infer[]{\m{C \lor D}              }{\m{C \lor A } & \cancel{\m{C \lor D \lor \lnot A}}}} \\
\vspace{10pt}
\m{simp_{=}} & \vcenter{\infer[]{\m{\termRepAt{C}{r}{\posss{C}{l}}}}{\m{l=r} & \cancel{~\m{C}~}}}   &
\parbox[c][2cm]{3cm}{\m{l \succ r}}\\
\vspace{10pt}
\end{array}
$

\bigskip
\noindent
\textbf{Congruence closure}\\
We also discuss three variants of the transitive reflexive congruence closure calculus \m{\mathbf{CC}}.\\
The reason we mention three versions is that one is minimally refutationally complete, so useful for completeness proofs,
the second follows directly the definition of a congruence relation and is complete for non-tautological (unit ground equality) consequences and hence useful for defining interpolants, 
and the third describes congruence closure graphs.

\noindent
\bigskip
The first version \m{\mathbf{CC}} is:\\
$
\begin{array}{lll}
	\vspace{10pt}
	\m{tra_{\bowtie}} & \vcenter{\infer[]{\m{s \bowtie t}}{\m{s=u,u \bowtie t}}} \\
	\vspace{10pt}
	\m{con}           & \vcenter{\infer[]{\fa{f}{s}=\fa{f}{t} }{\m{C} & \tup{st} }} &
\parbox[c][2cm]{2cm}{\m{\fa{f}{s} \lhd C}}\\
	\vspace{10pt}
	\m{res}           & \vcenter{\infer[]{\emptyClause }{\m{s=t, s \neq t}}} \\
\end{array}
$

\noindent
Where \m{\tup{s=t}} is the set \s{s_i = t_i \mid i \in 0..\size{s}-1 \land s_i \not\equiv t_i}.\\
For a set of unit ground equality clauses \m{S}, \CC{S} is the closure of \m{S} w.r.t. \m{\mathbf{CC}} - we will use a dedicated data structure to represent \CC{S}, described later. 
\bigskip

\noindent
The second version $\mathbf{CC_R}$, that is refutationally complete, replaces only the congruence closure rule with:\\
$
\begin{array}{lllll}
	\vspace{10pt}
	\m{con_R} & \vcenter{\infer[]{\fa{f}{s}=\fa{f}{t} }{\m{C} & \m{D} & \tup{s}=\tup{t} }} & 
	\parbox[c][1.5cm]{2cm}{\m{\fa{f}{s} \lhd C}\\\m{\fa{f}{t} \lhd D}}\\
\end{array}
$\\
This version does not generate any new terms.

The third version $\mathbf{CC_I}$, is (non tautological) consequence complete, replaces the reflexivity, congruence closure rule and adds a rule to derive all inequalities:\\
$
\begin{array}{llll}
	\vspace{10pt}
	\m{con_I} &
	\vcenter{\infer[]{\fa{f}{s}=\fa{f}{t} }{\tup{s}=\tup{t} }} & 
	\parbox[c][1.5cm]{4cm}{} \\
	\vspace{10pt}
	\m{das_I} &
	\vcenter{\infer[]{\m{u \neq v}}{\m{s \neq t}}} & 
	\parbox[c][1.5cm]{4cm}{\m{s \not\equiv t}\\\m{u \neq v \in das_u^{max}(s,t)}}\\
\end{array}
$\\
Where \m{das_u^{max}(s,t)} for \m{s \not\equiv t} is the set containing the maximal unit disagreement sets of \m{s,t} - defined as:\\
\m{das_u(s,t) \triangleq \s{ u \neq v \mid u \not\equiv v \land s \neq t \models u \neq v }} \\
\m{das_u^{max}(s,t) \triangleq \s{ u \neq v \in das_u(s,t) \mid \forall u' \neq v' \in das_u(s,t) \cdot u' \neq v' \not\models u \neq v}}\\
That is, \m{das_u(s,t)} are all unit inequalities on sub-terms of \m{s,t} that are implied by \m{s \neq t}.
We will discuss later how to determine this side condition effectively, we only note here that for each such \m{u \neq v} both \m{u,v} are sub-terms of \m{s,t} (at least one is proper) and for each of \m{s,t} at least one of \m{u,v} is a sub-term.
The important property to note of the calculus $\mathbf{CC}$ is that none of its productions introduces new equivalence classes - formally:
\bigskip

\subsection{Programs}
\subsubsection{Structure}
\noindent
\textbf{CFG paths:}\\
For a program (DAG) CFG \m{G}, a \emph{path} in the graph is a (possibly empty) sequence \m{\tup{n}} of nodes s.t. \m{\forall i \cdot p_{i+1} \in \succs{p_i}}.\\
We use \paths{G}{} for all directed paths in \m{G}, starting at any node and ending at any transitive successor of the node, include one and zero length paths.\\
For a node \node{n} and transitive predecessor \m{p \in \predst{n}},\\
\paths{p}{n} are all the paths in \m{G} that start at \m{p} and end at \m{n},including \m{n=p}.\\
\paths{n}{} is short for \paths{root}{n}.\\
For a path \m{P}, we define \m{ \clauses{P} \triangleq \bigcup\limits_{n \in P} \clauses{n}}.\\
For a set of clauses \m{S}, we denote by \Eqs{S} the subset of \m{S} that is unit equalities, inequalities and the empty clause:\\
\m{\Eqs{S} \triangleq (S \cap \s{\emptyClause}) \cup \s{u \bowtie v \mid u \bowtie v \in S}}\\
We use \m{\clauseseq{n}} for the set as above of clauses at the node \m{n}, \\
and \m{\clauseseq{P} \triangleq \bigcup\limits_{n \in P} \clauseseq{n}}.


\subsubsection{Semantics}
\textbf{Validity:}\\
A clause \m{C} holds at node \node{n} iff: \\
\m{n \models C \triangleq \forall P \in \paths{root}{n} \cdot \clauses{P} \models C } \\
A node \m{n} is \emph{infeasible} iff \m{n \models \emptyClause}\\
A program \emph{verifies} iff for each assertion node \m{n}, \m{n \models \emptyClause}.\\
Note that if we are working under a theory (that is \m{\models} applies the semantics of a theory in addition to the pure logic semantics), it might be the case that a program verifies but there is no Hoare annotation (interpolant) for it even without loops - the theory might be incomplete either for interpolation, joins or both - we will only discuss theories that are axiomatizable as a fragment of the logic.


\subsection{Fragments}
A \emph{program logic fragment} \m{F=(C_F,\vdash_F,\sqcup_F)} is:
\begin{itemize}
	\item A subset \m{C_F} of the finite sets of \Cs{\sig} for any signature \sig{}
	\item A derivation relation \m{\vdash_F} on sets of \m{C_F}
	\item A maximal join \m{\sqcup_F : P(C_F) \times P(C_F)\ast \rightarrow P(C_F)} \\
	that satisfies \m{\forall c \in \sqcup_F(C,S) \cdot \forall P \in S \cdot ( \emptyClause \in P \lor C \cup P \vdash_F c)} - \\
	basically this set includes any clause that is derivable by the fragment in all paths
\end{itemize}

\noindent
For the fragment of ground unit equalities \m{=}:
\begin{itemize}
	\item \m{\Eqs{C} = \s{C \in \Cs{\sig} \mid C=\emptyClause \lor \exists s,t \cdot C=s \bowtie t }}
	\item \m{\vdash_{=}} is \m{\vdash_{\mathbf{CC_I}}}
	\item \m{\sqcup_{=}(C,S) = \s{c \in C_{=} \mid \forall P \in S \cdot C \cup P \vdash_{=} c}} - 
	that is, a full relative join
\end{itemize}

\noindent
We define a \emph{fragment DAG interpolant} for verifying a subset of the leaf nodes \m{A}:\\
A fragment DAG interpolant \m{I} for a logical fragment \m{F} is a mapping from nodes to finite sets (conjunctions) of clauses - so \m{I_n} is the set of clauses at node \m{n} - that satisfies, for each node \node{n} (\sig{\m{n}} is the signature at node \node{n}, 
until discussing scoping we assume all the nodes have the same signature):\\
$
\m{I_n \in C_F(\sig{n})}\\
\m{\sqcup_F(\clauses{n},\s{I_p \mid \node{p} \in \preds{n}}) \vdash_F I_n}\\
\m{\forall n \in A \cdot \emptyClause \in I_n}\\
$
For a given CFG and fragment \m{F}, the set of all interpolants in the fragment \m{F} is \m{I_F}.

\noindent
To see why we need a separate join operation, consider the following alternative definition for a join for ground unit equalities:\\
\m{\sqcup_{GUE'}(C,S) = C \cup \bigcap S}\\
This would be the simplest join that just takes the intersection of clauses on both sides, but is strictly weaker as we will show later.

\noindent
\textbf{Provability in a fragment:}\\
For a given program logic fragment \m{F}:\\
\m{n \models_F C \triangleq \exists I \in I_F \mid C \in I_n}\\
And the program is \emph{within the fragment} if there is a \m{I \in I_F} s.t. for each assertion node \m{n}, \m{\emptyClause \in I_n}.\\
Note that even if all assertions nodes are provable in a fragment, 
it might be the case that the program is not within the fragment, 
if e.g. the fragment limits the number of clauses at a node (limited resource strategy), 
and the conjunction of interpolants needed to prove the program is too large and hence not within the fragment - in the fragments we present we will try to avoid such cases.


\subsection{Equivalence Classes}
For a given set of clauses \m{S}, we overload the meaning of \Eqs{S} to denote also the equivalence relation defined by the reflexive transitive closure of the unit ground equalities in \Eqs{S}.\\
We define the set of equivalence classes of terms of a set of clauses\\
 \m{\ECs{S} \triangleq \terms{S}/\Eqs{S}}.\\
For a node \node{n} we will use \ECs{n} for \ECs{\clauses{n}}.

\noindent
A desirable property of the calculus \m{\mathbf{CC}} is that\\
$\size{\ECs{S}} \geq \size{\ECs{CC(S)}}$.\\
In fact, if \m{C} is the result of a derivation with premises in \m{S}, and \m{S'=S \cup \s{C}}, then $\size{\ECs{S}} \geq \size{\ECs{S'}}$. \\
So the set of equivalence classes does not grow from applying derivations in the calculus.
This property is immediate from the definition of the calculus, as for each rule, for each subterm of the conclusion, either the subterm appears in the premises, or the conclusion equates it to a term that appears in the premises.
We will actually use a stronger property that more accurately models complexity:

\noindent
\subsubsection{GFAs}
For a given congruence relation on ground terms we define \emph{ground function application equivalence class} 
which are the smallest sets of terms out of which equivalence classes are constructed, and the smallest unit shareable with refinements of the congruence relation.\\
For a sub-term-closed set \m{S} of ground terms, a congruence relation \m{R} over terms, a function symbol \m{f} and a sequence of equivalence classes \\
\m{\tup{s} \in (S/R)^{\arity{f}}}, we call the set of terms \\
\m{\fa{f}{s} \triangleq \s{\fa{f}{t} \mid \bigwedge\limits_i t_i \in s_i}} \\
a \emph{ground function application equivalence class} - \GFAEC, and the set of such \GFAECSet for a relation \m{R} \GFAECs{R}.\\
By the definition of congruence closure, \m{\forall \fa{f}{s} \in \GFAECs{R},\m{t} \in \fa{f}{s} \cdot \fa{f}{s} \subseteq [t]_{R}}, 
but even if \m{\fa{f}{s} \cap S \neq \emptyset} it may be the case that \m{\fa{f}{s} \setminus S \neq \emptyset} - that is, a ground function application EC may include more terms than were used to generate it.
Note also, that it is not necessarily the case that \fa{f}{s} is an equivalence class of \m{R} over the set of all terms - for example if \m{R} is generated by \m{S = \s{a=b,f(a)=g(c)}}, then in \m{S/R}, we have five \GFAECSet - 
\s{a(),b(),c(),f(\s{a,b}),g(\s{c})}, while we only have three equivalence classes: \s{ \s{a,b}, \s{c}, \s{f(a),f(b),g(c)}}.\\
This hints also at another property of \GFAECSet: \\
For the above set \m{S} and the set \m{S' = \s{a=b,f(f(a))=f(a)}}, 
the set of \GFAECSet of \m{S'} is \\
\s{a(),b(),f(\s{a,b}),f(\s{f(\s{a,b})})}, \\
so if \m{S} is the set of clauses of a node and \m{S'} is the set of clauses of a direct successor of that node, they can share the common \GFAECSet \s{a(),b(),f(\s{a,b})} (assuming e.g. \m{c} goes out of scope at the successor node) while they could only share the equivalence classes \s{\s{a,b}}.\\
For a given \m{R}, all \GFAECSet are disjoint and each equivalence class is a union of \GFAECSet.
Our congruence closure calculus \m{\mathbf{CC}} does not generate any new \GFAECSet - the only rule that may introduce a new term (con) does not introduce a new \GFAEC.
We will use the number of \GFAECSet as the main space complexity measure as our data structure is based on \GFAECSet and, for all the other congruence closure algorithms, the space complexity is at least the number of \GFAECSet, possibly more.
In most cases we do not consider the (largest) function arity as a complexity factor as it does not change asymptotic behaviour, 
but in the few cases where it does we mention it.\\
For a set of functions \m{F} and a set of equivalence classes \m{E}, the maximal number of \GFAECSet is:\\
\m{\sum\limits_{f \in F} \size{E}^{\arity{f}}} so if $n=max\s{\arity{f} \mid f \in F}$ then the upper bound is \\
\bigO{\size{F}\size{E}^n}.\\
The size of the representation of each such \GFAEC \fa{f}{s} is \arity{f} (references to term equivalence classes), so the total complexity is at most \\ \m{\sum\limits_{f \in F} \arity{f}\size{E}^{\arity{f}}}, which, by sharing such tuple ECs can be reduced to 
\m{\sum\limits_{f \in F} \size{E}^{\arity{f}}}.\\
However, new \GFAECSet are only introduced by introducing new clauses, not by congruence closure derivations, and is at most linear in the sum of sizes of clauses in \m{S}.\\
For an arity \m{n} we expect many equivalence class tuples to participate in more than one \GFAEC - for example:\\
In \m{f(a,b)=g(a,b),a=c} the EC tuple \m{(\s{a,c},\s{b})} is used twice,
we can also share EC tuples to reduce overall complexity, but the dominant part of the complexity measure is still \bigO{\size{E}^n}.\\
Another important property of this complexity measure is that it is agnostic to the order of derivations - it only depends on the current set of clauses - for example, if we first assume \m{f(a)=c,f(b)=d} and then \m{a=b}, the final result will have only one \GFAEC with the function symbol \m{f}, while a union find data structure might have two such terms, while if the introduction order is  
first \m{a=b} and then \m{f(a)=c,f(b)=d} then union find will only have one such term.



\newpage
\subsection{Predicate Transformer Semantics}
In this section we refine the strongest post-conditions discussed earlier in order to show which part of the verification can be done at the unit level. We emphasize the time and space complexity of propagation as our objective is efficient and reliable verification rather than maximizing the set of programs verifiable in the fragment.

As in the propositional case, we discuss mostly information propagation between adjacent nodes, but will also discuss some cases in which we can have "bypasses" between non-adjacent nodes.

For this discussion we need some extra terminology:\\
As before, we denote the set of clauses known at a node \node{n} as \clauses{n}.
We want to define the subset of \precond{n} and \postcond{n} these which is guaranteed to be unit ground equalities.

Remember the definitions for pre and post conditions:\\
$
\begin{array}{lll}
	\precond{n}  &\triangleq   & \bigwedge\limits_{\substack{\node{p} \in \predsto{n} \\ \clause{c} \in \clauses{p}}} (\rpc{p}{n} \rightarrow \clause{c}) \\
	\postcond{n} & \triangleq  & \lpc{n} \land \precond{n} \land \bigwedge \clauses{n}
\end{array}
$

Remember that we can add to \clauses{n} any \clause{C} if $\postcond{n} \vdash \clause{C}$ without losing soundness or completeness.

We assume from now on that $\lpc{n} \in \clauses{n}$.\\
We write the definitions in CNF treating \rpc{p}{n} as a set of literals and writing 
$\lnot \rpc{p}{n}$ for $\bigvee\limits_{\m{l} \in \rpc{p}{n}} \lnot \m{l}$ :\\
$
\begin{array}{lll}
	\vspace{10pt}
	\precond{n}  & \triangleq & \bigwedge\limits_{\substack{\node{p} \in \predsto{n} \\ \clause{c} \in \clauses{p}}} 
(\clause{c} \lor \lnot \rpc{p}{n} )\\
	\vspace{10pt}
	\postcond{n} & \triangleq & \precond{n} \land \bigwedge \clauses{n} \\
\end{array}
$

The clauses $(\clause{c} \lor \lnot \rpc{p}{n} )$ are still not unit clauses and contain path (non equality) literals.
We could remap path literals to constant equality literals as in the transformation from PL to GFOLE but that still leaves us with no unit clauses.

The first step is to reformulate preconditions as a function of only direct predecessors:\\
$
\begin{array}{lll}
	\vspace{10pt}
	\precondI{n}   & \triangleq & \bigwedge\limits_{\substack{ \node{p} \in \preds{n} \\\clause{c} \in \postcondI{p}}}
( \clause{c} \lor \lnot \rpc{p}{n}) \\
	\vspace{10pt}
	\postcondI{n} & \triangleq & \precondI{n} \land \bigwedge \clauses{n}
\end{array}
$

This is semantically equivalent to the above, the proof relying on the lemma that:\\
$\forall \node{n} \cdot \forall \node{p} \in \preds{n} \cdot \forall \node{p_1} \in \predsto{p} \cdot \rpc{p_1}{n} = \rpc{p}{n} \cup \rpc{p_1}{p}$

Now if we look at \rpc{p}{n} where \node{p} is a direct predecessor of \node{n}, we have two options:
\begin{itemize}
	\item \node{n} is a sequential node and $\rpc{p}{n}=\emptyset$ which means $\lnot \rpc{p}{n} \Leftrightarrow \false$
	\item \node{n} is a join node that joins the path condition \m{c} and so for a direct predecessor \node{p}, $\rpc{p}{n} \in \s{c,\lnot c}$
\end{itemize}

In order to avoid losing precision because of infeasible predecessors, we define the set of valid predecessors:\\
$\vpredsII{n} \triangleq \s{\node{p} \in \preds{n} \mid  \emptyClause \not\in \postcondII{p}}$

The next step is to remove, syntactically, the redundant \true literals in the clauses - for that we will use the set of \emph{common clauses}
\cprecondII{n} between all of the feasible (not provably infeasible) direct predecessors of a node, which for sequential nodes is just all the clauses from the predecessor:\\
$\cprecondII{n}  \triangleq \bigcap\limits_{\node{p} \in \vpredsII{n}} \postcond{p}$\\
We define also the complement \uprecondII{n,p}, the clauses unique to a predecessor.

The preconditions of the node will include the empty clause iff it is not the root and all the direct predecessors are provably infeasible.\\
The next iteration of the definitions is as follows:\\
$
\begin{array}{lll}
	\vspace{10pt}
	\vpredsII{n}     & \triangleq & \s{\node{p} \in \preds{n} \mid  \emptyClause \not\in \postcondII{p}} \\
	\vspace{10pt}
	\cprecondII{n}   & \triangleq & \bigcap\limits_{\node{p} \in \vpredsII{n}} \postcondII{p} \\
	\vspace{10pt}
	\uprecondII{n,p} & \triangleq & \postcondII{p} \setminus \cprecondII{n} \\
	\vspace{10pt}
	\precondII{n}    & \triangleq & \bigwedge\cprecondII{n} \wedge \bigwedge\limits_{\substack{\node{p} \in \vpredsII{n}\\\clause{c} \in \uprecondII{n,p}}} 
	(\m{c} \lor \lnot \rpc{p}{n})\\
	\vspace{10pt}
	\postcondII{n} & \triangleq & \precondII{n} \land \bigwedge \clauses{n}
\end{array}
$

Now a sequential node would get all the unit clauses from the predecessors and join nodes would get all the common unit clauses.
Additionally, there is much less in the way of redundant literals in clauses.
This can serve as a good basis for finding the set of unit clauses that the algorithm will calculate, however, consider the following program:
\begin{lstlisting}[caption={three way join},label=snippet3.1]
$\node{p_b}:$
if ($\m{c_1}$)
	$\node{p_t}:$
	assume a=b
else
	$\node{p_e}:$
	assume b=c
$\node{p_j}:$
assume a=c
	$\node{p_ja}:$
	assert a=b
\end{lstlisting}

Here, \\
$
\begin{array}{lll}
\precondII{p_j}     & = & \s{\lnot \m{c_1} \lor \term{a=b}, \m{c_1} \lor \term{b=c}} \\
\postcondII{p_j}    & = & \s{\term{a=c}, \lnot \m{c_1} \lor \term{a=b}, \m{c_1} \lor \term{b=c}} \\
\postcondII{p_{ja}} & = & \s{\term{a \neq b},\term{a=c}, \lnot \m{c_1} \lor \term{a=b}, \m{c_1} \lor \term{b=c}}
\end{array}
$\\
This is sufficient in order to prove the assertion, but if we restrict \precondII{n} 
to only ground unit equalities that are in both predecessors, we get:\\
$
\begin{array}{lll}
	\restrict{\precondII{p_j}}{u}     & = & \s{} \\
	\restrict{\postcondII{p_j}}{u}    & = & \s{\term{a=c}} \\
	\restrict{\postcondII{p_{ja}}}{u} & = & \s{\term{a \neq b},\term{a=c}}
\end{array}
$\\
Which is insufficient. 
This is the general problem where $\m{(a \sqcup b) \sqcap c}$ is potentially less precise than $\m{(a \sqcap c) \sqcup (b \sqcap c)}$.
This problem is mentioned in ~\cite{GulwaniTiwariNecula04} as the \emph{context sensitive join}.
In order to be able to handle this fragment we want to use the transitive congruence closure of $(\clauses{n} \cup \postcondII{p})$ in the intersection.
We will see more related examples for this later.

Using the above, we define, for a node \node{n} and a direct predecessor \node{p} the \emph{relative clauses} of \node{p} as:\\
$\rClausesIII{p}{n} \triangleq (\CC{\postcondIII{p} \cup \clauses{n}})$\\
and using that we refine the set of valid predecessors:\\
$\vpredsIII{n}      \triangleq \s{\node{p} \in \preds{n} \mid  \emptyClause \not\in \rClausesIII{p}{n}}$

The motivation for this formulation comes from programs such as this:
\begin{lstlisting}[caption={join inequality propagation},label=snippet3.2]
if (*)
	$\node{p_t}:$
	assume $\m{f(a) \neq f(b)}$
else	
	$\node{p_e}:$
	assume $\m{c=d}$
$\node{p_j}:$
assume $\m{a=b}$
	$\node{p_{ja}}:$
	assert $\m{c=d}$
\end{lstlisting}

Here $\vpredsII{p_j}=\s{p_e}$ because \\
$\emptyClause \in \CC{\clauses{p_j} \cup \clauses{p_t}}=\CC{f(a) \neq f(b),a=b} \\
=\s{a=b,f(a)=f(b),f(a) \neq f(b),\emptyClause}$,\\
 and so we can use the clause \m{c=d} from \node{p_e}, which would not be possible without considering both \clauses{p_j}, \clauses{p_t} and congruence closure.

%\s{s \neq t \mid \exists u,v \cdot \s{\term{s=u,v=t,u \neq v}} \subseteq \m{S} } \cup \\
%\s{ \emptyClause \mid \exists s,t \cdot \s{\term{s=t,s \neq t}} \subseteq \m{S} } \cup \\
%\mathbf{DAI}(\m{S})$

%We will explain the last rule in the following.

\noindent
Now we can define another version of our preconditions:\\
$
\begin{array}{lll}
	\vspace{10pt}
	\rClausesIII{p}{n} & \triangleq & \CC{\postcondIII{p} \cup \clauses{n}} \\
	\vspace{10pt}
	\vpredsIII{n}      & \triangleq & \s{\node{p} \in \preds{n} \mid  \emptyClause \not\in \rClausesIII{p}{n}} \\
	\vspace{10pt}
	\cprecondIII{n}   & \triangleq & \bigcap\limits_{\node{p} \in \vpredsIII{n}} \rClausesIII{p}{n} \\
	\vspace{10pt}
	\uprecondIII{n,p} & \triangleq & \postcondIII{p} \setminus \cprecondIII{n} \\
	\vspace{10pt}
	\precondIII{n}    & \triangleq & \bigwedge\cprecondIII{n} \wedge \bigwedge\limits_{\substack{\node{p} \in \vpredsIII{n}\\\clause{c} \in \uprecondIII{n,p}}} 
	(\m{c} \lor \lnot \rpc{p}{n})\\
	\vspace{10pt}
	\postcondIII{n} & \triangleq & \CC{\precondIII{n} \land \bigwedge \clauses{n}}
\end{array}
$

Now coming back to ~\ref{snippet3.1}:\\
$
\begin{array}{lllll}
\CC{\postcondIII{p_t} \cup \clauses{p_j}}  & = & \s{a=b,b=c,c=a} \\
\CC{\postcondIII{p_e} \cup \clauses{p_j}}  & = & \s{a=b,b=c,c=a} \\
\cprecondIII{p_j}                          & = & \s{a=b,b=c,c=a} \\
\precondIII{p_j}                           & = & \s{a=b,b=c,c=a} \\
\postcondIII{p_j}                          & = & \s{a=b,b=c,c=a} \\
\postcondIII{p_{ja}}                       & = & \s{a=b,b=c,c=a,a \neq b,\emptyClause} \\
\end{array}
$\\
This is sufficient in order to prove the assertion, even under the unit restriction.

The space complexity of the pre and post conditions above, referring to \size{\ECs{\mathbf{\postcondIII{n}}}} is, however, in the worst case double exponential in the size of the original program, as we have seen in the previous section.

Also, as mentioned before, a simple program as this:
\begin{lstlisting}[caption={join congruence closure},label=snippet3.3]
if (*)
	$\node{p_t}:$
	assume $\m{f(a) = f(b)}$
else	
	$\node{p_e}:$
	assume $\m{a=b}$
$\node{p_j}:$
	...
	$\node{p_{ja}}:$
	assert $\m{f(a)=f(b)}$
\end{lstlisting}

Will not verify with the above formulation as (again, showing only unit clauses and not showing reflexive equalities)\\
$
\begin{array}{lllll}
\restrict{\CC{\postcondIII{p_t} \cup \clauses{p_j}}}{\m{u}}  & = & \s{f(a)=f(b)} \\
\restrict{\CC{\postcondIII{p_e} \cup \clauses{p_j}}}{\m{u}}  & = & \s{a=b} \\
\restrict{\cprecondIII{p_j}}{\m{u}}                          & = & \s{} \\
\restrict{\precondIII{p_j}}{\m{u}}                           & = & \s{} \\
\restrict{\postcondIII{p_j}}{\m{u}}                          & = & \s{} \\
\restrict{\postcondIII{p_{ja}}}{\m{u}}                       & = & \s{f(a) \neq f(b)} \\
\end{array}
$

The terms \m{f(a)} and \m{f(b)} will not appear at the join as they are not both represented on both sides of the join.

This is obviously highly unsatisfactory - a potentially double exponential algorithm that cannot verify very simple correct programs.
In a sense, the join (and also equality propagation to sequential nodes) is both too eager and too lazy - it propagates equalities regardless of the statements in successor nodes.
As in the propositional case, we want propagation to be goal sensitive - that is, propagate information that is potentially useful in successors. Also as in the propositional case, we have seen that we do not want to propagate, in the unit fragment, all the potentially useful information, as this might too high complexity, or even not be finitely representable.

\newpage
\section{Unit Ground Equalities}
We will now consider the handling of the fragment that includes only unit ground equalities (both of positive and negative polarity).
This fragment forms the basis for all the other fragments that we consider.

We consider programs where the CFG is a DAG with one root and each node has only statements of the form \lstinline{assume t$\bowtie$s} or \lstinline[mathescape]{assert t$\bowtie$s} where \m{t,s} are ground terms.

\subsection{Complexity}
We will only describe in this section the general known results for our fragment and give further examples later.

\textbf{Input size:} We measure the size of the input for this problem by the number \m{n} of occurrences of function symbols in the input, and the number \m{e} of edges in the program CFG - so, for example, a statement \lstinline[mathescape]{assume f(a)=g(b,b)} would have the size 5. 
Note that for a CFG with a bounded out degree the number of edges is linear in the number of nodes, so we can use these interchangeably for asymptotic complexity. Well branching programs have an out degree 2.

\textbf{Worst case time:} The best known time complexity for deciding a set (conjunction) of unit ground equalities and inequalities is \m{O(n log(n))} - several congruence closure decision procedures have been shown sound and complete - for example ~\cite{DowneySethiTarjan}, ~\cite{NieuwenhuisOliveras03} and (the congruence closure part of) ~\cite{Shostak84} and ~\cite{NelsonOppen80}. These include also complexity analysis.
All of the above-mentioned algorithms essentially build a graph with terms as vertices, and perform congruence and transitive closure with differing levels of laziness.
Roughly, the reason for the $O(n\ \mathrm{log}(n))$ complexity is that the graph need never have more nodes and edges than there are terms in the original problem, and each time a new equality is inserted into the graph, we can merge the smaller equivalence class into the bigger one, so each term is remapped at most \m{O(log_2(n))} times - this is proven each of the above papers. 
The number of equivalence classes is reduced by at least one for each assumed equality (or more in the case of congruence closure), so in total at most \m{n} such reductions can happen. A search data structures is used to index each term to its direct super-terms in the graph(e.g. \term{a} would be mapped to \term{f(a),g(a)}), usually termed the \emph{uses} list, so that congruence closure can be done efficiently. This data structure is merged for two vertices when these vertices are merged.
A preprocess of the set of equations can \emph{flatten} and them and curryfy them so that it includes only terms of depth at most 2 and only one binary function (~\cite{NieuwenhuisOliveras03}).
The \term{uses} data structure can be implemented as an \m{a} dimensional array for a complexity \m{O(a)} for insert,lookup and remap(on merge) where \m{a} is the largest function arity, but space \m{O(n^a)} - for a total complexity of \m{O(n log(n))}.
A more space efficient option is a binary tree for \m{log(n)} for the above operations but space \m{O(n)} - giving an overall complexity of \m{O(n log^2(n))}. 
Another practical solution is to use hash table for average \m{O(1)} operations and \m{O(n)} space - giving the optimal average complexity but worse case \m{O(n^2)} complexity - see ( ~\cite{DowneySethiTarjan} for a discussion.

\textbf{Worst case space:} Equality is described by either linking two vertices with an equality edge or merging the vertices. For transitive closure all algorithms do not produce all transitive edges but rather select one representative for each equivalence class and, lazily or eagerly, the path from each vertex to its representative is compressed to one edge, so at most one extra edge is added per vertex.
On the graph representation distinct inequality edges can be added, and the only source for inconsistency can be an inequality edge between two vertices with the same representative. Space complexity is, hence, O(n) as we have at most one vertex and one edge per input symbol occurrence - a vertex will have at most as many incoming edges as it has occurrences - if \m{f(a)} and \m{g(a)} appear in the input, the graph will have just one vertex to represent \m{a}, but an incoming edge into \m{a} each for \m{f(a),g(a)}.
As detailed above, unless the array solution is used we get a space complexity of \m{O(n)}.
This linear space property explains, to some degree the appeal of DPLL solvers.

From now on we will not consider the array solution as we find it impractical in terms of space and also, for large inputs, the array is not likely to fit in the processor cache and so would be practically less efficient than other implementations. 

\textbf{Verification algorithm:}
For a program with no joins (a tree shaped CFG) the time complexity is still \bigO{n\ log^2(n)} (using trees), as we can verify a tree-shaped program as follows:
\begin{lstlisting}
proc verify(CFG cfg)
	d := empty congruence closure data structure
	n := cfg.root
	e := 0   //next successor to explore
	do
		add all (in)equalities from n to d
		if (n is an assertion) and (d.isConsistent)
			return FAIL(n) //The assertion does not hold
		if (!d.isConsistent) or (e==n.successors.count)
			if (stack is empty)
				return PASS
			else
				(n,d,e) = pop
		else
			if (n.successors.count==1)
				n := n.successors.first
			else //explore next successor of a branch
				push (n,d,e+1)
				e := 0    //reset e for the next branch
				n := n.successors[e]
	end
\end{lstlisting}
This algorithm explores the depth first, and stores backtracking information at each branch which has not been fully explored.
We have to evaluate only up to \m{n} equalities in total and we traverse each edge at most once, so the worst case time complexity is \m{O(n log^2(n)+e)} with \m{e} the number of edges. 
The space complexity is at most \m{O(n \times e)} (worst case quadratic in the total input size) as we store the data structure at each branch, but some of the congruence closure implementations above support backtracking without asymptotically increasing the space, sot the space complexity is reduced to \m{O(n + e)}.

As can be seen above, the operations needed on the congruence closure data structure are:
\begin{itemize}
	\item Assume an (in)equality, including congruence closure
	\item Check for conflict
	\item Forget an (in)equality, undoing the relevant implied (congruence and transitive closures) equalities
	\item Add a term and get its representative - not used above, but can be used to implement queries
\end{itemize}
Different congruence closure algorithms are compared in ~\cite{BachmairTiwari00}. They all result in a data structure that can answer efficiently the question of whether two given terms are equivalent under the conjunction of equalities.
The efficiency of the above operations depends on the specific algorithm. Some algorithms perform congruence and transitive closure eagerly, while others try to minimize the time it takes to add assumptions, and only perform closure on queries relying on caching (e.g. path compression) to reduce the amortized time for the whole algorithm.

In all of the above algorithms the resulting data structure \emph{represents} a certain set of terms, which include at least all the terms that appeared in the equalities used to construct the data structure. For each term that is represented, all the terms that belong to the same equivalence class (under the conjunction of equalities) and all the subterms are also represented. 
Note that the set of represented terms can be infinite even for a finite set of equalities - for example the data structure for \m{a=f(a)} represents the terms \s{f^i(a) \mid i \in \mathbb{N}}. For a term \m{t} not represented in the data structure it can be added in at most \m{\size{t}} steps - adding a term cannot cause any existing equivalence classes to be merged.

For most implementations, the way to check (in)equality between two terms is to check whether they have the same representative.
The time it takes to map a term \m{t} to its representative depends on the laziness of the algorithm - eager algorithms answer it in \m{O(\size{t} log(n))} (n is the number of vertices in the graph) as the term needs to be mapped bottom up from constants, and each step up requires a lookup in the \emph{uses} index.

All of the above algorithms compute the congruence closure only from positive equalities, and then it is possible to check for each inequality whether both sides of the inequality are in the same equivalence class, which signals a contradiction. 
For an inequality \m{s \neq t} this check can be done by adding the terms \m{s,t} to the congruence closure data structure and then checking whether they map to the same equivalence class - so at most at \m{O((\size{s}+\size{t}) log(n))}.

A conjunction of positive equalities in our setting is always consistent, so it might be the case that only a fraction of the equalities are needed in order to show that a given inequality is inconsistent. The algorithms above are all eager in that they take all equalities into account and calculate the equivalence classes for all the terms that appear in the program, while it is sufficient to calculate equivalence classes only for terms that appear in inequalities. 
We can reduce somewhat the set of equalities we consider when trying to refute a given inequality by using scoping as we will show later.

\textbf{Joins:}
Even for a loop-free procedure with joins, the complexity rises to exponential because of join points which cannot be represented as conjunctions.

Our algorithm would work for a DAG shaped program, in fact being a variation of the DPLL procedure:  when backtracking from a branch after having explored all its outgoing edges, we forget that we have covered all outgoing edges for the branch, so that the next time we reach the branch (on another path) we will again explore all outgoing edges.
This has a worst case complexity of \bigO{n log^2(n) \times 2^v} as the number of times we traverse a node (and hence its equalities) can be exponential - for example if we have $v/3$ diamonds of branch-join in sequence, the last leaf node will be traversed $2^{v/3}$ times.
Modern DPLL has several advantages over this naive procedure - notably:
\begin{itemize}
	\item Order of evaluation - DPLL could decide to explore the decision tree in another order than the one described above, that could mean deciding on branches before having decided on the path leading to the branch, but could also mean deciding on an (in)equality that appears somewhere in the program before deciding a path that leads to such a point in the program
	\item Clause learning - DPLL can learn a clause that generalizes part of the proof of the infeasibility of one path of exploration, 
	which can help it prune some other paths from being explored
\end{itemize}
We cannot expect better than exponential worst case complexity for DAGs as we can encode CNF-SAT to this problem in linear time - each clause with n literals is encoded into an n-branch which is immediately joined, where each literal is encoded as above using the \term{T} symbol.
The branch-join structures are organized in sequence and the CNF-SAT problem is satisfiable iff the last node (the only leaf node) is reachable - if we have not found a path leading to it in which we have found no contradiction.

However, we can easily construct a sequence of programs that each have a Hoare proof linear in the size of the program, but their encoding into SMT would take exponential time to current DPLL-CDCL solvers, this example taken from ~\cite{DPLLJoin}:
\begin{lstlisting}[caption={linear join proof},label=snippet3.4]
$b_{0}$:
	assume $a_0=d$
	if (*)
		assume $\m{b_1=a_0}$
		assume $\m{a_1=b_1}$
	else
		assume $\m{c_1=a_0}$
		assume $\m{a_1=c_1}$
$j_{0}:$

...
$j_{n-1}:$
	if (*)
		assume $\m{b_n=a_{n-1}}$
		assume $\m{a_n=b_n}$
	else
		assume $\m{c_n=a_{n-1}}$
		assume $\m{a_n=c_n}$
$j_{n}:$
	assert $\m{a_n=d}$ //negated $\m{a_n \neq d}$
\end{lstlisting}

This program will take exponential time for current CDCL solvers (we have tried both Z3 and CVC4 - both timed out for 50 diamonds, which were verified in less than a second using congruence closure with join as described below) without provisions for join as the literals \m{a_{i}=a_{i+1}} and \m{a_{i+1}=d} do not exist in the original problem and hence cannot be learned by CDCL. 
Note that the unit clause \m{d=a_{i+1}} is essentially an interpolant between \postcond{j_{0}} and \postcond{j_{n}}. 
Another problem with the DPLL based approach in our setting is that we want a verifier that is gradual in that it applies stronger and costlier methods gradually. DPLL must arrive at a conflict on a path in order to learn a new clause - when quantifiers are involved we do not want to try unbounded quantifier instantiation on a single path before other paths have been explored at all, and we want to be able to learn potentially useful lemmas (that could be shared with other tools) even without reaching a conflict.

As we have seen for the propositional case, we do not always have a small interpolant, even when there is a small proof for the whole program. 

\subsection{Joins}
When discussing joins we would use the term \emph{joinees} for the two direct predecessor nodes of a join node, and refer to these nodes as the \emph{left} and \emph{right} joinees (in the order in which they are introduced in the text unless otherwise noted).
We would use \m{[t]_l} resp \m{[t]_r} for the equivalence class of the term \m{t} in the congruence relation induced by the set of equalities at the left, resp. right joinee.

The join (disjunction or intersection) of the congruence relation defined by two sets(conjunctions) of unit equalities cannot always be represented as the conjunction of a finite set of unit ground equalities, or even by an infinite set - for example, the disjunction of the sets \s{a=b} and \s{a=c} cannot be represented by ground unit equalities. for a program such as:

\begin{lstlisting}[caption={non unit join},label=snippet3.5]
	if (*)
		assume c=a
	else
		assume c=b
$p_j:$
	if (*)
	$p_{t}:$
		assume a=b
		$p_{ta}:$
			assert a=c //negated a $\neq$ c
	else
		...
\end{lstlisting}

Although each path from root to assertion in the program can be proven using only unit (in)equalities, 
there is no set of ground unit (in)equalities that holds at $p_j$ and is sufficient to prove the assertion - 
it is not within our interpolation fragment.
As shown in ~\cite{GulwaniTiwariNecula04}, even when the disjunction is representable as a set of unit equalities, this set is not necessarily finite. 
In light of this limitation, our objective in calculating a join would be to only find small joins, and fall-back to non-unit ground equality clauses in other cases.

The class of programs that can be proven by only propagating unit \\
(in)equalities we defined as programs valid under the fragment of ground unit \\ 
(in)equalities - intuitively the programs that can be proven with a Hoare annotation (fragment interpolant) that is only conjunctions of ground unit\\
 (in)equalities and the empty clause.

We will call this set of programs $\mathbf{P}_{=}$.

The example given in ~\cite{GulwaniNecula07} shows a program of size \m{n} (total function symbols) with only unit equalities (in fact only variable assignments - an even smaller class) that ends in an \m{\sqrt{n}} sided join node for which the minimal representation of the equivalence class of a certain variable as a set of equalities is of size \m{\theta(2^{\sqrt{n}})}.\\
We will show later that this example can be written using assumes (rather than assigns) so that the number of distinct \GFAECSet in representing the said variable at the join node is \m{\theta(2^{n})}.\\
Designating this program of size \m{n} with the variable \m{x} as \m{P(n,x)}, we can construct the following program:
\begin{lstlisting}[caption={exponential join proof},label=snippet3.6]
$\node{b}$:
	P(n,x)
$\node{j_0}$:
	P(n,y)
$\node{j_1}$:
	assert x=y
\end{lstlisting}

This program is within our fragment, but the minimal number of \GFAECs needed to prove it in the fragment is \m{\theta(2^{n})}, while DPLL could simply explore each of the \m{\sqrt{n} \times \sqrt{n} = n} paths of the program and produce a proof of size \m{n} for each path - so in total \m{O(n^2)} sized proof.
This means that even for programs within our class we can have exponential sized minimal interpolants.

The complexity of verifying this class of programs is NP-complete as we have seen there are polynomial encodings to CNF, 
and as the example above shows there are programs with worst case (single) exponential interpolated proof (in our fragment) size as represented using \GFAECSet, and a worst case double exponential interpolated proof if one exists, but we are not aware of a better lower or upper bound for the complexity of deciding whether such an interpolated proof exists, and whether a non-\GFAEC based representation can allow smaller proofs. \\
We note here that we are not always interested in complete joins for this class of programs, even if such a complete join is required to prove the program. 
Rather, in a program as above, we would fall-back to the non-unit fragment, 
encode each join using (linear sized conjunctions of) equalities guarded by branch conditions, and rely on resolution and superposition at \node{j_1} in order to derive a contradiction.

Although the congruence closure algorithms mentioned above differ somewhat in presentation, they essentially all manipulate a graph where nodes represent sets of terms and ordered edges represent function application. In some implementations the graph is fully reduced - that is, each equivalence class is represented by exactly one node - we call these eager algorithms as they merge equivalence classes eagerly (no duplicated \GFAECSet), while in others equality edges are drawn between nodes that belong in the same equivalence class - hence lazy algorithms.
In all cases we can represent an inequality between two terms as an inequality labeled edge between the representatives of the equivalence classes of these two terms in the graph, and as we do not need to add implied inequalities for complexity (until we do scoping - described in later chapters), the number of inequalities is at most the number of those in the input.

We use an eager version of congruence closure as the basic engine for the theory of unit ground equalities, implementing a join algorithm for it in order to handle programs as the above case, and falling back to non-unit clauses (described in the next chapter) for the cases where the join cannot be represented as unit equalities. 
This means that we represent an equivalence class not using a representative but as an object that represents all of the equivalence class's members symmetrically. This representation, although somewhat more expensive to construct and update, ensures that operations such as comparison and join are simpler, and especially that we can share these objects between CFG nodes that agree on these equivalence classes and that adjacent nodes can communicate using these objects rather than terms - so we avoid the \m{O(\size{t})} term lookup price except when constructing the initial CFG.
We use the number of edges of such a graph as the measure of its size as the number of edges dominates the number of vertices. A fully reduced graph constructed of a set of equalities will always be smaller or equal in size to the total size of the set of equalities - as will be shown in the construction algorithm.

In ~\cite{GulwaniTiwariNecula04}, an \m{O(n^2)} algorithm is given for joining two sets of unit equalities, which guarantees that any term that is represented on both sides (that is, for which an there is a node in the graph that represents its equivalence class), is also represented at the join, and the join contains the full equivalence class for that term.

The basic reason for this complexity is that any equivalence class at the join must correspond to at least one equivalence class in each joinee, while not necessarily all such pairs are needed in order to represent all the common terms (that is - terms represented on both sides of the join) at the join.

To illustrate: consider joining two identical congruence closure graphs - the join is exactly the size of each side, and the only pairs are two copies of the same equivalence node.

On the other hand, consider joining  \s{a=f^m(a)} and \s{a=f^n(a)} where \m{m} and \m{n} are co-prime - here the join would be 
\s{a=f^{m+n}(a)}, so of a quadratic size representation. 
For both joinees and for the join point, the set of represented terms is \s{f^i(a) \mid i \in \mathbb{N}}.
Here we are using all the pairs where each pair \m{([f^x(a)]_l,[f^y(a))]_r} represents the equivalence class \\
\s{f^{((xn+ym) \mathbf{~mod~} mn) + imn}(a) \mid i \in \mathbb{N}}, by the Chinese remainder theorem.

For any given term \m{t}, we can calculate the complete equivalence class of that term at any join by adding the term to each side and calculating the join as above.
Adding a term \m{t} to a congruence closure graph is of complexity \size{t} and hence obviously can add at most \size{t} edges to the graph.
For a join of two graphs of size \m{m,n}, we can add any term \m{t} to both graphs and get the full equivalence class of \m{t} at the join at O(\m{(m+\size{t}) \times (n+\size{t}))} time.

However, it is not immediately clear which terms should be added at which join - consider:
\begin{lstlisting}[caption={join indirect congruence closure},label=snippet3.7]
	if (*)
		assume a=b
	else
		assume f(a)=f(b)
$p_j:$
	if (*)
		assert g(f(a))=g(f(b)) //negated g(f(a)) $\neq$ g(f(b))
	else
		...
\end{lstlisting}

Here it seems clear that \m{g(f(a)),g(f(b))} should be added, but consider:
\begin{lstlisting}[caption={join indirect congruence closure DSA},label=snippet3.8]
	if (*)
		assume a=b
	else
		assume f(a)=f(b)
$p_j:$
	assume $\m{a_1}$ = a
	assume $\m{b_1}$ = b
	if (*)
		$p_t:$
		assert $\m{g(f(a_1))=g(f(b_1))}$ //negated $\m{g(f(a_1)) \neq g(f(b_1))}$
	else
		...
\end{lstlisting}

Here we need to translate the terms \m{g(f(a_1)),g(f(b_1))} through \\
 \m{a_1=a,b_1=b} in order to derive the set of terms which would have to be added to the joinees of $p_j$ in order to be able to prove the assertion.
Consider also:
\begin{lstlisting}[caption={join indirect congruence closure loop},label=snippet3.9]
	if (*)
		assume $\m{a=b}$
	else
		assume $\m{a=f(f(b))}$
		assume $\m{a=f(a)}$
$p_j:$
	if (*)
		$p_t:$
		assume $\m{a=f(a)}$
		assume $\m{b=f(b)}$
		assert $\m{g(a)=g(b)}$ //negated $\m{g(a) \neq g(b)}$
	else
		...
\end{lstlisting}

Here, all of the terms $\m{g(f^i(a))}$ at $p_j$ would map to $\m{g(a)}$ at $p_t$, although only the set \m{g(a)} is need at the else branch, the entire set $\m{g(f^i(a))}$ is potentially needed at the then branch.
Even when the needed set is finite, it could be large - consider:
\begin{lstlisting}[caption=congruence closure source quadratic,label=snippet3.10]
	if (*)
		assume $\m{a=b}$
		assume $\m{c=d}$
		assume $\m{f(a,a)=e}$
		assume $\m{f(a,d)=e}$
		assume $\m{f(d,a)=e}$
		assume $\m{f(d,d)=e}$
	else
		assume $\m{a=c}$
		assume $\m{b=d}$
		assume $\m{f(c,c)=e}$
		assume $\m{f(c,b)=e}$
		assume $\m{f(b,c)=e}$
		assume $\m{f(b,b)=e}$
$p_j:$
	if (*)
		$p_t:$
		assume $\m{a=b=c=d}$
		assert $\m{f(a,a)=e}$ //negated $\m{f(a,a) \neq e}$
	else
		...
\end{lstlisting}
Here we have 16 options for terms which we could add to the join to get the assertion proven, each of which would suffice.

We have experimented with several methods for determining which terms to add to a join in order to make later assertions provable, as will be described later, but, as we have seen above, in order to ensure polynomial complexity we cannot allow the ground unit fragment to deduce even all equalities at a join and hence we choose a subset of these and the rest of the information is encoded as (in)equalities guarded by the branch condition that is joined at the node, and later equalities (as in above a=b=c=d) can allow simple resolution steps to deduce the rest - in example ~\ref{snippet3.10}, using \m{p} as the joined branch condition, this could be:\\
$\m{\lnot p \lor a=b}$\\
$\m{\lnot p \lor c=d}$\\
$\m{p \lor a=c}$\\
$\m{p \lor b=d}$\\
$\m{f(a,a)=e}$\\
$\m{f(a,d)=e}$\\
$\m{f(d,a)=e}$\\
$\m{f(d,d)=e}$

Which is complete and gives us a linear sized join.

For an example where the minimal term is of quadratic size (m,n co-prime):
\begin{lstlisting}[caption=congruence closure source quadratic depth,label=snippet3.11]
	if (*)
		assume $\m{b=f^m(a)}$
		assume $\m{b=f^m(b)}$
		assume $\m{b \neq g(b)}$
	else
		assume $\m{c=f^n(a)}$
		assume $\m{c=f^n(c)}$
		assume $\m{c \neq g(c)}$
$p_j:$
	//Here $\m{f^{2mn}(a)=f^{mn}(a)}$
	//  and $\m{f^{mn}(a) \neq g(f^{mn}(a))}$
	if (*)
		$p_t:$
		assume $\m{a=f(a)}$
		assert $\m{a \neq g(a)}$ //negated $\m{a=g(a)}$
	else
		...
\end{lstlisting}

Here falling back to guarded equalities would get:\\
$\m{\lnot p \lor a=f^m(a)}$\\
$\m{\lnot p \lor f^{2m}(a)=f^m(a)}$\\
$\m{\lnot p \lor f^{m}(a)\neq g(f^{m}(a))}$\\
$\m{      p \lor a=f^n(a)}$\\
$\m{      p \lor f^{2n}(a)=f^n(a)}$\\
$\m{      p \lor f^{n}(a)\neq g(f^{n}(a))}$

Which, at $p_t$, would be reduced by congruence closure to:\\
$\m{a=f(a)}$\\
$\m{\lnot p \lor a=a}$\\
$\m{\lnot p \lor a=a}$\\
$\m{\lnot p \lor a \neq g(a)}$\\
$\m{      p \lor a=a}$\\
$\m{      p \lor a=a}$\\
$\m{      p \lor a\neq g(a)}$

Now tautology elimination would leave:\\
$\m{a=f(a)}$\\
$\m{\lnot p \lor a \neq g(a)}$\\
$\m{      p \lor a\neq g(a)}$

And then the reducing resolution we have seen in the previous chapter would leave us with:\\
$\m{a=f(a)}$\\
$\m{a \neq g(a)}$

Which is sufficient to prove the assertion.

Note that if we want to construct an example where the minimal interpolant at a join is exponential in depth (as opposed to size, that was shown in ~\cite{GulwaniNecula07}) by cascading joins as in the above example, we would need to show that for some integer c, for any n, there are at least n pairwise co-prime integers whose sum is less than \m{nc} and whose product is at least \m{2^n} - we have not been able to establish this property.

To summarize the complexity discussion: 
We have seen that for some programs joins can reduce the verification runtime exponentially, while in other cases either a join does not exist as a set of equalities, or it could be of exponential size or at least quadratic depth or size when represented as a set of equalities, even if the Hoare proof is linear in size.
Furthermore, in order to ensure overall polynomial complexity, when calculating a join, we need to make sure that we reject both terms that are too deep, terms whose representation is too large and too many equivalence classes.

All the above-mentioned algorithms discussed a monolithic congruence closure data structure that can be built gradually by adding  equalities. As we are interested in using such a structure as the basis for a gradual prover at each CFG node, we would need, in addition, a method in which these structures can communicate - for example, if we first use congruence closure on all nodes, 
then apply one step of resolution, we might discover new equalities at some of the nodes - each such node would need to communicate these equalities to all of its successors, including through joins. 
In order to maintain good performance, we must make sure that such incremental updates are communicated between nodes incrementally, and no join or meet are recalculated.

\newpage
\section{Information Propagation}
The pre- and post-conditions defined in the previous section (including non-unit clauses) are, in a sense, strongest post-conditions, so a CFG node is infeasible iff its post-condition is unsatisfiable.

However, in many cases the above formulation propagates much more information than is needed - essentially, if a CFG has one assertion at the end of the method, the precondition for that assertion would be the encoding of the transition relation of the whole method.
This means that little is gained in comparison with whole method VCG.

In this section we will show how to optimize the propagation of information so that we are guaranteed that each node has enough information to show infeasibility if it is infeasible (completeness), 
while reducing the information propagated as much as possible (locality),
reducing the number of propagation operations (efficiency),
and avoiding applying the same inference more than once (sharing).

We will start by discussing propagation on the simplest linear program, with only the unit ground equality fragment, 
and later expand to tree and eventually DAG shaped CFGs, 
and the interaction of propagation with the application of other logical fragments.

One way to attack the locality problem is to use scoping, so that the precondition of each node only contains clauses with the latest DSA versions of only variables in scope. Using scoping means we need to calculate an interpolant between the disjunction of the post-conditions of the direct predecessors of the assertion node and the clauses of the assertion node. Already in the propositional case this could lead to an exponential explosion, but in many cases could also bring a drastic reduction in the size and complexity of the pre-condition. 
Hence, as our aim is efficient proof search, we will use interpolants and scoping only in cases where we can ensure that it will not increase the size of the problem, and otherwise ensure that the post-conditions can at least be propagated so that the size of the pre-condition of any node is linear in the total size of the clauses of all its transitive predecessors - so the total size of all pre-conditions for a given CFG is of at most quadratic space complexity.

Both with and without interpolation, not always all the information of all transitive predecessors is necessary in order to prove each assertion.
In the propositional case, we used the resolution calculus in order to filter which clauses needed to be propagated - basically we would only propagate a clause to a node if it has a literal that appears negated at that node.
If we add ordering restrictions to resolution, so that each ground clause has exactly one maximal literal, and allow resolution only on maximal literals, then we only need to propagate clauses to a node whose maximal literal appears negated as a maximal literal at the node.
We will discuss the non-ground case in chapter about non-ground clauses.

\subsection{Clause propagation criteria}
Let us inspect the superposition calculus, now with ordering and restricted to units:\\
$
\vspace{20pt}
\begin{array}[c]{lcl}
\vspace{20pt} \mbox{resolution}&
	\vcenter{\infer[\m{res}]{\m{\emptyClause}                               }{\m{s=t } & \m{s \neq t}}} \\
\vspace{20pt} \mbox{equality resolution} &
	\vcenter{\infer[\m{res_{=}}]{\m{\emptyClause}                               }{\m{s\neq s}}} \\
\vspace{20pt} \mbox{superposition equality}  & 
	\vcenter{\infer[\m{sup_{=}}]{\m{\termRepAt{s}{r}{p} =    t}}{\m{l=r} & \m{\termRepAt{s}{l}{p} =    t}}} & 
	\parbox[c][1cm]{3cm}{\m{l \succ r,s \succ t}\\\m{s=t \succ l=r}}\\
\vspace{20pt} \mbox{superposition inequality} & 
	\vcenter{\infer[\m{sup_{\neq}}]{\m{\termRepAt{s}{r}{p} \neq t}}{\m{l=r} & \m{\termRepAt{s}{l}{p} \neq t}}} & 
	\parbox[c][1cm]{3cm}{\m{l \succ r,s \succ t}}\\
\vspace{20pt} \mbox{simplification}  & 
	\vcenter{\infer[\m{smp}]{\m{\termRepAt{s}{r}{p} \bowtie t}}{\m{l=r} & \cancel{\m{\termRepAt{s}{l}{p} \bowtie t}}}} & 
	\parbox[c][1cm]{3cm}{\m{l \succ r}}\\
\vspace{20pt} \mbox{tautology deletion}  & 
	\vcenter{\infer[\m{tau}]{}{\cancel{\m{s=s}}}} & 
	\parbox[c][1cm]{3cm}{}\\
\end{array}
$

Note that if we apply simplification eagerly, no superposition will take place.
However, this holds only for the unit case (although ~\cite{BachmairGanzinger94} does contain an extension of simplification to the non-unit case) and furthermore, simplification is not necessary for completeness, so we use the side conditions of the superposition inferences to decide which clauses need to be propagated, which would extend to the non-unit case without much modification.

For a node \m{n}, where \m{l=r \in \clauses{n}} and \m{l \succ r}, we would need to propagate from predecessors any clause of the form:
\begin{itemize}
	\item \m{l \neq r}
	\item \m{s = t} where \m{\termAt{l}{p} = s}, \m{s \succ t}, \m{l=r \succ s=t}    (sub-terms of \m{l})
	\item \m{s \bowtie t} where \m{\termAt{s}{p} = l}, \m{s \succ t}, \m{s \bowtie t \succ l=r} (super-terms of \m{l})
\end{itemize}
When \m{s \neq t \in \clauses{n}} and \m{s \succ t}, we would need:
\begin{itemize}
	\item \m{l = r} where \m{\termAt{s}{p} = l}, \m{l \succ r} (includes also \m{s=t})
\end{itemize}

Assuming we have a tree shaped CFG, we can use the above to verify our program.
We will use the predicate \m{relevant(c_1,c_2)} to denote that the (unit) clause \m{c_2} is relevant for \m{c_1}, as defined above.
For a tree shaped CFG there are no path conditions, so if all clauses are unit so are all relative clauses.
We denote by \m{inferences(c,S)} all the conclusions of inferences of the above calculus between a clause \m{c} and a clause \m{c' \in S
}.

\begin{figure}
\begin{lstlisting}
verify(cfg) : Set of unverified assertions
	Foreach node n in topological order
		done = $\emptyset$
		todo.enqueue( $\clauses{n}$ )
		while todo not empty
			c = todo.dequeue
			done.add(c)
			for $\m{p} \in \predsto{n}, \m{c'} \in \m{p.done}$
				if $\m{relevant(c,c')}$
					if $\m{c' \notin done}$
						todo.enqueue($\m{c'}$)
			for $\m{c' \in \m{inferences(c,done)}}$
				if $\m{c' \notin done}$
					todo.enqueue($\m{c'}$)
		if ($\emptyClause \notin\in$ done)
			result.add(n)
\end{lstlisting}
\caption{Verification algorithm, version 1}
\label{verification_algorithm_v1}
\end{figure}

This algorithm will terminate if the underlying calculus will (which it will in our case) and is complete (returns the empty set if the program is correct) if the calculus is complete (which again it is).

We will say that a clause is \emph{imported} to \node{n} if it was propagated from a predecessor of \m{n}, 
even if it was also derived in \m{n} or originally in \clauses{n}.

We can immediately see several possible improvements:
\begin{itemize}
	\item If a non leaf node produces the empty clause, we do not need to consider any of its transitive successors
	\item As in the propositional case, we want to reduce the number of searches for relevant clauses in predecessors, and so we can import recursively where each node imports only from direct predecessors, and cache at each node the result of each search in order to prevent redundant CFG traversals - we will elaborate on this in the following.
	\item If we apply the above and import recursively from direct predecessors only, each such predecessor could apply simplifications on imported clauses, so that if the clause is propagated to both sides of a branch but can be simplified already at the branch it will be simplified only once.
	\item We can mark each imported clause and avoid derivations where all the premises are imported, 
	as this derivation will have been performed in the latest transitive predecessor where both clauses existed, and the conclusion will be propagated if necessary.
	This ensures that, on each path from root to a leaf, each derivation can only happen once, unless one side of the derivation is derivable through more than one derivation tree, which means that it will be performed only once for both sides of a branch if all premises exist at the branch.
	\item We can bunch up several predecessors queries into one, for example, we could initially import all relevant clauses for \clauses{n} and mark in the \lstinline{todo} queue the point until which all clauses are imported, and then whenever we dequeue the clause at the marked point, we import relevant clauses for all of the \lstinline{todo} queue and again mark the end point.
	\item We may want to perform simplification inferences also on \lstinline{todo}, so that only simplified clauses are processed, and the same for cheap redundancy elimination (e.g. pure literal elimination)
	\item If saturating the set of clauses in the calculus can have a higher time complexity than we want to allow (as it will in all other fragments), we could limit inferences and clause propagations to some sub-fragment with acceptable complexity (e.g. resolutions that produce clauses up to some width) and gradually increase the sub-fragment until we reach the full fragment, for theoretical completeness. 
\end{itemize}


\textbf{Superposition Based Propagation:}
Considering the definition of relevance, we should support the following recursive queries:
\begin{itemize}
	\item For a clause \m{l=r} where \m{l \succ r}:
		\subitem \m{l \neq r}
		\subitem \m{s = t} where \m{\termAt{l}{p} = s}, \m{s \succ t}, \m{l=r \succ s=t}
		\subitem \m{s = t} where \m{\termAt{s}{p} = l}, \m{s \succ t}, \m{s=t \succ l=r}
		\subitem \m{s \neq t} where \m{\termAt{s}{p} = l}, \m{s \succ t}
	\item For a clause \m{l \neq r} where \m{l \succ r}:
		\subitem \m{s = t} where \m{\termAt{l}{p} = s}, \m{s \succ t} 
\end{itemize}
We can create a query containing \m{l \bowtie r} and send it recursively to the transitive predecessors, where each node caches the clauses queried and also, as suggested above, adds the imported clauses and saturates them so they end up in the \m{done} set.
This would ensure that a node never propagates the same query twice.
However, note that for queries regarding \m{l=r}, \m{r} is only used for ordering constraints (except for the first sub-bullet).\\
For the second sub-bullet, we know that \m{l \succ r},
so if \m{l=r \succ s=t} (assuming any \m{s=s} is deleted), 
then either \m{l \succ s} or \m{l = s \land r \succ t}.\\
For the third bullet we want all equalities such that either \m{s \succ l} or \m{s = l \land t \succ r}.\\
We can divide the clauses at a node to three groups: \emph{original} - \clauses{n}, \emph{imported} - \precond{n} and \emph{derived}
As stated earlier we do not need to perform superposition between clauses that are both imported, as it will have been performed in a transitive predecessor.\\
Combining the above, our superposition import condition would be:
\begin{itemize}
	\item For \m{l=r} where \m{l \succ r}:
		\subitem \m{s=t} s.t. \m{s \succ t},\m{s=\termAt{l}{p}} or \m{l=\termAt{s}{p}}
		\subitem \m{s\neq t} s.t. \m{s \succ t},\m{l=\termAt{s}{p}}
	\item For \m{l \neq r} where \m{l \succ r}:
		\subitem \m{s=t} s.t. \m{s \succ t}, \m{\termAt{l}{p} = s}
\end{itemize}
\m{r} plays no role in determining the set of relevant clauses.

This is good news because it means we can build a query made of just the larger term in each inequality, and the cache at each node will remember exactly those terms that have been queried, so each query and each cache entry \m{l} is valid for all equalities \m{l=r} where \m{l \succ r}.

\textbf{Congruence Closure Based Propagation:}
Even for a large set of equalities without any inequality,
many superposition derivations can take place, although the set is trivially satisfiable.
More generally, even in a set with inequalities, we can find a subset of the equalities that is sufficient to show a refutation if there is one:\\
We can create a graph where nodes are function symbols, and an edge between any two function symbols that appear in the same equality, 
we can drop all equalities that have symbols only in connected components where no inequality has any symbol.\\
Completeness is not affected because we have two sets of clauses with disjoint signatures, 
and all derivations in the unit ground superposition calculus require the premises to share at least one symbol, 
so we can saturate each set of clauses independently. 
All derivations that produce the empty clause involve an inequality, so the set without inequalities cannot contribute to the proof.\\
This is a step in the direction of a goal directed algorithm - if we consider inequalities as goals to be refuted.
In the above conditions for a query \m{l}, we have to propagate any equality on any super-term of \m{l} - this could mean many irrelevant equalities, as opposed to inequalities which could potentially all be relevant.


\subsection{Congruence Closure Graphs}
We will define now a congruence closure graph data structure that we will form the basis of the verification algorithm, 
and also the basis of complexity calculations. Each node in the graph is an equivalence class of terms.\\
Each node in the graph is labeled with a set of pairwise disjoint set of \emph{ground function application equivalence classes} that we term \GFAEC. Each such \GFAEC is of the form \fa{f}{n} where \m{f} is a function symbol in the signature and \tup{n} is a tuple of nodes in the graph. Each \GFAEC appears at most once in the graph - this ensures that the graph is a partition of terms.\\
The terms represented in the graph are defined as follows: for a term \fa{f}{t} and a node \m{n}:\\
\m{\fa{f}{t} \in n \equivdef \exists \tup{m} \in g \mid \fa{f}{m} \in n \land \bigwedge\limits_i t_i \in m_i}\\
This definition is recursive but is well defined as the recursion is well founded (by definition of terms).\\
We then define the terms in the graph:\\
\m{t \in g \equivdef \exists n \in g \mid t \in n}\\
The sets of terms of a node, and the whole graph:\\
\m{\terms{n} \triangleq \s{t \mid t \in n}}\\
\m{\terms{g} \triangleq \cup \s{\terms{n} \mid n \in g}}\\
\m{\GFAECs{g} \triangleq \cup \s{n \mid n \in g}}\\
\m{g(t)} is a partial function that represents the node that represents the equivalence class of \m{t}, defined as:\\
\m{g(t) = n} iff \m{t \in n \land n \in g}\\
To show that this is well defined we need to show that \\
\m{\forall t \in \terms{\sig} \cdot \forall m,n \in g \cdot t \in m \land t \in n \Rightarrow m=n )}\\
This we show by induction on the depth of \m{t}: for a constant term \m{c}, of (depth 1), 
\m{c \in n} iff \m{c() \in n}, and similarly for \m{m}. As nodes are pairwise disjoint sets of \GFAECs{} this means \m{m=n}.\\
For depth \m{k+1} and term \fa{f}{t}, we know from i.h. that \\
\m{\forall i \cdot (t_i \in m' \land t_i \in n' \Rightarrow m'=n')}.
If \m{t \in m \land t \in n} then, by definition there are \tup{m'},\tup{n'} s.t. \m{\fa{f}{m'} \in m \land \fa{f}{n'} \in n} and
\m{\bigwedge\limits_i t_i \in m'_i} and \m{\bigwedge\limits_i t_i \in n'_i}.
By the induction hypothesis this implies that \m{m' = n'} (tuples are equal iff they are of the same length and equal for all indices).\\
This implies \m{\fa{f}{m'}=\fa{f}{n'}} (\GFAECs{} are equal iff the function symbol and tuple are equal).\\
By the pairwise disjointness of nodes we get \m{m=n}.\\
\m{g \models s=t} when \m{s,t \in g} and \m{g(t)=g(s)}, extended in the standard way for tuples and sets.\\
\m{g \models s \neq t} iff \m{s,t \in g} and there is an edge in \m{g} between \m{g(t)} and \m{g(s)}.\\
\m{g \models \emptyClause} iff, for some \m{l,r}, \m{g \models l=r} and \m{g \models l \neq r}.\\
To represent an EC graph as a minimal set of equations we need a representative \GFAEC for each node, 
and then the set of equalities is exactly equalities between the representatives of \GFAECs at each node.\\
We choose always the representative of least weight, and among them by an arbitrary order on terms (unrelated to the one for superposition) - formally:\\
\m{\eqs{g} \triangleq \cup \s{\eqs{n} \mid n \in g}}\\
\m{\eqs{n} \triangleq \s{s=t \mid s,t \in gfareps(n) \land t = min_{<_{rep}}(gfareps(n) \setminus \s{s})}}\\
\m{gfareps(n) \triangleq \s{gfarep(\fa{f}{s}) \mid \fa{f}{s} \in n}}\\
\m{gfarep(\fa{f}{s}) \triangleq \fa{f}{rep(s)}}\\
\m{gfarep(\fa{f}{}) \triangleq \fa{f}{}}\\
\m{rep(n) \triangleq min_{weight,<_{rep}}(gfareps(n))} \\
\m{weight(\fa{f}{t}) \triangleq 1+\Sigma_i weight(t_i)}\\
Where \m{min_{weight,<_{rep}}} is the minimum in lexicographic order, first on weight then on the arbitrary term order\\
This is well defined as the weight ordering implies that a term is always smaller than super-terms and hence a cyclic term would never be a representative.

\bigskip
\noindent
\textbf{Properties:}\\
\textbf{Consistency:} The graph is called consistent iff \m{g \not\models \emptyClause}.\\
\textbf{Sub-term closure:} The graph is by definition sub-term closed, as a term is in the graph only if all direct sub-terms are.\\
\textbf{Congruence closure:} The graph is by definition congruence closed, by the uniqueness of \GFAECs{}

\bigskip
\noindent
\textbf{Operations:}\\
\textbf{Constructor:} The constructor takes a set of axioms and \lstinline{assumes} them.\\
\textbf{Assume:} Assuming an axiom \m{s \bowtie t} means \lstinline{add}ing \m{t,s} to \m{g} and then:\\
For \m{s \neq t} we add an (undirected) edge between \m{g(s)} and \m{g(t)}. \\
For \m{s = t} we proceed as follows:
\begin{lstlisting}
assume( $\m{s=t}$ )
	ns = add(s)
	nt = add(t)
	mergeSet($\s{ns,nt}$)
	
mergeSet(S0 : Set[Node])
	mergeOnce(S0)
	while not all nodes are pairwise disjoint
		S = choose all nodes that share a $\GFAEC$
			mergeOnce(S)
	
mergeOnce(S : set of node)
	n = $\cup$ S 
	remove S from nodes
	add n to nodes
	foreach node $\m{m \in g}$
		replace each $\m{\fa{f}{s} \in m}$
			with $\m{\fa{f}{s}[S \mapsto n]}$
	replace each edge \m{(m,m')}
		with $\m{(m,m')[S \mapsto n]}$
\end{lstlisting}
We use the syntax 
\m{n[m \mapsto l]} 
for nodes \m{m,n,l} to define substitution similar to term substitution - formally:\\
\m{n[m \mapsto l] \triangleq \ite{m \equiv n}{l}{n}}\\
The set extension:\\
\m{n[S \mapsto l] \triangleq \ite{n \in S}{l}{n}}\\
And tuples:\\
\m{\tup{s}[S \mapsto l]_i \triangleq s_i[S \mapsto l]}\\
\lstinline{mergeOnce} performs essentially congruence closure, as seen by the loop condition.\\
The important property for \lstinline{mergeSet} is that it never adds new nodes or \\
\GFAECs{}, 
only replaces existing ones, so the complexity of the graph (as measured by number of nodes and \GFAECs{}) does not increase.\\
However, each merge can potentially 
Also, no terms are removed, only added. \\
\textbf{Add term:} Adding a term \m{t} to the graph is defined recursively as follows:
\begin{lstlisting}
add( $\fa{f}{s}$ : Term ) : Node
	m = add($\tup{s}$) //tuple extension
	if $\m{\fa{f}{m} \in n}$ for some $\m{n \in g}$
		return n
	else
		n = add new node $\s{\fa{f}{m}}$
		return n
\end{lstlisting}
The above code maintains the invariant that nodes are pairwise disjoint.\\
By definition also \lstinline{$\fa{f}{s} \in $add($\fa{f}{s}$)} at the post-state.

\noindent
\textbf{Satisfiablity using congruence closure:}\\
We can use the above graph to check the satisfiability of a set of unit ground (in)equalities (axioms) by \lstinline{assuming} all axioms and checking if the graph is consistent.\\
However, we want to use only a subset of the axioms that are guaranteed to suffice to show inconsistency iff the axioms are inconsistent.\\
We know that any set of only positive equalities is consistent, so we start with all inequalities and gradually add equalities on sub-terms until we get an inconsistency, or there are no more axioms to add:

\begin{lstlisting}
unsat(axioms)
	if $\m{\emptyClause \in axioms}$ return true
	S := new Set($\s{s \neq t \mid s \neq t \in axioms}$)
	g := new EC graph
	g.assume(S)
	do
		if g is inconsistent
			return true
		ns = $\s{l=r \in axioms \setminus S \mid l \in \terms{g}}$
		foreach $\m{l=r \in ns}$//Axiom closure
			g.assume(l=r)
			S.add(l=r)
	until ns=$\emptyset$
	return false
\end{lstlisting}

As we apply the congruence closure and axiom addition until saturation, the set of equalities represented by the graph is saturated with respect to the congruence closure calculus for the axioms in the set \lstinline{s}.
\begin{theorem}
Theorem: The graph \m{g} and set \m{s} constructed for the initial set of axioms \m{Ax} satisfies 
\m{\forall l,r \in g \cdot g \models l=r \Leftrightarrow s \models l=r}

\noindent
\textbf{Proof:} \\
We will show that the set of equalities implied by the graph is saturated with respect to the calculus and includes all the equalities in \m{s}.\\
\textbf{Axioms:} Each axiom \m{l=r} in \m{s} holds in \m{g} because each such axiom is \lstinline{assume}d in \m{g}, and by the definition of \lstinline{assume}, after the \lstinline{assume} \m{g(l)=g(r)}, which is the definition of \m{g \models s=t}.\\
\textbf{Transitivity:} If \m{g \models l=t,t=r} then \m{g(l)=g(t)=g(r)} hence \m{g \models l=r}\\
\textbf{Reflexivity:} If \m{t} is a sub-term of some axiom in \m{s}, then when that axiom is \lstinline{assume}d \m{t} is added to \m{g}, and so \m{t \in g} and \m{g(t)=g(t)} hence \m{g \models t=t}\\
\textbf{Congruence Closure:} If \m{g \models \tup{s}=\tup{t}} and \fa{f}{s} is a subterm of some term \m{u} in an axiom \m{a \in s}, then after \m{a} is \lstinline{assume}d we know \m{u \in g}, because the graph is sub-term closed, we know \m{\fa{f}{s} \in g}.
\fa{f}{s} is represented (by definition) by a \GFAEC \fa{f}{m}, which also, as \m{g \models \tup{s}=\tup{t}}, represents \fa{f}{t}.
\textbf{Monotonicity:} All the above operations are monotonic in the sense that if \m{g \models s=t} in the pre-state it also holds in the post-state, and the same for \m{t \in g}.
\end{theorem}
Note that the theorem does not hold for inequalities - for example, from \\
\m{s = \s{f(a) \neq f(b)}} we will not derive \m{g \models a \neq b} - we will return to this point later.

\begin{theorem}
The graph \m{g} constructed for the initial set of axioms \m{Ax} satisfies 
\m{\forall l,r \in g \cdot g \models l=r \Leftrightarrow Ax \models l=r}

\noindent
\textbf{Proof:} \\
\textbf{Soundness:}\\
For \m{l,r \in g \land  g \models l=r \Rightarrow Ax \models l=r} :\\
By uniqueness of \GFAECs{} the graph is always a partition of the terms represented in it, so it always represents an equivalence relation. 
An equality \m{g \models l=r} in the graph be generated by:\\
\lstinline{add} Adding a new \GFAEC \fa{f}{m} for the term \fa{f}{s} to a singleton node \s{\fa{f}{m}} - so, for some \m{\tup{u},\tup{v}} where \m{\tup{u},\tup{v} \in \tup{m}}, the equality \m{l=\fa{f}{u}=\fa{f}{v}=r} was added - this is justified by congruence closure as it means \m{g \models \tup{u}=\tup{v}}.\\
\bigskip
\lstinline{assume}: The invariant of the loop in \lstinline{mergeSet} is that \\
\m{\forall l,r \in g \land \exists n \cdot l,r \in m \Rightarrow Ax \models l=r}\\
Initially, this holds as it holds for the input graph.\\
After \lstinline{mergeOnce(S0)} it holds because \m{\exists s=t \in Ax \mid S0=\s{g(s),g(t)}}, 
so if \m{g \models l=r} is established on a node merge in \lstinline{mergeOnce(S0)} it means that, at the prestate, \m{l \in \terms{g(s)},r \in \terms{g(t)}} and so \m{g \models l=s,r=t}, and hence \m{Ax models l=s,t=r} and by transitivity \m{Ax \models l=r}.
If \m{g \models l=r} is established by replacing \GFAECs{} after merging \m{g(s),g(t)} to \m{n'}, 
at the prestate \m{l=\fa{f}{u} \in \terms{m}, r=\fa{h}{v} \in \terms{n}}, \\
and \m{\tup{u} \in \terms{\tup{mm}}, \\\tup{v} \in \terms{\tup{nn}}} so that \m{\fa{f}{mm} \in m,\fa{f}{nn} \in n}, at the post-state 
\tup{mm,nn} are replaced by 
\m{\tup{mm'}==\tup{mm}[\s{g(s),g(t)} \mapsto n']} and \\
\m{\tup{nn'}==\tup{nn}[\s{g(s),g(t)} \mapsto n']} and \\
where $\fa{f}{mm'} \equiv \fa{h}{nn}$ implying \m{f = h,mm'=nn'}.
As \m{n'} is a new node, we get \\
\m{\bigwedge\limits_i (mm_i==nn_i \lor mm_i,nn_i\in\s{g(s),g(t)})} \\
Putting it all together we get \m{\bigwedge\limits_i (Ax \models u_i==v_i)} and so \m{Ax \models l=r}.

\noindent
\textbf{Termination:} \\
\lstinline{unsat} terminates as the set \m{Axioms \setminus S} is finite and strictly decreasing in each iteration, and the loop terminates when it is empty.\\
\lstinline{mergeSet} terminates as the set of nodes of the graph strictly decreases with each iteration and is finite.

\noindent
\textbf{Completeness:}\\
For \m{l,r \in g \land Ax \models l=r \Rightarrow g \models l=r}:\\
By contradiction, assume that for some \m{l,r \in g}, \m{Ax \models l=r}, but \m{g(l) \neq g(r)}.
As the congruence closure calculus is complete for \terms{Ax}, assume that there is a derivation \m{D} in the calculus for \m{l=r}.\\
We select a conclusion \m{u=v} of a sub-derivation \m{D'} of \m{D} where \m{u \in g} and \m{g \not\models u=v}, and where \m{D'} is minimal in that sense - the conclusions of all sub-derivations of \m{D'} are either implied by \m{g} or both terms are not in \m{g}.\\
By case analysis on the derivation at the root of \m{D'}:\\
\textbf{Axiom:} If \m{u=v \in Ax} and \m{u \in g} then \m{u=v} was \lstinline{assumed} by the termination condition for \lstinline{unsat} and so \m{u=v \in s} and hence \m{g(u)=g(v)} after the call \lstinline{mergeSet(S0)}.\\
\textbf{Reflexivity:} If \m{u \in g} then \m{g \models u=u} by definition.\\
\textbf{Transitivity:} If \m{u \in g} and \m{D'} includes proper sub-derivations for \m{u=t,t=v} for some \m{t}, then by the minimality of \m{u=v} we know \m{t \in g} and \m{g \models u=t} and similarly \m{v \in g} and \m{g \models t=v} - hence \m{g(u)=g(t)=g(v)} and so \m{g \models u=v}.\\
\textbf{Congruence Closure:} If \m{v=\fa{f}{t}} and \m{u=\fa{f}{s} \in g} and \m{D'} includes proper sub-derivations for \m{s_i=t_i} then by minimality \m{g \models \tup{s}=\tup{t}} and hence \m{g(\tup{s})=g(\tup{t})} and so \m{\fa{f}{g(s)}=\fa{f}{g(t)}} and by the pairwise disjointness of the nodes in the graph we know that \m{g(u) \ni \fa{f}{g(s)}=\fa{f}{g(t)} \in g(v)} which implies \m{g(u)=g(v)}.

\end{theorem}

\begin{theorem}
The graph \m{g} constructed for the initial set of axioms \m{Ax} satisfies \\
\m{Ax \vdash l \neq r \Leftrightarrow g \models l \neq r}

Note that \m{Ax \vdash l \neq r} is not equivalent to \m{Ax \models l \neq r}, for example, from \m{f(a) \neq f(b)} we cannot derive \m{a \neq b}, but the congruence closure calculus is refutationally complete - that is:\\
\m{Ax \vdash \emptyClause \Leftrightarrow Ax \models \emptyClause }

\noindent
\textbf{Proof:}

\noindent
\textbf{Soundness:}\\
The proof is similar to the proof for equalities except that we do not have a congruence closure - the transitivity axiom is the same for both polarities.

\noindent
\textbf{Completeness:}\\
Assuming \m{Ax \vdash l \neq r} so we have a derivation \m{D} for \m{l \neq r} from \m{Ax}.\\
Again we choose the minimal sub-derivation \m{D'} of \m{D} such that\\
 \m{root(D)=u \neq v}, 
\m{g \not\models u \neq v} and for all sub-derivations of \m{D'} with an inequality at the root the inequality is also implied by \m{g}.\\
The proof proceeds as for equalities, except that there is no congruence closure case.
\end{theorem}

\begin{theorem}[caption={Refutational Completeness}]
The graph \m{g} constructed for the initial set of axioms \m{Ax} satisfies \\
\m{Ax \models \emptyClause \Leftrightarrow g \models \emptyClause}

\noindent
\textbf{Proof:}\\
The empty clause is generated only by resolution, from the above two axioms we know that the premises for this resolution hold in the graph iff they are derivable from the axioms, and the graph is inconsistent iff such premises hold in the graph - hence by the refutational completeness of the congruence closure calculus the graph is inconsistent iff the \m{Ax} are.
\end{theorem}

This process allows us to consider only a subset of the axioms which is guaranteed to be sufficient for showing unsatisfiability -  we would want to apply the same idea when querying for equalities so that we can reduce the number of imported clauses.
So the congruence closure import condition would be:
\begin{itemize}
	\item For \m{l = r}
		\subitem \m{s=t} s.t. \m{\termAt{l}{p}=s}
		\subitem \m{s \neq t} s.t. \m{\termAt{s}{p}=l}
	\item For \m{l \neq r}
		\subitem \m{s=t} s.t. \m{\termAt{l}{p}=s}
\end{itemize}

\noindent
\textbf{Comparison of the propagation conditions:}
Inspection of the different import rules shows us that the difference is mainly that the superposition rules only taken into account the maximal (in the ordering) term in any equality, but need to consider any maximal term that is a \emph{super-term} for an equality in a successor node, while the graph based approach needs to consider both sides of an equality in order to determine whether that equality is relevant, but does not need to consider super-terms.

Essentially, the superposition based approach establishes a rewrite relation for ground terms at every node which has a unique normal form for each ground term. The relation is only partially represented (by equalities) at the node, and when a term is added to the node (either from original clauses, through a query from a successor, by quantifier instantiation or by superposition), we ensure that the relevant part of the rewrite relation is imported from predecessors.\\
This can be likened, to some degree, to Shostak theories (~\cite{Shostak84}), where we have a \emph{canonizer} for theories which rewrites every theory term to a unique normal form, and indeed some combinations of rewriting and Shostak theories have been presented (~\cite{SuperpositionModuloShostak} ). We have experimented with a very limited canonizer for arithmetic expressions which we will discuss later.\\
Our earlier tool was based only on normalizing rewriting, where the ordering was oriented so that later DSA versions of variables are larger than earlier ones, so that terms tend to get rewritten to earlier versions, and interpreted functions (e.g. arithmetic, numbers) where at the bottom of the ordering. That tool also integrated rewriting by map axioms, which required the tracking of inequalities as well.\\
The main issue we have encountered is joins - the problem is basically, given two strongly normalizing rewrite relations which agree on an ordering, and given a term \m{t}, find the normal form of \m{t} at the intersection. \\
Basically, the intersection of two strongly normalizing rewrite systems that agree with the same total well found ordering is also strongly normalizing, by the simple argument that the normal form of a term \m{t} at the intersection is the minimum of the intersection of the equivalence classes of \m{t} in each rewrite relation. We can enumerate the part of the equivalence class on each side that is less than or equal to \m{t} (finite as ordering is well founded), but in general there is no bound on the size of that part of the equivalence class, especially where separating orderings are involved (as in our case).

Another issue is that of incremental updates - once we have calculated the normal form for a term \m{t} at the join, several kinds of new information can be added from e.g. quantifier instantiation, resolution or theories. 
In order to ensure complexity bounds on the whole verification process, we want to make sure that the join calculation is incremental - that is, the complexity of calculating the join when all the information is known should help us bound the complexity of calculating the join by adding the information in any order.
The changes that might affect the join are:
\begin{itemize}
	\item A new equality is added at one or both of the joined nodes - this may or may not affect the join. To be incremental we would not want, for example, to have to recalculate the whole equivalence class of each term on each side, but just the new part of it.
	\item A new term is queried by a transitive successor - if we have already answered the query for a sub-term of the new term, we would expect to perform less work, so that the total work done in any order of querying for a set of terms will be proportional to the work done on the sub-term closure of the set as a whole.
	\item A new equality is added at the join node - this might change the previously calculated normal form of a term directly (by rewriting the normal form), or indirectly through the join - e.g. we join \m{\s{a=b} \sqcup \s{b=c}} where \m{b} is its own normal form at the join, but after learning \m{a=c} at the join the normal form for \m{b} becomes \m{a} (if the ordering is alphabetical).
\end{itemize}
The graph based approach, which we will describe in detail later, has the property that finding the join for a term includes finding the join of its sub-term closure, so that the second point is covered. 
Regarding the addition of equalities at a joined node, the modification check takes time relative to the intersection of the modified set (at the join) and the set of already queried terms, which should cover the first point.
A similar property holds for the third point, but adding such an equality might cause additional queries to predecessor nodes - for example, we have a join \m{\s{f(b)=c} \sqcup \s{f(a)=c}} and we have queried \m{f(b)} which has a singleton equivalence class, now we add \m{a=b} at the join and we have to query for \m{f(a)} which we did not do before.

In our earlier text-based tool the ordering was not fixed but determined dynamically at each node (to agree with the ordering of the previous node, plus potentially more rules), and could be incompatible between the two sides of the join, so a join was not practical.\\
We will show later that defining a global ordering that respects scoping is not trivial but possible.

\noindent
To show that the import conditions are incomparable, consider:
\begin{lstlisting}[caption=propagation condition comparison 2,label=snippet3.12]
$\m{n_1:}$
	assume f(c,e)=a
	assume g(g(c,e),g(e,c))=e
	assume g(h,h)=b
$\m{n_2:}$
	assume c=b
	assume e=d
	if (*)
		$\m{t_{a}:}$
			assert f(b,d)=a //negated $\m{f(b,d) \neq a}$
	else
		$\m{e_{a}:}$
			assert f(b,e)=a //negated $\m{f(b,e) \neq a}$
			
\end{lstlisting}

With the precedence \m{h \succ e \succ d \succ c \succ b \succ a \succ f \succ g} and kbo with the same weight for all symbols. Here:\\
\m{n_1} will not derive any new clauses.\\
\m{n_2} will import \s{f(c,e)=a,g(g(c,e),g(e,c))=e} from \m{n_1} and derive:\\
\s{c=b,e=d,f(b,d)=a,g(g(b,d),g(d,b))=d}\\
\m{t_a} will import \s{f(b,d)=a} and derive the empty clause.
\m{e_a} will import \s{f(b,d)=a,e=d} and derive the empty clause.

So \m{n_2} imported \m{g(g(c,e),g(e,c))=e}, which is clearly not usable for any refutation, but avoided importing \m{g(h,h)=b}, which is also not usable.\\
However, if \m{g(g(c,e),g(e,c))=e} were a satisfiable theory clause, while\\
 \m{g(g(b,d),g(d,b))=d} is an unsatisfiable theory clause, then these derivations are not useless, and we would need another mechanism to filter them.

If we take the graph based approach, \m{n_2} will initially not import any clause as here we only import equations on sub-terms of inequalities, \\
\m{t_{a}} will query about the terms \m{a,b,d,f(b,d)}, where the query would require importing also unordered equations on sub-terms -
so it will cause the import of \s{f(c,e)=a,g(h,h)=b} to \m{n_2} of which \m{g(h,h)=b} is useless.

To see why this is necessary consider:
\begin{lstlisting}[caption=propagation condition comparison,label=snippet3.13]
$\m{n_1:}$
	assume f(c,e)=a
	assume g(g(h))=b
	assume i(c,c)=e
	assume g(c)=c
$\m{n_2:}$
	assume g(h)=c
	assume e=d
	$\m{t_{a}:}$
		assert f(b,d)=a //negated $\m{f(b,d) \neq a}$
\end{lstlisting}

Now, with the graph based approach, \m{n_2} will initially not import anything.\\
\m{t_{a}} queries for rewrites from and to \s{a,b,d,f(b,d)}, which, at \m{n_1} are \s{f(c,e)=a,g(g(h))=b}\\
When \m{f(c,e)=a} arrives at \m{n_2}, it is simplified to \m{f(c,d)=a}, \\
When \m{g(g(h))=b} arrives at \m{n_2}, it is simplified to \m{g(c)=b}, 
which triggers the propagation of \m{g(c)=c} that gets simplified to \m{b=c}, 
which in turn simplifies \m{f(c,d)=a} to \m{f(b,d)=a}.\\
The final query response that \m{t_a} receives is \s{c=b,g(c)=b,f(b,d)=a}

So we have avoided the import of the unneeded \m{i(c,c)=e}, but if it were replaced by \m{i(c,c)=d} we would have imported it, and simplified it to  \m{i(b,b)=d} needlessly, which the superposition based case would not do. 

When comparing the process, both import criteria allowed the import of useless clauses, and it is easy to construct examples where either of the approaches imports much more than the other - there is no asymptotic separation on the number of imported clauses as for each approach we could build an example program which does not verify (assertion does not hold), but all clauses are imported.
For both approaches we were able to construct and cache queries based on one term, which allows for better caching and less redundant queries - we will base our queries mostly on term queries and literal queries for (non equality) resolution.

The situation is different, however, when joins are concerned - for example: 
\begin{lstlisting}[caption=propagation condition comparison join,label=snippet3.14]
$\m{n_1:}$
if (c1)
	$\m{n_{t1}:}$
	assume f(g(d))=e
	assume d=c
	$\m{n_{t2}:}$
	assume g(c)=b
else
	$\m{n_e:}$
	assume f(g(d))=e
$\m{j:}$
	$\m{j_a:}$
		assert f(g(d))=e //negated $\m{f(g(d)) \neq e}$
\end{lstlisting}
Where \m{d \succ c \succ b \succ a \succ e}

Here 
\m{n_{t1}} will include only the clauses \s{d=c,f(g(c))=e}\\
\m{n_{t2}} will include only the clauses \s{g(c)=b,f(b)=e}\\
\m{n_e} will include \s{f(g(d))=e}\\
So there is not enough information to perform the join unless we import \m{d=c} to \m{n_{t2}} - 
which would be triggered by importing (unordered) equations on sub-terms of inequalities (\m{d} in this case).

The reason is that, in this case, while it is valid to use simplification at \m{n_{t1}} in order to check for the infeasibility of \m{n_{t1}}, 
at \m{j} the clause \m{d=c} from \m{n_{t1}} is actually \m{\lnot c1 \lor d=c} which only allows the use of non unit ground superposition:

\[
\vspace{20pt}
\begin{array}[c]{lcl}
\vcenter{\infer[\m{sup_{=}}]{\m{\termRepAt{s}{r}{p} =    t}}{\m{C \lor l=r} & \m{\termRepAt{s}{l}{p} =    t \lor D}}} & 
	\parbox[c][2cm]{3cm}{\m{l \succ r,l=r \succ C}\\\m{s \succ t,s=t \succ D}\\\m{s=t \succ l=r}}\\
\end{array}
\]

This rule does not allow us to delete the clause \m{f(g(d))=e}, but rather keep \m{\lnot c1 \lor f(g(d))=e} and produce \m{\lnot c1 \lor f(g(c))=e}. \\
(We assume that path literals are lowest in the ordering, i.e. \m{e \succ c1}, otherwise ordered resolution would automatically produce a quadratic number of clauses at each join).

One could attempt to find an ordering that would allow ordered rewriting with simplification to work with joins, however the following example will show this is not possible with a global total ordering:

\begin{lstlisting}[caption=propagation condition ordering,label=snippet3.15]
$\m{n_1:}$
if (c1)
	$\m{n_{t1.1}:}$
	assume d=c
	$\m{n_{t1.2}:}$
	assume f(d)=a
else
	$\m{n_{e1}:}$
	assume f(c)=a
$\m{j_1:}$
	$\m{j_{1a}:}$
		assert f(c)=a //negated $\m{f(c) \neq a}$
if (c2)
	$\m{n_{t2.1}:}$
	assume d=c
	$\m{n_{t2.2}:}$
	assume g(c)=a
else
	$\m{n_{e2}:}$
	assume g(d)=a
$\m{j_2:}$
	$\m{j_{2a}:}$
		assert g(d)=a //negated $\m{g(d) \neq a}$
\end{lstlisting}

Here neither \m{d \succ c} nor \m{c \succ d} would work.
In the non unit fragment this would work with either ordering, for example, if \m{d \succ c} then 
\m{j_{1}} would find \m{f(c)=a} on both join sides, so the assertion will be verified,\\
\m{j_{2}} would not be able to join initially, but the clause \m{g(d) \neq a} at \m{j_{2a}} would trigger propagations that would give us the following set of clauses at \m{j_{2a}} \\
\s{g(d) \neq a,c2 \lor g(d)=a,\lnot c2 \lor d=c} where unit propagation would give us \\
\s{g(d) \neq a,c2,d=c,g(c) \neq a} which would trigger the propagation of \\
\m{\lnot c2 \lor g(c)=a} and then unit propagation would give us the empty clause.
We could adjust the above process so that the clause \m{g(d) \neq a} triggers the propagation of \m{d=c} only until the next join,
but it would seem that this involves many more DAG propagations than a more eager approach based on propagating all and only equivalence classes of terms mentioned at each node.

The formal definition of equality at the join \m{n_j} of \m{n_t,n_e} is \\
\m{n_j \models s=t \Leftrightarrow (n_t \models s=t \land n_e \models s=t)}, when $\clauses{n_j}=\emptyset$.

Given a term \m{t} at some node after the join node \m{n_j}, how do we find the relevant (for superposition) equalities that hold at the join? The intersection of equalities might be empty even if the intersection of non-trivial implied equalities isn't - for example, as above: \\
$\s{f(d)=f(a),b=a} \sqcup \s{f(c)=f(b),d=c}$ with \m{f \succ d \succ c \succ b \succ a}\\
Where we should be able to derive at the join \m{f(d)=f(b)} when we query for \m{f(d)}.\\
If we query (using the superposition criterion) for \s{f(d),d} (sub-term closure) - on the left and right we will get \s{f(d)=f(a)},\s{d=c} resp.

We are not aware of, and have not found, a satisfactory join algorithm for oriented rewrite systems. 
We are also not aware of the actual complexity bound, while for the (not oriented) equivalence class based case the complexity is worst case quadratic, as we will discuss later.

To summarize:\\
While both import criteria have advantages and disadvantages, in our setting we have found the congruence closure based approach to be more suitable in the unit ground equality case.
For larger fragments (non ground and/or non-unit) we will use a hybrid method, where the unit fragment will serve as a base.

\newpage
\subsection{Ground unit equality propagation}
In this section we will describe how we handle the propagation of unit equalities, 
both for proving (in)equalities at specific nodes and as the backbone for all other fragments.
We will discuss the complexity and completeness of propagation and show that it is sometimes preferable not to be complete,
and sketch an algorithm that satisfies a reduced notion of completeness while satisfying complexity bounds.

The main points are:
\begin{itemize}
	\item A definition for completeness
	\item A simple algorithm that is complete for tree-shaped CFGs
	\item A discussion of completeness for joins including
		\subitem Existence of a complete solution, 
		\subitem Worst and average case space complexity for a solution
		\subitem Examples and pragmatics in completeness vs. complexity
	\item A sketch of the algorithm with a limited notion of completeness (full algorithm in next section)
	\item Discussion of time complexity when interacting with other fragments, 
	and a mechanism to keep within complexity bounds also when interacting with other fragments
\end{itemize}

\subsubsection*{Completeness}
Completeness for the ground unit fragment could be defined using the \\
strongest post-conditions:\\
\m{\forall n \in cfg, s,t \in \terms{g_n} \cdot \postcondIII{n} \models s=t \Rightarrow g_n \models s=t} \\
Or equivalently, using paths:\\
\m{\forall n \in cfg, s,t \in \terms{g_n} \cdot (\forall P \in \paths{n}{} \cdot \clauses{P} \models s=t) \Rightarrow g_n \models s=t} \\
The definition for inequalities is similar.

However, as we have seen in example ~\ref{snippet3.5}, this condition is too strong.
Instead, we want \emph{interpolation completeness} for the fragment of ground unit equalities:\\
\m{\forall n \in cfg, s,t \in \terms{g_n} \cdot (n \models_{=} s = t \Rightarrow g_n \models s = t)}\\
This definition means that if there is a fragment interpolant \m{I_{=}} s.t. \m{I_n \models s = t} \\
and \m{s,t \in \terms{g_n}} then \m{g_n \models [s]_{g_n}=[t]_{g_n}}, and similarly for inequalities.

As we represent all information about ground (in)equalities using EC graphs, 
and as we propagate information only between adjacent nodes, 
this means that the node EC graphs form a fragment interpolant for the CFG.\\
We are looking,then, for an interpolant that is sufficient for proving all required inequalities, but minimal in some sense to reduce complexity.\\
As we have discussed regarding propagation criteria, we have chosen to propagate eagerly all equalities on sub-terms, 
and hence the interpolation completeness above implies the following condition:\\
\m{\forall n \in cfg, s \in \terms{g_n},t \in \Ts{\sig} \cdot}\\
\m{(n \models_{=} s = t \Rightarrow t \in \terms{g_n} \land g_n \models s = t)}\\
That is, if the fragment implies that a term in the graph is equal to another term, 
the other term will also be in the graph in the same EC.
Remember also that the graphs are by construction sub-term closed, and hence for any node \node{n}, 
if a term \m{t} is in \m{g_n} then we get essentially the strongest possible interpolant for the sub-term closure of \m{t} (that is, all fragment implied (in)equalities on the sub-term closure). \\
This might seem wasteful, but it has the following advantages:
\begin{itemize}
	\item It is predictable for programmers - as opposed to ordering based criteria where it might be harder for users of the tool to predict exactly which equalities should be deduced at each node
	\item It is independent of the order in which equalities are established at various nodes - 
	so that we can analyze complexity by looking only at the final result, rather than all the ways of arriving at the final result (more on this later)
	\item It makes re-establishing completeness after local changes to nodes easier, as we can derive locally the actions needed to repair completeness after changes (described at the end of the section)
\end{itemize}
The main point is that \emph{the only freedom we have in order to establish completeness is in choosing which terms appear in which node} (in the EC graph) - so the propagation algorithm will deal with determining which terms need to be added at which node.

We are interested in completeness in a setting where, on the one hand, no information needs to be forgotten (monotonicity) - which simplifies things, but on the other hand, any other fragment can introduce new (in)equalities and terms at any CFG node at any time.\\
In order to preserve completeness efficiently in this setting we will restrict somewhat the order of evaluation and enforce a backward monotonicity invariant - that is, any operation on a node is allowed to modify any of the node's transitive predecessors, but only in a monotonic way - formally:\\
For each operation on node \node{n} we denote the pre-state resp. post-state of the graph of a node \node{p} as 
\m{g_p} resp. \m{g_p'}. \\
Now each operation on \node{n} satisfies:\\
\m{\forall p \in \predst{n},s,t \in \terms{g_p} \cdot s,t \in \terms{g_p'} \land (g_p \models s = t \Rightarrow g_p' \models s = t) }\\
\m{\forall m \in cfg \setminus \predst{n} \cdot g_m'=g_m}\\
The second formula means that operations on a node \node{n} only modify the sub-DAG between the node and the root because this is the only part of the DAG involved in information propagation to \node{n} - by the definition of semantic validity by paths.\\
This is not an obvious restriction - for example, one might consider information flow to a branch point considering the terms on both sides of the branch, neither of which is in the sub-DAG of the other. \\
We have chosen to restrict the information flow criteria so that it can be calculated locally, and be robust to the addition and removal of independent branches - otherwise reasoning about complexity and completeness could become dependent on the order in which other fragments generate clauses - for example, if one side of a branch is an assertion that gets refuted at some point in the verification process, if the information flow to the other side of the branch depends on the order in which we have evaluated the branches.

\subsubsection{The Sources Function}
The $\mathbf{sources}$ function for a CFG node \node{n} links each EC node in \m{g_n} with the EC nodes in \m{g_p} for each direct predecessor \node{p} of \node{n}. It forms the backbone of the propagation mechanism.

For a given path \m{P} in the CFG we write \\
\m{\clauseseq{P} \triangleq \bigcup\limits_{p \in P} \clauseseq{p}}\\
For a path \m{P} and terms \m{s,t}, we write\\
\m{P \models s=t \equivdef \clauseseq{P} \models s=t}\\
We write \m{p.P.n} for a path that starts at \m{p} and ends at \m{n}, of length at least two (so \m{n \neq p}).

When a node \node{n} queries for the clauses where \m{t \in \terms{n}} is maximal, when the query reaches \m{p}, it must includes all \m{s \in \terms{p}} such that \m{\exists p.P.n \in cfg \mid p.P.n \models s=t}.

The function \sources{n}{p}{t} returns, for a node CFG \node{n}, direct predecessor \node{p} and a node (term equivalence class) \m{t \in g_n} , the set of nodes \m{s \in g_p} s.t. \m{\terms{t} \cap \terms{s} \neq \emptyset}.\\
For example, in ~\ref{snippet3.16b}, we would have \\
\m{sources(n_3,n_{2a},\s{b}) = \s{a,b}} \\
\m{sources(n_3,n_{2b},\s{b}) = \s{b,c}} \\
\m{sources(n_{2a},n_1,\s{a,b}) = \s{a}} \\
\m{sources(n_{2b},n_1,\s{b,c}) = \s{c}} \\
But,\\
\m{sources(n_3,n_{2a},\s{f(b)}) = \emptyset} \\
\m{sources(n_3,n_{2b},\s{f(b)}) = \emptyset} \\
Because there is no corresponding term at \m{n_{2a},n_{2b}} respectively.

Before discussing how we tackle this problem, we extend the definition of the \textbf{sources} function to tuples:\\
\m{\sources{n}{p}{\tup{s}}_i \triangleq \sources{n}{p}{\tup{s_i}}} \\
sets :\\
\m{\sources{n}{p}{S} \triangleq \bigcup\limits_{t \in S} \sources{n}{p}{t}} \\
and paths:\\
\m{\sourcesB{n}{t} \triangleq \s{t}}\\
\m{\sourcesB{p.P.n}{t} \triangleq \sourcesB{p.P}{\sourcesB{n}{t}}}\\
Where \m{n} is a singleton path and \m{p.P.n} is a path from \m{p} to \m{n}.\\
The last extension is for a (not-essentially direct) predecessor:\\
\m{\sources{n}{p}{t} \triangleq \bigcup\limits_{P \in \paths{p}{n}} \sourcesB{P}{t}}\\
For direct predecessors this coincides with the previous definition by construction.

\subsubsection{The Source Invariant}
We have the following requirements from the $\mathbf{sources}$ function, and set of terms at each node:
\begin{itemize}
	\item The sources function should be complete as per the definition above
	\item It should ensure that enough equality information is propagated so that each EC at each CFG node is complete (has all the members implied by the equality fragment), and the sources function is complete
	\item It should ensure that each node can query its transitive predecessors (recursively) for relevant clauses for resolution or superposition, by making sure that on each (or at least one) path to the transitive predecessor there are enough terms at each node to phrase the query
\end{itemize}

\subsubsection*{Source Completeness}
For ground (non-unit) clauses, we want to be able to determine whether a clause needs to be propagated from a node in which it was derived to a transitive successor node where it might participate in an inference with another clause.\\
We cannot simply look at both clauses to determine this - for example:
\begin{figure}[H]
\begin{lstlisting}
$\node{n_1}:$
	assume $\m{\underline{g(f(d))}=g(a) \lor C}$ //clause named $\m{\mathbf{E}}$, $\m{g(f(d))}$ is maximal
$\node{n_2}:$
	assume $\m{d=c}$
$\node{n_3}:$
	assume $\m{f(c)=h(b)}$
$\node{n_4}:$
	assume $\m{\underline{g(h(b))}=a \lor D}$ //clause named $\m{\mathbf{F}}$ $\m{g(h(b)) }$ is maximal
\end{lstlisting}
\caption{clause propagation sources}
\label{snippet3.16aa}
\end{figure}
Here, if we propagate \m{\underline{g(f(d))}=g(d) \lor C} to \node{n_3}, it is equivalent to (simplified to):\\
\m{\underline{g(h(b))}=g(a) \lor C}, which is valid for the ground superposition instance:\\
$
\begin{array}[c]{llll}
%\vspace{1cm}\\
\vcenter{\infer[]{\m{g(a)=a \lor C \lor D}}{\m{\underline{g(h(b))}=g(a) \lor C} & \m{\underline{g(h(b))}=a \lor D}}} 
%& \parbox[c][2cm]{3cm}{\m{g(h(b))=g(a) \succ C,g(h(b)) \succ g(a)}\\\m{g(h(b))=a \succ D,g(h(b)) \succ a}}
\\
\end{array}
$\\
But it is not obvious from inspecting just the two clauses that this inference is needed, 
as we need the equalities on the path from \node{n_1} to \node{n_4} in order to determine the relevance.
The key here is that \m{n_1.n_2.n_3.n_4 \models g(h(b))=g(f(d))}, and as \m{g(h(b))} is already simplified, and \m{g(f(d))} 
appears at \m{\mathbf{E}}, the inference is viable if \m{g(h(b))} is still maximal in the simplified version of \m{\mathbf{E}}.

We could simply propagate all clauses to \node{n_4}, simplify them accordingly and then check if the simplified version (assuming its not tautological) is relevant for any inference. We want to do better - as \m{\mathbf{F}} is already simplified, we only need to consider the maximal term there \m{g(h(b))}, and we need to consider \m{\mathbf{E}} because \m{g(f(d))} appears in it and would be simplified on the path to \m{g(h(b))}.\\
We need to consider any term that appears \m{\mathbf{E}} because simplification can change the maximal term in a clause, 
we will discuss this issue in the next chapter - in this chapter we are only interested in making sure that we can recognize 
all such clauses \m{\mathbf{E}} where a term appears that is equal to our maximal term on the path.

We will use the sources function in order to determine \\
\m{n_1.n_2.n_3.n_4 \models g(h(b))=g(f(d))} - essentially we will want to ensure that:\\
\m{[g(h(b))]_{g_{n_1}} \in \sources{n_1.n_2.n_3.n_4}{[g(h(b))]_{g_{n_4}}}}\\
that is, the EC node that represents \m{g(h(b))} at \node{n_1} is in the transitive sources of the EC node that represents 
\m{g(h(b))} at \node{n_4}.

We want to use the sources function in order to determine which clauses need to be propagated to a node, 
by propagating a query up the CFG where at each node we query about clauses containing the transitive sources of the term of interest.

In the above example, this would mean that we have to add the following terms:\\
\m{g(h(b))} to \node{n_3} (implying adding \m{g(f(c))} as they are equal there).\\
\m{g(f(c))} to \node{n_2} (implying \m{g(f(d))} as above).\\
And then the sources chain is:\\
\m{\sources{n_4}{n_3}{[g(h(b))]_{g_{n_4}}} = \s{[g(h(b))]_{g_{n_3}}}} \\
\m{\sources{n_3}{n_2}{[g(h(b))]_{g_{n_3}}} = \s{[g(f(c))]_{g_{n_2}}}} \\
\m{\sources{n_3}{n_2}{[g(f(c))]_{g_{n_2}}} = \s{[g(f(d))]_{g_{n_1}}}} \\
Assuming \m{C,D} do not contain the constants \s{a,b,c,d,e}.

It would seem that the node \node{n_4} could have enough enough information to determine whether \m{\mathbf{E}} is relevant, 
but as we will show in this section, this does not hold if there are any joins on the path.\\
Also with scoping, if each constant is in scope only between nodes where it is mentioned, 
then \m{g(f(d))} is out of scope for \node{n_4}, and so it cannot determine its relevance.

Formally, in order to ensure completeness when using the sources function for clauses we would need to ensure that:\\
\m{\forall n \in cfg,p \in \predsto{n},P \in \paths{p}{n},t \in \terms{g_n},s \in \terms{g_p} \cdot}\\
\m{\clauseseq{P} \models t=s \Rightarrow [s]_{g_p} \in \sourcesB{P}{[t]_{g_n}}}\\
This means that if two terms are equivalent on a path, and appear on the graphs on both ends of the path, then each node on the path has a term equivalent to both terms, so that these terms form an equality chain ($\mathbf{sources}$ chain) from \m{[t]_{g_n}} to \m{[s]_{g_p}}.\\
We call this condition \emph{full source completeness}.\\
We say that a CFG node is fully source complete when the sub-DAG that includes all the paths from the root to the node is source complete.
Strictly speaking we only need to ensure this property for terms \m{s} that appear in some clause in \m{p}, 
but this does not affect the actual algorithm so we omit this detail in the discussion.


\subsubsection*{Weak Source Completeness}
We will show that achieving full source completeness, although possible, is highly inefficient in some cases as it might require an exponential number of terms to be added to the EC graphs at nodes.

Instead, we will achieve a restricted form of completeness that is enough to show completeness for the ground unit fragment 
(that is, for each EC node in the graph of each CFG node, the EC is complete - it includes all the terms provable equal to it in the fragment), and in the next chapter we will show how to handle the incompleteness regarding general clauses.

Our source invariant will ensure that:\\
\m{\forall n \in cfg,t \in \terms{g_n}, s \in \Ts{\sig} \cdot} \\
\m{n \models_{=} s=t \Rightarrow s \in \terms{[t]_{g_n}}}

We will require one additional notion in order to define the local weak completeness condition on the \m{\mathbf{sources}} function.

We maintain at each CFG node \node{n} a list of \emph{rejected \GFAEC} - \rgfas{n}.\\
An \rgfa is a \GFAEC \fa{f}{s} s.t. \m{\tup{s} \in g_n} but \m{\fa{f}{s} \notin g_n}, it is used to mark the fact that there is no provable (in the fragment) equality on any of the terms of \terms{\fa{f}{s}} at \node{n}.

The \emph{weak source invariant} is formally:\\
\m{\forall n \in cfg,\fa{f}{t} \in \GFAECs{g_n} \cup \rgfas{n},p \in \predsto{n}, \tup{s} \in \sources{n}{p}{\tup{t}} \cdot}\\
\m{ \fa{f}{t} \in \GFAECs{g_p} \cup \rgfas{p}}\\
And\\
\m{\forall n \in cfg,\tup{t} \in g_n,f \in \Fs{\sig} \cdot}\\
\m{(\forall p \in \predsto{n} \cdot \exists \tup{s} \in \sources{n}{p}{\tup{t}}\cdot \fa{f}{s} \in g_p) \Rightarrow \fa{f}{t} \notin \rgfas{n})} 

Intuitively this invariant implies that two terms that appear each at the end of a path and are equal on the path will be appear in all nodes on the path \emph{if at every join on the path an equivalent term appears at every joinee}.\\
An \rgfa at a CFG node means essentially that none of the terms represented by the \rgfa appear on all paths leading to the CFG node.
This differs from the strong invariant in that we require a term to appear at the join only if it appears in \emph{all} joinees,
while the strong invariant requires it to appear if it appears in any joinee.
When a \GFAEC \fa{f}{t} is added to a graph \m{g_n}, it is automatically removed from \rgfas{n} if it was there.

The \emph{propagation invariant}  ensures that all relevant equality information is propagated locally:\\
\m{\forall n \in cfg,t \in \terms{g_n}, s \in \Ts{\sig} \cdot} \\
\m{s=t \in \sqcup_F(\eqs{g_n},\s{\eqs{g_p}}_{p \in \preds{n}}) \Rightarrow s \in \terms{[t]_{g_n}}}
Combining the propagation invariant, the weak source invariant and the fact that the empty tuple appears in all EC graphs, we will show that we can ensure \emph{weak source completeness}:\\
\m{\forall n \in cfg,p \in \predsto{n},P \in \paths{p}{n},t \in \terms{g_n},s \in \terms{g_p} \cdot}\\
\m{n \models_{=} t=s \Rightarrow [s]_{g_p} \in \sourcesB{P}{[t]_{g_n}}}

We will show in the next section an algorithm to establish both invariants and to re-establish them incrementally after modifications to a node (that is, the addition of clauses, terms or equalities).

\noindent
We want to ensure source completeness in a manner which is
\begin{itemize}
	\item Efficient: does not increase the overall worst case asymptotic complexity (space and time) of the verification algorithm compared to a minimal solution (minimal set of terms at each CFG node that ensure source completeness)
	\item Incremental: the amount of work (time complexity) for repairing completeness after a change should be proportional to the size of the change and the size of the proof of the new equalities (of a Hoare proof of the new equalities from the previously annotated CFG)
	\item Local: each step in establishing completeness, after some incremental changes to some of the node graphs, should include information from no more than a node and its immediate predecessors and successors - this allows us more flexibility to be lazy with these updates
\end{itemize}

In our setting, once source completeness is established, it can be violated by:
\begin{itemize}
	\item \lstinline{Adding} a new term to the graph at some node \node{n} which is not connected to an existing term in a transitive predecessor \node{p} (e.g. as a term in a clause learned from another fragment)
	\item Merging two term EC nodes at some node \node{n} - e.g. if we have an EC for \m{f(a)} and we \lstinline{assume} \m{a=b}, we might now have a new source that equals \m{f(b)} (e.g. as the result of a unit equality learned from another fragment)
\end{itemize}

\subsubsection{Examples}
We will show now several examples to how source completeness works in practice, the role of \rgfas{} and invariants.
We will use a graphical representation for EC graphs as shown in ~\ref{ec_graph_legend}.
We use rectangular nodes for \GTTECs and \rgtts as it simplifies representation and allows \GFAECs to share the tuples, 
and as we have used them in the implementation as well.

\begin{figure}[!htp]
%\framebox[0.5\textwidth]{
\begin{tikzpicture}
	
  \node[gttn]  (1)               {$()$};
  \node[gtn]   (2)  [above =1cm of 1] {\m{\svb{a}{b}}};
  \node[rgttn] (3)  [above =1cm of 2] {\m{\left(\svb{a}{b}\right)}};
  \node[rgtn]  (4)  [above =1cm of 3] {\m{f\left(\svb{a}{b}\right)}};

	\node[gl,align=left] (1l) [below = 0cm of 1] {
		Graph for \term{a=b}: \\ 
		\terms{g}  = \s{a,b} \\ 
		\GFAECs{g} = \s{a(),b()} \\ 
		\gtts{g}   = \s{()} \\
		\rgtts{g}  = \s{(\s{a,b})} \\
		\rgfas{g}  = \s{f(\s{a,b})}\
	};
				
	\draw[gfa] (2) to[bend right] node[el] {\m{a}} (1);
	\draw[gfa] (2) to[bend left]  node[el] {\m{b}} (1);

	\draw[rgtt] (3) to node[rl] {\m{0}} (2);
	\draw[rgfa] (4) to node[rl] {\m{f}} (3);

	\node (legendAnchor) [right = 5cm of 4] {};
	\node[gttn, below = 0.2 of legendAnchor] (gttn)  {\scriptsize a \GTTEC node - a tuple of term ECs};
	\node[rgttn,below = 0.2 of gttn ]        (rgttn) {\scriptsize an \rgtt node};
	\node[gtn,  below = 0.2 of rgttn]        (gtn)   {\scriptsize a \GTEC node - an EC of terms};
	\node[rgtn, below = 0.2 of gtn  ]        (rgtn)  {\scriptsize an \rgfa};

	\node (gfal) [below left  = 0.2 and 1 of rgtn] {};
	\node (gfar) [right      = of gfal] {A \GFAEC edge};
	\draw[gfa] (gfal) to  node[el,anchor=south] {\m{f}} (gfar);

	\node (rgfal) [below      = 0.2 of gfal] {};
	\node (rgfar) [right      = of rgfal] {An \rgtt edge};
	\draw[rgfa] (rgfal) to  node[rl,anchor=south] {\m{f}} (rgfar);

	\node (sgttl) [below    = 0.2  of rgfal] {};
	\node (sgttr) [right    = of sgttl] {A tuple \term{i}-th member edge};
	\draw[sgtt] (sgttl) to node[el,anchor=south] {\term{i}} (sgttr);
	\node (rgttl) [below    = 0.2  of sgttl] {};
	\node (rgttr) [right    =      of rgttl] {An \rgtt \term{i}-th member edge};
	\draw[rgtt] (rgttl) to node[rl,anchor=south] {\term{i}} (rgttr);

\end{tikzpicture}
%}
\caption{Equivalence class graph notation}
\label{ec_graph_legend}
\end{figure}

In figures \ref{ec_graph_example_binary_tuple}  we show some graphs with binary tuples.

\begin{figure}[H]
\centering
\begin{subfigure}[t]{0.48\textwidth}
	\framebox[\textwidth]{
	\raisebox{0pt}[0.4\textheight][0pt]
	{
		\begin{tikzpicture}
			\node(O) at (0,0){};
			\node[gttn] (1)  at (2,2.5)                      {$()$};
			\node[gtn]  (2)  [above left  =1cm and 1cm of 1] {\s{a}};
			\node[gtn]  (3)  [above right =1cm and 1cm of 1] {\s{b}};
			\node[gttn] (4)  [above =2cm of 1]               {$\s{(a,b)}$};
			\node[gtn]  (5)  [above =1cm of 4]               {$\s{f(a,b)}$};

			\node[gl,align=left] (1l) [below = 0cm of 1] {
				Graph for\s{}: \\ \terms{n} = \s{a,b,f(a,b)} \\ \tuples{n} = \s{(), (a,b)}
			};
						
			\draw[gfa] (2) to node[el] {\term{a}} (1);
			\draw[gfa] (3) to node[el] {\term{b}} (1);
			\draw[gfa] (5) to node[el] {\term{f}} (4);

			\draw[sgtt] (4) to node[el] {\term{0}} (2);
			\draw[sgtt] (4) to node[el] {\term{1}} (3);

		\end{tikzpicture}
		\label{ec_graph_example_binary_tuple1}
	}}
\end{subfigure}
\begin{subfigure}[t]{0.48\textwidth}
	\framebox[\textwidth]{
	\raisebox{0pt}[0.4\textheight][0pt]
	{
		\begin{tikzpicture}
			\node(O) at (0,0){};
			\node[gttn] (1)   at (2,2.5)                     {$()$};
			\node[gtn]  (2)  [above left =1cm and 1cm of 1]  {\s{a}};
			\node[gtn]  (3)  [above right =1cm and 1cm of 1] {\s{b}};
			\node[gttn] (4)  [above =1cm of 2]               {\s{(a,b)}};
			\node[gttn] (5)  [above =1cm of 3]               {\s{(b,a)}};
			\node[gtn]  (6)  [above =1cm of 4]               {\s{f(a,b)}};
			\node[gtn]  (7)  [above =1cm of 5]               {\s{f(b,a)}};

			\node[gl,align=left] (1l) [below = 0cm of 1] {
				Graph for \s{}: \\
				\terms{n} = \s{a,b,f(a,b),f(b,a)} \\
				\tuples{n} = \s{(), (a,b),(b,a)}
			};
						
			\draw[gfa] (2) to node[el] {\term{a}} (1);
			\draw[gfa] (3) to node[el] {\term{b}} (1);
			\draw[gfa] (6) to node[el] {\term{f}} (4);
			\draw[gfa] (7) to node[el] {\term{f}} (5);

			\draw[sgtt] (4) to node[el] {\term{0}} (2);
			\draw[sgtt] (4) to node[el,pos=0.3,anchor=west] {\term{1}} (3);

			\draw[sgtt] (5) to node[el,pos=0.3,anchor=east] {\term{1}} (2);
			\draw[sgtt] (5) to node[el] {\term{0}} (3);

		\end{tikzpicture}
	}}
	\label{ec_graph_example_binary_tuple3}
\end{subfigure}
\begin{subfigure}[t]{0.48\textwidth}
	\framebox[\textwidth]{
	\raisebox{0pt}[0.4\textheight][0pt]
	{
		\begin{tikzpicture}
			\node(O) at (0,0){};
			
			\node[gttn] (1)  at (2,2.5)                        {$()$};
			\node[gtn]  (2)  [above =1cm of 1]               {\s{a,b}};
			\node[gttn] (3)  [above =1cm of 2]               {\s{\left(\svb{a}{b},\svb{a}{b}\right)}};
			\node[gtn]  (4)  [above =4cm of 1]               {\s{f\left(\svb{a}{b},\svb{a}{b}\right)}};

			\node[gl,align=left] (1l) [below = 0cm of 1] {
				Graph for \s{a=b}: \\
				$\begin{array}{ll}
				\terms{n} & =
					\left\{
						\begin{array}{l}
							\term{a,b, f(a,a),f(a,b),} \\
							\term{f(b,a),f(b,b)}
						\end{array}
					\right\} \\
				\tuples{n} & =
					\left\{
						\begin{array}{l}
							\term{(a,a),(a,b),} \\
							\term{(b,a),(b,b)}
						\end{array}
					\right\}
				\end{array}$
			};
						
			\draw[gfa] (2) to[bend right] node[el] {\term{a}} (1);
			\draw[gfa] (2) to[bend left ] node[el] {\term{b}} (1);
			\draw[gfa] (4) to node[el] {\term{f}} (3);

			\draw[sgtt](3) to[bend right] node[el] {\term{0}} (2);
			\draw[sgtt](3) to[bend left ] node[el] {\term{1}} (2);

		\end{tikzpicture}
	}}
	\label{ec_graph_example_binary_tuple4}
\end{subfigure}
\begin{subfigure}[t]{0.48\textwidth}
	\framebox[\textwidth]{
	\raisebox{0pt}[0.4\textheight][0pt]
	{
		\begin{tikzpicture}
			\node(O) at (0,0){};
			
			\node[gttn] (1)  at (2,2.5)                        {$()$};
			\node[gtn]  (2)  [above left =1cm and 1cm of 1]  {\s{a}};
			\node[gtn]  (3)  [above right =1cm and 1cm of 1] {\s{b}};
			\node[gttn] (4)  [above =1cm of 2]               {\s{(a,b)}};
			\node[gttn] (5)  [above =1cm of 3]               {\s{(b,a)}};
			\node[gtn]  (6)  [above =4cm of 1]               {\s{f(a,b),f(b,a)}};

			\node[gl,align=left] (1l) [below = 0cm of 1] {
				Graph for \s{f(a,b)=f(b,a)}: \\
				\terms{n} = \s{a,b,f(a,b),f(b,a)} \\
				\tuples{n} = \s{(), (a,b),(b,a)}
			};
						
			\draw[gfa] (2) to node[el] {\term{a}} (1);
			\draw[gfa] (3) to node[el] {\term{b}} (1);
			\draw[gfa] (6) to node[el] {\term{f}} (4);
			\draw[gfa] (6) to node[el] {\term{f}} (5);

			\draw[sgtt] (4) to node[el] {\term{0}} (2);
			\draw[sgtt] (4) to node[el,pos=0.3,anchor=west] {\term{1}} (3);

			\draw[sgtt] (5) to node[el,pos=0.3,anchor=east] {\term{1}} (2);
			\draw[sgtt] (5) to node[el] {\term{0}} (3);

		\end{tikzpicture}
	}}
	\label{ec_graph_example_binary_tuple2}
\end{subfigure}
\caption{Binary tuples}
\label{ec_graph_example_binary_tuple}
\end{figure}

In figures \ref{ec_graph_example_cyclic}  we show some graphs with cycles.
\begin{figure}[H]
\centering
\begin{subfigure}[t]{0.48\textwidth}
	\framebox[\textwidth]{
	\raisebox{0pt}[0.4\textheight][0pt]
	{
		\begin{tikzpicture}
			\node(O) at (0,0){};
			\node[gttn] (1)  at (2,2.5)                      {$()$};
			\node[gtn]  (2)  [above =1cm of 1]               {\s{a}};
			\node[gttn] (3)  [above =1cm of 2]               {$\s{(a)}$};

			\node[gl,align=left] (1l) [below = 0cm of 1] {
				Graph for\s{\term{a=f(a)}}: \\
				\terms{n} = \s{a,f^n(a)} \\
				\tuples{n} = \s{(), (f^n(a))}
			};
						
			\draw[gfa] (2) to                            node[el] {\term{a}} (1);
			\draw[gfa] (2.225) to[out=225,in=135,looseness=2] node[el] {\term{f}} (3.135);

			\draw[sgtt](3) to node[el] {\term{0}} (2);

		\end{tikzpicture}
		\label{ec_graph_example_cyclic1}
	}}
\end{subfigure}
\begin{subfigure}[t]{0.48\textwidth}
	\framebox[\textwidth]{
	\raisebox{0pt}[0.4\textheight][0pt]
	{
		\begin{tikzpicture}
			\node(O) at (0,0){};
			\node[gttn] (1)  at (2,2.5)                       {$()$};
			\node[gtn]  (2)  [above left =1cm and 1cm of 1]   {\s{a}};
			\node[gtn]  (3)  [above right=1cm and 1cm of 1]   {\s{b}};
			\node[gttn] (4)  [above      =2.5cm       of 1]   {$\s{(a,b)}$};

			\node[gl,align=left] (1l) [below = 0cm of 1] {
				~Graph for\s{a=f(a,b),b=g(a,b)}: \\
				$\begin{array}{ll}
				\terms{n} & =
					\left\{
						\begin{array}{l}
							\term{a,b, f(a,b),} \\
							\term{g(a,b),f(f(a,b),a),} \\
							\term{g(f(a,b),b),...} \\
						\end{array}
					\right\} \\
				\tuples{n} & =
					\left\{
						\begin{array}{l}
							\term{(a,b),(f(a,b),b),} \\
							\term{(a,g(a,b)),} \\
							\term{(f(a,b),g(a,b)),...} \\
						\end{array}
					\right\}
				\end{array}$				
			};
						
			\draw[gfa] (2)     to node[el] {\term{a}} (1);
			\draw[gfa] (3)     to node[el] {\term{b}} (1);
			\draw[gfa] (2.225) to[out=225,in=135,looseness=2] node[el] {\term{f}} (4.135);
			\draw[gfa] (3.315) to[out=315,in=45, looseness=2] node[el] {\term{g}} (4.45);

			\draw[sgtt] (4) to node[el] {\term{0}} (2);
			\draw[sgtt] (4) to node[el] {\term{1}} (3);

		\end{tikzpicture}
		\label{ec_graph_example_cyclic2}
	}}
\end{subfigure}
\begin{subfigure}[t]{0.48\textwidth}
	\framebox[\textwidth]{
	\raisebox{0pt}[0.4\textheight][0pt]
	{
		\begin{tikzpicture}
			\node(O) at (0,0){};
			\node[gttn] (1)  at (2,2.5)                       {$()$};
			\node[gtn]  (2)  [above left =1cm and 1cm of 1]   {\s{a}};
			\node[gtn]  (3)  [above right=1cm and 1cm of 1]   {\s{b}};
			\node[gttn] (4)  [above      =1cm         of 2]   {$\s{(a,b)}$};
			\node[gttn] (5)  [above      =1cm         of 3]   {$\s{(b,a)}$};

			\draw[gfa] (2)     to node[el] {\term{a}} (1);
			\draw[gfa] (3)     to node[el] {\term{b}} (1);
			\draw[gfa] (2.225) to[gfa,out=225,in=135,looseness=1.5] node[el,anchor=west] {\term{f}} (4.135);
			\draw[gfa] (3.315) to[out=315,in=45, looseness=1.5] node[el] {\term{g}} (5.45);

			\draw[sgtt] (4) to node[el] {\term{0}} (2);
			\draw[sgtt] (4) to node[el,pos=0.3,anchor=west] {\term{1}} (3);
			\draw[sgtt] (5) to node[el,pos=0.3,anchor=east] {\term{1}} (2);
			\draw[sgtt] (5) to node[el] {\term{0}} (3);

			\node[gl,align=left] (1l) [below = 0cm of 1] {
				~Graph for\s{a=f(a,b),b=g(b,a)}: \\
				$\begin{array}{ll}
				\terms{n} & =
					\left\{
						\begin{array}{l}
							\term{a,b, f(a,b),} \\
							\term{g(a,b),f(f(a,b),a),} \\
							\term{g(f(a,b),b),...} \\
						\end{array}
					\right\} \\
				\tuples{n} & =
					\left\{
						\begin{array}{l}
							\term{(a,b),(f(a,b),b),} \\
							\term{(a,g(a,b)),} \\
							\term{(f(a,b),g(a,b)),...} \\
						\end{array}
					\right\}
				\end{array}$				
			};
						
		\end{tikzpicture}
		\label{ec_graph_example_cyclic3}
	}}
\end{subfigure}
\caption{Cyclic graphs}
\label{ec_graph_example_cyclic}
\end{figure}
In some cases we will ommit the curly braces to simplify the representation where it is unambiguous, 
in any case all nodes (term EC and tuple EC) always represent non empty sets of terms resp. tuples, 
and a function applied to a a vertical list of tuples represents the set of applying the function to each member of the list.

\noindent
We start with a simple example:
\begin{figure}[H]
\begin{lstlisting}
$\node{n_1}:$
	assume $\m{f(a)=g(a)}$
	//rgfas      : $\m{f(\s{b})_,g(\s{b})}$ (none with scoping)
$\node{n_2}:$
	assume $\m{a=b}$
	//extra terms: $\m{f(\s{a,b})_,g(\s{a,b})}$
$\node{n_3}:$
	assert $\m{f(b)=g(b)}$ //negated $\m{f(b) \neq g(b)}$
\end{lstlisting}
\caption{propagation sources},
\label{snippet3.16a}
\end{figure}

In ~\ref{snippet3.16a}, we would need to add \m{f(\s{a,b})_,g(\s{a,b})} to \m{g_{n_2}} in order to ensure completeness.

We show the initial state, with the propagation invariant satisfied but not the source invariant:\\
\begin{figure}[!ht]
\begin{tikzpicture}
	\node[gttn] (1)              {$()$};
	\node[gl]   (1l) [below = 0.2cm of 1] {\m{n_1}};

	\node[gtn,ultra thick]  (2) [above left  = 0.5cm and 0.2cm of 1] {\s{a}};
	\node[gtn,ultra thick]  (3) [above right = 0.5cm and 0.2cm of 1] {\s{b}};

	\draw[gfa] (2) to node[el]             {\m{a}} (1);
	\draw[gfa] (3) to[out=-90,in=90] node[el,anchor=west] {\m{b}} (1);

	\node[gttn,ultra thick] (4)  [above = 0.5cm of 2]    {\m{(a)}};
	\node[gttn,ultra thick] (5)  [above = 0.5cm of 3]    {\m{(b)}};

	\draw[sgtt,ultra thick] (4) to node[el] {\textbf{0}} (2);
	\draw[sgtt,ultra thick] (5) to node[el] {\textbf{0}} (3);

	\node[gtn]  (6)  [above = 2.5cm of 1] {\svb{f(a)}{g(b)}};
	\draw[gfa]  (6) to node[el]             {\m{f}} (4);
	\draw[gfa]  (6) to node[el,anchor=west] {\m{g}} (5);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\node[gttn] (11)  [right = 3cm of 1] {$()$};
	\node[gl,anchor=north]   (11l) [below = 0.2cm of 11]   {\m{n_2}};

	\node[gtn,ultra thick]  (12) [above = 0.5cm of 11] {\s{a,b}};

	\draw[gfa] (12) to[out=-110,in=110] node[el]             {\m{a}} (11);
	\draw[gfa] (12) to[out=- 70,in= 70] node[el,anchor=west] {\m{b}} (11);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\node[gttn] (21)  [right = 4cm of 11] {$()$};
	\node[gl]   (21l) [below = 0.2cm of 21]   {\m{n_3}};

	\node[gtn,ultra thick]  (22) [above = 0.5cm of 21] {\s{a,b}};

	\draw[gfa] (22) to[out=-110 ,in=110] node[el]             {\m{a}} (21);
	\draw[gfa] (22) to[out=- 70,in= 70] node[el,anchor=west] {\m{b}} (21);

	\node[gttn,ultra thick] (24)  [above = 0.5cm of 22]    {\m{(\s{a,b})}};

	\draw[sgtt,ultra thick] (24) to node[el] {\textbf{0}} (22);

	\node[gtn]  (26)  [above left  =  0.5cm and 0.2cm of 24] {\faB{f}{a}{b}};
	\node[gtn]  (27)  [above right =  0.5cm and 0.2cm of 24] {\faB{g}{a}{b}};
	\draw[gfa]  (26) to node[el]             {\m{f}} (24);
	\draw[gfa]  (27) to node[el,anchor=west] {\m{g}} (24);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\draw[se] (11) to  ( 1);
	\draw[se] (21) to  (11);

	\node (12a) [left = 0.3cm of 12] {};
	\node (12b) [left = 0.3cm of 12a] {};
	\node (3a) [above = 0.1cm of 3] {};

	\draw[se,ultra thick] (12.180) to (12a.0) to (12b.0) to[out=170,in=0] (3a.0) to[out=180,in=0] (2.0);
	\draw[se,ultra thick] (12.180) to (12a.0) to (12b.0) to[out=190,in=0] (3.0);
	\draw[se,ultra thick] (22) to  (12);

	\node (24a) [left = 2.9cm of 24] {\color{red}$\times$};
	\node (24b) [left = 1cm of 24a] {\color{red}$\times$};
	\node (24c) [above = 0.2cm of 24b] {\color{red}$\times$};
	\node (5c) [above = 0.7cm of 5] {};
	\draw[me] (24) to (24a);
	\draw[me] (24b) to (5);
	\draw[me] (24c) to (5c) to (4);

	\node (26a) [above = 0.6cm of 24a] {\color{red}$\times$};
	\node (26b) [above = 0.0cm of 26a] {\color{red}$\times$};
	\node (26c) [above = 1cm of 24b] {\color{red}$\times$};
	\node (26u) [above = 0.0cm of 26] {};
	\draw[me] (26.180) to (26a.0);
	\draw[me] (27.180) to (26u) to (26b.0);
	\draw[me] (26c.180) to (6.0);

	\draw[ie] (26) to node[el,below] {\m{\neq}} (27);
	
\draw[draw=none, use as bounding box] (current bounding box.north west) rectangle (current bounding box.south east);

\begin{pgfinterruptboundingbox}
	\draw[separator] (2cm,-0.7cm) to (2cm,3.8cm);
	\draw[separator] (4.5cm,-0.7cm) to (4.5cm,3.8cm);
\end{pgfinterruptboundingbox}
\end{tikzpicture}

\caption{
\scriptsize
The sources function\\
missing rgfas\\
Dashed arrows represent inequalities\\
\color{blue} Blue dashed arrows represent the $\mathbf{sources}$ function\\
\color{gray} Gray dashed arrows represent rejected sources\\
\color{red} Red dashed arrows represent missing or broken sources
}
\label{snippet3.16a_graph1}
\end{figure}

Basically two nodes should be merged if they share at least one source in each predecessor (although a slightly more involved condition is needed for propagation completeness as we will discuss in the next section).\\
In figure ~\ref{snippet3.16a_graph1} the two upper nodes in \node{n_2} share one transitive source, but are not merged - hence the incompleteness. The highlighted source path shows the tuple EC \m{(\s{a,b})} at \m{n_3} 
whose first term EC has a transitive source \m{\s{a}} at \m{n_1} with the same super-tuple, but the tuples are not connected with the source function (same for the source path to \m{\s{b}}).

We now show one failed attempt to satisfy the source invariant by adding an \rgfa:\\
\begin{figure}[!ht]
\begin{tikzpicture}
	\node[gttn] (1)              {$()$};
	\node[gl]   (1l) [below = 0 of 1] {\m{n_1}};

	\node[gtn]  (2) [above left  = 0.5cm and 0.2cm of 1] {\s{a}};
	\node[gtn]  (3) [above right = 0.5cm and 0.2cm of 1] {\s{b}};

	\draw[gfa] (2) to node[el]             {\m{a}} (1);
	\draw[gfa] (3) to node[el,anchor=west] {\m{b}} (1);

	\node[gttn] (4)  [above = 0.5cm of 2]    {\m{(a)}};
	\node[gttn] (5)  [above = 0.5cm of 3]    {\m{(b)}};

	\draw[sgtt] (4) to node[el] {0} (2);
	\draw[sgtt] (5) to node[el] {0} (3);

	\node[gtn]  (6)  [above = 2.5cm of 1] {\svb{f(a)}{g(b)}};
	\draw[gfa]  (6) to node[el]             {\m{f}} (4);
	\draw[gfa]  (6) to node[el,anchor=west] {\m{g}} (5);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\node[gttn] (11)  [right = 3.8cm of 1] {$()$};
	\node[gl]   (11l) [below = 0 of 11]   {\m{n_2}};

	\node[gtn]  (12) [above = 0.5cm of 11] {\s{a,b}};

	\draw[gfa] (12)     to[out=-110,in=100] node[el]             {\m{a}} (11);
	\draw[gfa] (12)     to[out=- 70,in= 70] node[el,anchor=west] {\m{b}} (11);

	\node[rgttn] (14)  [above = 0.5cm of 12]    {\m{f(\s{a,b})}};

	\draw[rgtt] (14) to node[rl] {0} (12);

	\node[rgtn]  (16) [above left  = 0.5cm and -0cm of 14] {\faB{f}{a}{b}};
	\node[rgtn]  (17) [above right = 0.5cm and -0cm of 14] {\faB{g}{a}{b}};

	\draw[rgfa]  (16) to node[rl]             {\m{f}} (14);
	\draw[rgfa]  (17) to node[rl,anchor=west] {\m{g}} (14);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\node[gttn] (21)  [right = 4.5cm of 11] {$()$};
	\node[gl]   (21l) [below = 0 of 21]   {\m{n_3}};

	\node[gtn]  (22) [above = 0.5cm of 21] {\s{a,b}};

	\draw[gfa] (22) to[out=-70 ,in= 70] node[el] {\m{a}} (21);
	\draw[gfa] (22) to[out=-110,in=110] node[el] {\m{b}} (21);

	\node[gttn] (24)  [above = 0.5cm of 22]    {\m{(\s{a,b})}};

	\draw[sgtt] (24) to node[el] {0} (22);

	\node[gtn]  (26)  [above left  =  0.5cm and -0cm of 24] {\faB{f}{a}{b}};
	\node[gtn]  (27)  [above right =  0.5cm and -0cm of 24] {\faB{g}{a}{b}};
	\draw[gfa]  (26) to node[el] {\m{f}} (24);
	\draw[gfa]  (27) to node[el] {\m{g}} (24);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\draw[se] (11) to  ( 1);
	\draw[se] (21) to  (11);

	\node (12a) [left = 0.5cm of 12] {};
	\node (12b) [left = 0.5cm of 12a] {};
	\node (3c)  [above = 0.1cm of 3] {};
  \draw[se] (12.180) to[out=180,in=0] ( 12a.0) to[out=180,in=0] (12b.0) to[out=180,in=0] (3c.0) to[out=180,in=0] (2.0);
  \draw[se] (12.180) to[out=180,in=0] ( 12a.0) to[out=180,in=0] (12b.0) to[out=180,in=0] (3.0);
	\draw[se] (22) to  (12);

	\node (14a) [left = 0.5cm of 14] {};
	\node (14b) [left = 0.5cm of 14a] {};
	\node (5c)  [above = 0.1cm of 5] {};
  \draw[me] (14.180) to[out=180,in=0] ( 14a.0) to[out=180,in=0] (14b.0) to[out=180,in=0] (5c.0) to[out=180,in=0] (4.0);
  \draw[me] (14.180) to[out=180,in=0] ( 14a.0) to[out=180,in=0] (14b.0) to[out=180,in=0] (5.0);
	\draw[re] (24) to  (14);

	\node (6a) [right = 0.cm of 6] {};
	\node (16c) [above = 0.cm of 16] {};
  \draw[me] (16.180) to[out=180,in=0] ( 6a.0) to[out=180,in=0] (6.0);
  \draw[me] (17.180) to[out=180,in=0] ( 16c.0) to[out=180,in=0] ( 6a.0) to[out=180,in=0] (6.0);

	\node (17c) [above = 0cm of 17] {};
	\node (17d) [below = 0cm of 17] {};
	\draw[re] (26.180) to[out=180,in=0] (17d.0) to[out=180,in=0] (16.0);
	\node (26a) [above = 0cm of 26] {};
	\draw[re] (27.180) to[out=180,in=0] (26a.0) to[out=180,in=0] (17.0);


	\draw[ie] (26) to node[el,below] {\m{\neq}} (27);

\draw[draw=none, use as bounding box] (current bounding box.north west) rectangle (current bounding box.south east);

\begin{pgfinterruptboundingbox}
	\draw[separator] (2.1cm,-0.7cm) to (2.1cm,3.7cm);
	\draw[separator] (6.5cm,-0.7cm) to (6.5cm,3.7cm);
\end{pgfinterruptboundingbox}

\end{tikzpicture}

\caption{
\tiny
The sources function\\
wrong rgfas
}
\label{snippet3.16a_graph2}
\end{figure}
Here the invariant says that an \rgfa is not allowed if one of its source is a \GFAEC - so at \m{n_2} the \rgfa \m{f(\s{a,b})} has the source \s{f(a),g(b)} at \m{n_1}, so we should have a \GFAEC at \m{n_2} and not a \rgfa.

We show now the part the propagation invariant plays:
\begin{figure}[!Ht]
\begin{tikzpicture}
  \node[gttn] (1)              {$()$};
	\node[gl]   (1l) [below = 0 of 1] {\m{n_1}};

  \node[gtn]  (2) [above left  = 0.5cm and 0.2cm of 1] {\s{a}};
  \node[gtn]  (3) [above right = 0.5cm and 0.2cm of 1] {\s{b}};
	
	\draw[gfa] (2) to node[el] {\m{a}} (1);
  \draw[gfa] (3) to node[el] {\m{b}} (1);
  
	\node[gttn] (4)  [above = 0.5cm of 2]    {\m{(a)}};
  \node[gttn] (5)  [above = 0.5cm of 3]    {\m{(b)}};

	\draw[sgtt] (4) to node[el] {0} (2);
	\draw[sgtt] (5) to node[el] {0} (3);

  \node[gtn]  (6)  [above = 2.5cm of 1] {\svb{f(a)}{g(b)}};
	\draw[gfa]  (6) to node[el] {\m{f}} (4);
  \draw[gfa]  (6) to node[el] {\m{g}} (5);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\node[gttn] (11)  [right = 3.8cm of 1] {$()$};
	\node[gl]   (11l) [below = 0 of 11]   {\m{n_2}};

	\node[gtn]  (12) [above = 0.5cm of 11] {\s{a,b}};
	
	\draw[gfa] (12) to[out=-70 ,in= 70] node[el] {\m{a}} (11);
	\draw[gfa] (12) to[out=-110,in=110] node[el] {\m{b}} (11);

	\node[gttn] (14)  [above = 0.5cm of 12]    {\m{(\s{a,b})}};

	\draw[sgtt] (14) to node[el] {0} (12);

	\node[gtn]  (16) [above left  = 0.5cm and -0cm of 14] {\faB{f}{a}{b}};
	\draw[gfa]  (16) to node[el] {\m{f}} (14);
	\node[gtn]  (17) [above right = 0.5cm and -0cm of 14] {\faB{g}{a}{b}};
	\draw[gfa]  (17) to node[el] {\m{g}} (14);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

	\node[gttn] (21)  [right = 4.5cm of 11] {$()$};
	\node[gl]   (21l) [below = 0 of 21]   {\m{n_3}};

	\node[gtn]  (22) [above = 0.5cm of 21] {\s{a,b}};
	
	\draw[gfa] (22) to[out=-70 ,in= 70] node[el] {\m{a}} (21);
	\draw[gfa] (22) to[out=-110,in=110] node[el] {\m{b}} (21);

	\node[gttn] (24)  [above = 0.5cm of 22]    {\m{(\s{a,b})}};

	\draw[sgtt] (24) to node[el] {0} (22);

	\node[gtn]  (26)  [above left  =  0.5cm and -0cm of 24] {\faB{f}{a}{b}};
	\node[gtn]  (27)  [above right =  0.5cm and -0cm of 24] {\faB{g}{a}{b}};
	\draw[gfa]  (26) to node[el] {\m{f}} (24);
	\draw[gfa]  (27) to node[el] {\m{g}} (24);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\draw[se] (11) to  ( 1);
	\draw[se] (21) to  (11);

	\node (12a) [left = 0.5cm of 12] {};
	\node (12b) [left = 0.5cm of 12a] {};
	\node (3c)  [above = 0.1cm of 3] {};
	\draw[se] (12.180) to[out=180,in=0] ( 12a.0) to[out=180,in=0] (12b.0) to[out=180,in=0] (3c.0) to[out=180,in=0] (2.0);
	\draw[se] (12.180) to[out=180,in=0] ( 12a.0) to[out=180,in=0] (12b.0) to[out=180,in=0] (3.0);
	\draw[se] (22) to  (12);

	\node (14a) [left = 0.5cm of 14] {};
	\node (14b) [left = 0.5cm of 14a] {};
	\node (5c)  [above = 0.1cm of 5] {};
	\draw[se] (14.180) to[out=180,in=0] ( 14a.0) to[out=180,in=0] (14b.0) to[out=180,in=0] (5c.0) to[out=180,in=0] (4.0);
	\draw[se] (14.180) to[out=180,in=0] ( 14a.0) to[out=180,in=0] (14b.0) to[out=180,in=0] (5.0);
	\draw[se] (24) to  (14);

	\node (6a) [right = 0.cm of 6] {};
	\node (16c) [above = 0.cm of 16] {};
	\draw[me] (16.180) to[out=180,in=0] ( 6a.0) to[out=180,in=0] (6.0);
	\draw[me] (17.180) to[out=180,in=0] ( 16c.0) to[out=180,in=0] ( 6a.0) to[out=180,in=0] (6.0);

	\node (17c) [above = 0cm of 17] {};
	\node (17d) [below = 0cm of 17] {};
	\draw[se] (26.180) to[out=180,in=0] (17d.0) to[out=180,in=0] (16.0);
	\node (26a) [above = 0cm of 26] {};
	\draw[se] (27.180) to[out=180,in=0] (26a.0) to[out=180,in=0] (17.0);

	\draw[ie] (26) to node[el,below] {\m{\neq}} (27);

\draw[draw=none, use as bounding box] (current bounding box.north west) rectangle (current bounding box.south east);

\begin{pgfinterruptboundingbox}
	\draw[separator] (2.1cm,-0.7cm) to (2.1cm,3.7cm);
	\draw[separator] (6.5cm,-0.7cm) to (6.5cm,3.7cm);
\end{pgfinterruptboundingbox}

\end{tikzpicture}

\caption{
\scriptsize
The sources function\\
propagation invariant broken
}
\label{snippet3.16a_graph3}
\end{figure}
Here the nodes \m{f(\s{a,b})} and \m{g(\s{a,b})} share a source, and so should be merged.

Here is the desired graph of all EC graphs:\\
\begin{figure}[!ht]
\begin{tikzpicture}
  \node[gttn] (1)              {$()$};
	\node[gl]   (1l) [below = 0 of 1] {\m{n_1}};

  \node[gtn]  (2) [above left  = 0.6cm and 0.2cm of 1] {\s{a}};
  \node[gtn]  (3) [above right = 0.6cm and 0.2cm of 1] {\s{b}};
	
	\draw[gfa] (2) to node[el]             {\m{a}} (1);
	\draw[gfa] (3) to node[el,anchor=west] {\m{b}} (1);
  
	\node[gttn] (4)  [above = 0.5cm of 2]    {\m{(a)}};
	\node[gttn] (5)  [above = 0.5cm of 3]    {\m{(b)}};

	\draw[sgtt] (4) to node[el] {0} (2);
	\draw[sgtt] (5) to node[el] {0} (3);

	\node[gtn]  (6)  [above = 2.5cm of 1] {\tiny$\svb{f(a)}{g(b)}$};
	\draw[gfa]  (6) to node[el]             {\m{f}} (4);
	\draw[gfa]  (6) to node[el,anchor=west] {\m{g}} (5);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\node[gttn] (11)  [right = 3cm of 1] {$()$};
	\node[gl]   (11l) [below = 0 of 11]   {\m{n_2}};

	\node[gtn]  (12) [above = 0.5cm of 11] {\s{a,b}};

	\draw[gfa] (12) to[out=-110,in=110] node[el]             {\m{a}} (11);
	\draw[gfa] (12) to[out=- 70,in= 70] node[el,anchor=west] {\m{b}} (11);

	\node[gttn] (14)  [above = 0.5cm of 12]    {\m{(\s{a,b})}};

	\draw[sgtt] (14) to node[el] {0} (12);

	\node[gtn]  (16)  [above = 2.5cm of 11] {\tiny $\faB{f}{a}{b},\faB{g}{a}{b}$};
	\draw[gfa]  (16) to[out=-100 , in=100] node[el]             {\m{f}} (14);
	\draw[gfa]  (16) to[out=- 80 ,in=  80] node[el,anchor=west] {\m{g}} (14);
				
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

	\node[gttn] (21)  [right = 3.5cm of 11] {$()$};
	\node[gl]   (21l) [below = 0 of 21]   {\m{n_3}};

	\node[gtn]  (22) [above = 0.5cm of 21] {\s{a,b}};

	\draw[gfa] (22) to[out=-110,in=110] node[el]             {\m{a}} (21);
	\draw[gfa] (22) to[out=- 70,in= 70] node[el,anchor=west] {\m{b}} (21);

	\node[gttn] (24)  [above = 0.5cm of 22]    {\m{f(\s{a,b})}};

	\draw[sgtt] (24) to node[el] {0} (22);

	\node[gtn]  (26)  [above = 2.5cm of 21] {\tiny $\faB{f}{a}{b},\faB{g}{a}{b}$};
	\draw[gfa]  (26) to[out=-100 ,in= 100] node[el]             {\m{f}} (24);
	\draw[gfa]  (26) to[out=- 80 ,in=  80] node[el,anchor=west] {\m{g}} (24);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\draw[se] (11) to  ( 1);
	\draw[se] (21) to  (11);

	\node(12a) [left = 0.5cm of 12] {};
	\node(3c) [above= 0.1cm of 3] {};
	\draw[se] ( 12.180) to[out=180,in=0] (12a.0) to[out=180,in=0] (3c) to[out=180,in=0] (   2.0);
	\draw[se] ( 12.180) to[out=180,in=0] (12a.0) to[out=180,in=0] (   3.0);

	\draw[se] (22) to  (12);

	\node(5c)  [above= 0.1cm of 5] {};
	\node(14a) [left = 0.7cm of 14] {};
	\draw[se] (14.180) to[out=180,in=0] (14a.0) to[out=180,in=0] (5c) to[out=180,in=0]( 4.0);
	\draw[se] (14.180) to[out=180,in=0] (14a.0) to[out=180,in=0]( 5.0);
	\draw[se] (24) to  (14);

	\draw[se] (16) to  ( 6);
	\draw[se] (26) to  (16);

	\draw[ie] (26) to[loop] node[el,above] {\m{\neq}} (26);

\draw[draw=none, use as bounding box] (current bounding box.north west) rectangle (current bounding box.south east);

\begin{pgfinterruptboundingbox}
	\draw[separator] (2.0cm,-0.7cm) to (2.0cm,3.5cm);
	\draw[separator] (5.5cm,-0.7cm) to (5.5cm,3.5cm);
\end{pgfinterruptboundingbox}

\end{tikzpicture}

\caption{
The sources function
}
\label{snippet3.16a_graph4}
\end{figure}

\subsection{Local EC Graph based invariant}
\subsubsection{Invariants for Sequential Nodes}

\subsubsection*{The Propagation Invariant}
Remember that the \textbf{propagation invariant} was phrased:\\
\m{\forall n \in cfg,t \in \terms{g_n}, s \in \Ts{\sig} \cdot} \\
\m{s=t \in \sqcup_F(\eqs{g_n},\s{\eqs{g_p}}_{p \in \preds{n}}) \Rightarrow s \in \terms{[t]_{g_n}}}\\
For a sequential node \node{n} with the predecessor \node{p} this simplifies to (with the strongest join):\\
\m{\forall t \in \terms{g_n}, s \in \Ts{\sig} \cdot} 
\m{(s=t \in \eqs{g_n} \cup \eqs{g_p}) \Rightarrow s \in \terms{[t]_{g_n}}}\\
We will show that, combined with the source invariant, this boils down to two conditions:\\
The \textbf{first condition} ensures eager equality propagation:\\
\m{\forall u,v \in g_n \cdot u \neq v \Rightarrow \sources{n}{p}{u} \cap \sources{n}{p}{v} = \emptyset}\\
That is, each predecessor EC node can be the source of at most one EC node at\node{n} - 
we have seen that this was broken in ~\ref{snippet3.16a_graph3} as the EC node \s{f(a),g(b)} in \node{n_1} 
is the source for both nodes \m{f(\s{a,b}),g(\s{a,b})} at \node{n_2}.\\ 
The \textbf{second condition} ensures \emph{gfa completeness}:\\
\m{\forall u \in g_n, v \in \sources{n}{p}{u}, \fa{f}{s} \in v \cdot}\\
\m{\exists \fa{f}{t} \in u \cdot \tup{s} \in \sources{n}{p}{\tup{t}} }\\
Where it is important to emphasize the meaning of sources for tuple ECs:\\
\m{\forall \tup{t} \in g_n,  \cdot \sources{n}{p}{\tup{t}} = \s{\tup{s} \in g_p \mid \bigwedge\limits_i s_i \in \sources{n}{p}{t_i} }}\\
Where also for tuple ECs:\\
\m{\forall \tup{s},\tup{t} \in g_n \cdot \tup{s} \neq \tup{t} \Rightarrow \sources{n}{p}{\tup{s}} \cap \sources{n}{p}{\tup{t}} = \emptyset}

This invariant is not broken in the above examples, but could be broken if the assertion at \node{n_3} was changes to 
\m{f(b)=f(a)}, as shown in ~\ref{snippet3.16a_graph5}:
\begin{figure}[H]
\begin{tikzpicture}
	\node[gttn] (1)              {$()$};
	\node[gl]   (1l) [below = 0 of 1] {\m{n_1}};

	\node[gtn]  (2) [above left  = 0.6cm and 0.2cm of 1] {\s{a}};
	\node[gtn]  (3) [above right = 0.6cm and 0.2cm of 1] {\s{b}};

	\draw[gfa] (2) to node[el] {\m{a}} (1);
	\draw[gfa] (3) to node[el,anchor=west] {\m{b}} (1);

	\node[gttn] (4)  [above = 0.5cm of 2]    {\m{(a)}};
	\node[gttn] (5)  [above = 0.5cm of 3]    {\m{(b)}};

	\draw[sgtt] (4) to node[el] {0} (2);
	\draw[sgtt] (5) to node[el] {0} (3);

	\node[gtn]  (6)  [above = 2.5cm of 1] {\tiny$\svb{f(a)}{g(b)}$};
	\draw[gfa]  (6) to node[el] {\m{f}} (4);
	\draw[gfa]  (6) to node[el,anchor=west] {\m{g}} (5);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\node[gttn] (11)  [right = 3cm of 1] {$()$};
	\node[gl]   (11l) [below = 0 of 11]   {\m{n_2}};

	\node[gtn]  (12) [above = 0.5cm of 11] {\s{a,b}};

	\draw[gfa] (12) to[out=-110 ,in=110] node[el] {\m{a}} (11);
	\draw[gfa] (12) to[out=- 70,in= 70] node[el,anchor=west] {\m{b}} (11);

	\node[gttn,ultra thick] (14)  [above = 0.5cm of 12]    {\m{(\s{a,b})}};

	\draw[sgtt] (14) to node[el] {0} (12);

	\node[gtn,ultra thick]  (16)  [above = 2.5cm of 11] {\tiny $\faB{f}{a}{b},\faB{g}{a}{b}$};
	\draw[gfa]              (16) to [out=-100, in= 100] node[el]             {\m{f}} (14);
	\draw[gfa,ultra thick]  (16) to [out=-80 , in=  80] node[el,anchor=west] {\m{g}} (14);
				
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

	\node[gttn] (21)  [right = 3.5cm of 11] {$()$};
	\node[gl]   (21l) [below = 0 of 21]   {\m{n_3}};

	\node[gtn]  (22) [above = 0.5cm of 21] {\s{a,b}};

	\draw[gfa] (22)  to[out=-110,in=110] node[el]             {\m{a}} (21);
	\draw[gfa] (22)  to[out=- 70,in= 70] node[el,anchor=west] {\m{b}} (21);

	\node[gttn,ultra thick] (24)  [above = 0.5cm of 22]    {\m{(\s{a,b})}};

	\draw[sgtt] (24) to node[el] {0} (22);

	\node[gtn,ultra thick]  (26)  [above = 2.5cm of 21] {\tiny $\faB{f}{a}{b}$};

	\draw[gfa]               (26) to [out=-100, in= 100] node[el]             {\m{f}} (24);
	\draw[mgfa,ultra thick]  (26) to [out=-80 , in=  80] node[ml,anchor=west] {\m{g}} (24);
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\draw[se] (11) to ( 1);
	\draw[se] (21) to  (11);

	\node (12a) [left = 0.5cm of 12] {};
	\node (3c) [above= 0.1cm of 3] {};
	\draw[se] ( 12.180) to[out=180,in=0] (12a.0) to[out=180,in=0] (3c) to[out=180,in=0] (   2.0);
	\draw[se] ( 12.180) to[out=180,in=0] (12a.0) to[out=180,in=0] (   3.0);

	\draw[se] (22) to  (12);

	\node (5c) [above= 0.1cm of 5] {};
	\node (14a) [left = 0.7cm of 14] {};
	\draw[se] (14.180) to[out=180,in=0] (14a.0) to[out=180,in=0] (5c) to[out=180,in=0]( 4.0);
	\draw[se] (14.180) to[out=180,in=0] (14a.0) to[out=180,in=0]( 5.0);
	\draw[se,ultra thick] (24) to (14);

	\draw[se] (16) to  (6);
	\draw[se,ultra thick] (26) to  (16);

\draw[draw=none, use as bounding box] (current bounding box.north west) rectangle (current bounding box.south east);

\begin{pgfinterruptboundingbox}
	\draw[separator] (2.0cm,-0.7cm) to (2.0cm,3.5cm);
	\draw[separator] (5.5cm,-0.7cm) to (5.5cm,3.5cm);
\end{pgfinterruptboundingbox}

\end{tikzpicture}

\caption{
The sources function\\
gfa invariant broken
}
\label{snippet3.16a_graph5}
\end{figure}
\noindent
At \node{n_3} the EC node \m{f(\s{a,b})} is missing the gfa \m{g(\s{a,b})} which is implied by the gfa completeness invariant, 
as shown by the highlighted path.
However, this invariant is not local - consider the following graph (irrelevant sources and rgfas ommitted):
\begin{figure}[H]
\begin{tikzpicture}
	\node[gttn,ultra thick] (1)              {$()$};
	\node[gl]   (1l) [below = 0 of 1] {\m{n_1}};

	\node[gtn]              (2) [above left  = 0.6cm and 0.2cm of 1] {\s{a}};
	\node[gtn,ultra thick]  (3) [above right = 0.6cm and 0.2cm of 1] {\s{b}};

	\draw[gfa]             (2) to node[el] {\m{a}} (1);
	\draw[gfa,ultra thick] (3) to node[el,anchor=west] {\m{\mathbf{b}}} (1);

	\node[gttn]             (4)  [above = 0.5cm of 2]    {\m{(a)}};
	\node[gttn,ultra thick] (5)  [above = 0.5cm of 3]    {\m{(b)}};

	\draw[sgtt]             (4) to node[el] {0} (2);
	\draw[sgtt,ultra thick] (5) to node[el] {\textbf{0}} (3);

	\node[gtn,ultra thick]  (6)  [above = 2.5cm of 1] {\tiny$\svb{f(a)}{g(b)}$};
	\draw[gfa]              (6) to node[el]             {\m{f}} (4);
	\draw[gfa,ultra thick]  (6) to node[el,anchor=west] {\m{g}} (5);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\node[gttn,ultra thick] (11)  [right = 3cm of 1] {$()$};
	\node[gl]   (11l) [below = 0 of 11]   {\m{n_2}};

	\node[gtn]  (12) [above = 0.6cm of 11] {\s{a,c}};
	\node[mgtn] (13) [above right = 0.65cm and 0.6cm of 11] {\s{b}};

	\draw[gfa]  (12) to[bend right] node[el] {\m{a}} (11);
	\draw[gfa]  (12) to[bend left]  node[el] {\m{c}} (11);
	\draw[mgfa] (13) to node[ml,anchor=west] {\m{b}} (11);

	\node[gttn]  (14)  [above = 0.5cm of 12]    {\m{(a,c)}};
	\node[mgttn] (15)  [above = 0.5cm of 13]    {\m{(b)}};

	\draw[sgtt]  (14) to node[el] {0} (12);
	\draw[msgtt] (15) to node[ml] {0} (13);

	\node[gtn,ultra thick]  (16)  [above = 0.76cm of 14] {\tiny$\m{f(\s{a,c})}$};
	\draw[gfa]              (16) to node[el]             {\m{f}} (14);
	\draw[mgfa]  (16) to node[ml,anchor=west] {\m{g}} (15);
 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\draw[se,ultra thick] (11) to  ( 1);

	\node (12a) [left = 0.5cm of 12] {};
	\node (3c) [above= 0.1cm of 3] {};
	
	\node (5c) [above= 0.1cm of 5] {};
	\node (14a) [left = 0.7cm of 14] {};

	\draw[se,ultra thick] (16) to  (6);

\draw[draw=none, use as bounding box] (current bounding box.north west) rectangle (current bounding box.south east);

\begin{pgfinterruptboundingbox}
	\draw[separator] (2.0cm,-0.7cm) to (2.0cm,3.5cm);
\end{pgfinterruptboundingbox}

\end{tikzpicture}

\caption{
The sources function\\
gfa invariant broken non-local
}
\label{snippet3.16a_graph6}
\end{figure}
In ~\ref{snippet3.16a_graph6} \node{n_2} is missing the whole path of \m{g(b)} in order to be complete, we will look now at how this can be detected.\\
There are principally 3 pre-states and operations that can reach the above state:\\
The \textbf{first} is when the last operation was \lstinline{adding} the term \m{f(a)} at \node{n_2}:
\begin{figure}[H]
\begin{tikzpicture}
  \node[gttn] (1)              {$()$};
	\node[gl]   (1l) [below = 0 of 1] {\m{n_1}};

  \node[gtn]  (2) [above left  = 0.6cm and 0.2cm of 1] {\s{a}};
  \node[gtn]  (3) [above right = 0.6cm and 0.2cm of 1] {\s{b}};
	
	\draw[gfa]  (2) to node[el] {\m{a}} (1);
  \draw[gfa]  (3) to node[el,anchor=west] {\m{\mathbf{b}}} (1);
  
	\node[gttn] (4)  [above = 0.5cm of 2]    {\m{(a)}};
  \node[gttn] (5)  [above = 0.5cm of 3]    {\m{(b)}};

	\draw[sgtt]             (4) to node[el] {0} (2);
	\draw[sgtt] (5) to node[el] {\textbf{0}} (3);

  \node[gtn]  (6)  [above = 2.5cm of 1] {\tiny$\svb{f(a)}{g(b)}$};
	\draw[gfa]  (6) to node[el]             {\m{f}} (4);
  \draw[gfa]  (6) to node[el,anchor=west] {\m{g}} (5);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \node[gttn] (11)  [right = 3cm of 1] {$()$};
	\node[gl]   (11l) [below = 0 of 11]   {\m{n_2}};

  \node[gtn]  (12) [above = 0.6cm of 11] {\s{a,c}};
	
	\draw[gfa]  (12) to[bend right] node[el] {\m{a}} (11);
	\draw[gfa]  (12) to[bend left]  node[el,anchor=west] {\m{c}} (11);
  
	\node[gttn] (14)  [above = 0.5cm of 12]    {\m{(a,c)}};

	\draw[sgtt] (14) to node[el] {0}          (12);
  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\draw[se] (11) to  ( 1);

	\node (12a) [left = 0.5cm of 12] {};
	\node  (3c) [above= 0.1cm of 3] {};
	
	\node  (5c) [above= 0.1cm of 5] {};
	\node (14a) [left = 0.7cm of 14] {};

	\draw[se] (14) to (14a) to (5c) to (4);

\draw[draw=none, use as bounding box] (current bounding box.north west) rectangle (current bounding box.south east);

\begin{pgfinterruptboundingbox}
	\draw[separator] (2.0cm,-0.7cm) to (2.0cm,3.5cm);
\end{pgfinterruptboundingbox}

\end{tikzpicture}

\caption{
The sources function\\
gfa invariant broken non-local\\
pre-state for \m{n_2.add(f(a))}
}
\label{snippet3.16a_graph7}
\end{figure}
In ~\ref{snippet3.16a_graph7} there is not (and should not be) a node for \m{b} or \m{(b)} at \node{n_2}.\\
The next step should create the whole chain of \m{g(b)}, which could be arbitrarily deep and large, e.g. \m{g^6(b)} or \m{h(h(a,b),h(b,a))}.\\
To do this incrementally and efficiently we cannot simply follow the path from \s{()} to \s{b} because there may be many other constants unrelated to the final term we create - instead we will \emph{traverse down on sources} from \s{f(a),g(b)} in \node{n_1} until we encounter a node in \m{g_{n_1}} that is a source to some node in \m{g_{n_2}} (in this case only \s{()} - which is always guaranteed to be) 
and then create the necessary nodes up in lockstep between the predecessor graph and the node graph.\\
In our example we will traverse down to \s{()} and then create the nodes, in bottom to top order (following function and tuple member edges in reverse direction), \s{b},\s{(b)} and add the gfa \m{g(b)} to the newly created node. \\
This process of completing source nodes down and then creating new nodes in lockstep will be the base for all of our join, meet and other EC graph manipulation algorithms.\\
As can be seen, the inherent time (and space) complexity of this process (assuming that we maintain the relevant lookup tables) is proportional to the size of the difference between the result and the pre-state. Unfortunately, this would not be exactly the case for joins, or when further restrictions, such as scoping and term radius, are enforced. We will, however, draw a complexity bound in all cases which is based on a worst case result size similar to the above.\\
The process described above stems directly from the gfa completeness invariant.

\noindent
The \textbf{second} possible pre-state is after we \lstinline{assumed f(a)=g(b)} at \node{n_1}, but before we have updated \node{n_2}:
\begin{figure}[H]
\begin{tikzpicture}
  \node[gttn] (1)              {$()$};
	\node[gl]  (1l) [below = 0 of 1] {\m{n_1}};

  \node[gtn]  (2) [above left  = 0.6cm and 0.2cm of 1] {\s{a}};
  \node[gtn]  (3) [above right = 0.6cm and 0.2cm of 1] {\s{b}};
	
	\draw[gfa]  (2) to node[el] {\m{a}} (1);
  \draw[gfa]  (3) to node[el,anchor=west] {\m{\mathbf{b}}} (1);
  
	\node[gttn] (4) [above = 0.5cm of 2]    {\m{(a)}};
  \node[gttn] (5) [above = 0.5cm of 3]    {\m{(b)}};

	\draw[sgtt] (4) to node[el] {0} (2);
	\draw[sgtt] (5) to node[el] {\textbf{0}} (3);

  \node[gtn]  (6) [above = 2.5cm of 1] {\tiny$\svb{f(a)}{g(b)}$};
	\draw[gfa]  (6) to node[el]             {\m{f}} (4);
  \draw[gfa]  (6) to node[el,anchor=west] {\m{g}} (5);

  \node[hgtn] (6a) [above = 1.5cm of 4] {\tiny$\s{f(\s{a})}$};
%	\draw[hgfa] (6a) to node[hl]          {\m{f}} (4);
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \node[gttn] (11) [right = 3cm of 1] {$()$};
	\node[gl]  (11l) [below = 0 of 11]   {\m{n_2}};

  \node[gtn]  (12) [above = 0.6cm of 11] {\s{a,c}};
	
	\draw[gfa]  (12) to[bend right] node[el,anchor=east] {\m{a}} (11);
	\draw[gfa]  (12) to[bend left]  node[el,anchor=west] {\m{c}} (11);
  
	\node[gttn] (14) [above = 0.5cm of 12]    {\m{(a,c)}};

	\draw[sgtt] (14) to node[el] {0}          (12);

  \node[gtn]  (16) [above = 0.5cm of 14] {\tiny$\m{f\left(\svb{a}{c}\right)}$};
	\draw[gfa]  (16) to node[el]             {\m{f}} (14);
  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\draw[se] (11) to  ( 1);

	\node (12a) [left = 0.5cm of 12] {};
	\node (3c) [above= 0.1cm of 3] {};
	
	\node (5c) [above= 0.1cm of 5] {};
	\node (14a) [left = 0.7cm of 14] {};

	\draw[se] (14) to (14a) to (5c) to (4);
	\draw[hse] (16) to (6a);
	\draw[he] (6a) to (6);

\draw[draw=none, use as bounding box] (current bounding box.north west) rectangle (current bounding box.south east);

\begin{pgfinterruptboundingbox}
	\draw[separator] (2.0cm,-0.7cm) to (2.0cm,3.5cm);
\end{pgfinterruptboundingbox}

\end{tikzpicture}

\caption{
The sources function\\
gfa invariant broken non-local\\
pre-state for \m{n_1.merge(f(a),g(b))}
}
\label{snippet3.16a_graph8}
\end{figure}
In ~\ref{snippet3.16a_graph8} the EC node \m{f(a)} at \m{g_{n_2}} points to an old version of the EC of \m{f(a)} at \m{g_{n_1}}.
This old version points (dotted arrow) to the current version, so when we need to update \m{g_{n_2}}, we need to find all out-of-date sources, map them to the up-to-date versions, and then determine whether existing nodes need merging or new gfa paths need to be added as in the previous case. We will maintain enough history information at each EC graph to make this process efficient.

\noindent
The \textbf{third} possible pre-state is before we \lstinline{assume a=c} at \node{n_2}:
\begin{figure}[H]
\begin{tikzpicture}
  \node[gttn] (1)              {$()$};
	\node[gl]  (1l) [below = 0 of 1] {\m{n_1}};

  \node[gtn]  (2) [above left  = 0.6cm and 0.2cm of 1] {\s{a}};
  \node[gtn]  (3) [above right = 0.6cm and 0.2cm of 1] {\s{b}};
	
	\draw[gfa]  (2) to node[el] {\m{a}} (1);
  \draw[gfa]  (3) to node[el,anchor=west] {\m{b}} (1);
  
	\node[gttn] (4) [above = 0.5cm of 2]    {\m{(a)}};
  \node[gttn] (5) [above = 0.5cm of 3]    {\m{(b)}};

	\draw[sgtt] (4) to node[el] {0} (2);
	\draw[sgtt] (5) to node[el] {0} (3);

  \node[gtn]  (6) [above = 2.5cm of 1] {\tiny$\svb{f(a)}{g(b)}$};
	\draw[gfa]  (6) to node[el]             {\m{f}} (4);
  \draw[gfa]  (6) to node[el,anchor=west] {\m{g}} (5);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \node[gttn] (11) [right = 2.5cm of 1] {$()$};
	\node[gl]  (11l) [below = 0.0cm of 11]   {\m{n_2}};

  \node[gtn]  (12) [above left = 0.6cm and 0.2 of 11] {\s{a}};
  \node[gtn]  (13) [above right= 0.6cm and 0.2 of 11] {\s{c}};
	
	\draw[gfa]  (12) to node[el,anchor=east] {\m{a}} (11);
	\draw[gfa]  (13) to node[el,anchor=west] {\m{c}} (11);
  
	\node[gttn] (15) [above = 0.5cm of 13]    {\m{(c)}};

	\draw[sgtt] (15) to node[el] {0}          (13);

  \node[gtn]  (16) [above = 0.5cm of 15] {\tiny$\s{f(c)}$};
	\draw[gfa]  (16) to node[el]             {\m{f}} (15);
  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	\draw[se] (11) to  ( 1);

	\node (12a) [left = 0.5cm of 12] {};
	
	\node (3c) [above= 0.1cm of 3] {};

	\draw[se] (12) to (3c) to (2);

\draw[draw=none, use as bounding box] (current bounding box.north west) rectangle (current bounding box.south east);

\begin{pgfinterruptboundingbox}
	\draw[separator] (1.4cm,-0.7cm) to (1.4cm,3.5cm);
\end{pgfinterruptboundingbox}

\end{tikzpicture}

\caption{
The sources function\\
gfa invariant broken non-local\\
pre-state for \m{n_2.assume(a=c)}
}
\label{snippet3.16a_graph9}
\end{figure}
In ~\ref{snippet3.16a_graph9}, at \m{g_{n_2}} we merge the nodes \s{a} and \s{c}, which propagates the change up until the node \m{f(c)} which becomes \m{f(\s{a,c})}, and update the sources for each node on the way according to gfa completeness. 
When we reach \m{f(\s{a,c})}, we need to propagate down the gfa \m{g(b)} from the sources and complete that path as in the other examples.

\noindent
In all of the above cases, the final result is:
\begin{figure}[H]
\begin{tikzpicture}
	\node[gttn] (1)              {$()$};
	\node[gl]   (1l) [below = 0 of 1] {\m{n_1}};

	\node[gtn]  (2) [above left  = 0.6cm and 0.2cm of 1] {\s{a}};
	\node[gtn]  (3) [above right = 0.6cm and 0.2cm of 1] {\s{b}};

	\draw[gfa]  (2) to node[el,anchor=east] {\m{a}} (1);
	\draw[gfa]  (3) to node[el,anchor=west] {\m{b}} (1);

	\node[gttn] (4)  [above = 0.5cm of 2]    {\m{(a)}};
	\node[gttn] (5)  [above = 0.5cm of 3]    {\m{(b)}};

	\draw[sgtt] (4) to node[el] {0} (2);
	\draw[sgtt] (5) to node[el] {0} (3);

	\node[gtn]  (6)  [above = 2.5cm of 1] {\tiny$\svb{f(a)}{g(b)}$};
	\draw[gfa]  (6) to node[el,anchor=east] {\m{f}} (4);
	\draw[gfa]  (6) to node[el,anchor=west] {\m{g}} (5);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\node[gttn] (11)  [right = 3cm of 1] {$()$};
	\node[gl]   (11l) [below = 0 of 11]   {\m{n_2}};

	\node[gtn]  (12) [above left  = 0.6cm and 0.2cm of 11] {\s{a,c}};
	\node[gtn]  (13) [above right = 0.6cm and 0.6cm of 11] {\s{b}};

	\draw[gfa] (12) to[bend right] node[el,anchor=east] {\m{a}} (11);
	\draw[gfa] (12) to[bend left]  node[el,anchor=west] {\m{c}} (11);
	\draw[gfa] (13) to             node[el,anchor=west] {\m{b}} (11);

	\node[gttn] (14)  [above = 0.5cm of 12] {\m{(\s{a,c})}};
	\node[gttn] (15)  [above = 0.5cm of 13] {\m{(b)}};

	\draw[sgtt] (14) to node[el] {0} (12);
	\draw[sgtt] (15) to node[el] {0} (13);

	\node[gtn]  (16)  [above = 2.5cm of 11] {\tiny$\svb{f(\s{a,c})}{g(b)}$};
	\draw[gfa]  (16) to node[el,anchor=east] {\m{f}} (14);
	\draw[gfa]  (16) to node[el,anchor=west] {\m{g}} (15);
 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\draw[se] (16) to  (6);

\draw[draw=none, use as bounding box] (current bounding box.north west) rectangle (current bounding box.south east);

\begin{pgfinterruptboundingbox}
	\draw[separator] (1.5cm,-0.7cm) to (1.5cm,3.5cm);
\end{pgfinterruptboundingbox}

\end{tikzpicture}

\caption{
The sources function\\
gfa invariant non-local fixed
}
\label{snippet3.16a_graph10}
\end{figure}
Note that, as opposed to union-find based approaches, equivalent final results are identical.
The three scenarios we have shown could all have been produced during different verifications of the same program, 
if the order of evaluation of the CFG nodes, or the order of evaluation of verification fragments, were different.
As the complexity in generating this result is proportional to the (graph) size of the result, 
we can analyze complexity regardless of the order of evaluation.
We will see later that with joins it is harder to keep complexity independent of evaluation order, but we will show a weaker property regarding complexity in different evaluation orders.

\noindent
We will consider one more example for sequential nodes, before formalizing the invariant:
\begin{figure}[H]
\begin{tikzpicture}
	\node[gttn] (1)              {$()$};
	\node[gl]   (1l) [below = 0 of 1] {\m{n_1}};

	\node[gtn]  (2) [above left = 1.0cm and 1.8cm of 1] {\s{a}};
	\node[gtn]  (3) [above left = 1.0cm and 0.4cm of 1] {\s{b}};
	\node[gtn]  (4) [above right= 1.0cm and 0.4cm of 1] {\s{c}};
	\node[gtn]  (5) [above right= 1.0cm and 1.8cm of 1] {\s{d}};

	\draw[gfa]  (2) to node[el,anchor=east] {\m{a}} (1);
	\draw[gfa]  (3) to node[el,anchor=east] {\m{b}} (1);
	\draw[gfa]  (4) to node[el,anchor=west] {\m{c}} (1);
	\draw[gfa]  (5) to node[el,anchor=west] {\m{d}} (1);

	\node[gttn] (2a) [above = 1.0cm of 2]    {\m{(a)}};
	\node[gttn] (3a) [above = 1.0cm of 3]    {\m{(b)}};
	\node[gttn] (4a) [above = 1.0cm of 4]    {\m{(c)}};
	\node[gttn] (5a) [above = 1.0cm of 5]    {\m{(d)}};

	\draw[sgtt] (2a) to node[el] {0} (2);
	\draw[sgtt] (3a) to node[el] {0} (3);
	\draw[sgtt] (4a) to node[el] {0} (4);
	\draw[sgtt] (5a) to node[el] {0} (5);

	\node[gtn]  (6)  [above right = 1.0cm and 0.0cm of 2a] {\tiny$\svb{f(a)}{f(b)}$};
	\draw[gfa]  (6) to node[el,anchor=east] {\m{f}} (2a);
	\draw[gfa]  (6) to node[el,anchor=west] {\m{f}} (3a);

	\node[gtn]  (7)  [above left = 1.0cm and 0.0cm of 5a] {\tiny$\svb{f(c)}{f(d)}$};
	\draw[gfa]  (7) to node[el,anchor=east] {\m{f}} (4a);
	\draw[gfa]  (7) to node[el,anchor=west] {\m{f}} (5a);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\node[gttn] (11)  [right = 6cm of 1] {$()$};
	\node[gl]   (11l) [below = 0 of 11]   {\m{n_2}};

	\node[gtn]  (12) [above left  = 1.0cm and 0.4cm of 11] {\s{a}};
	\node[gtn]  (13) [above right = 1.0cm and 0.4cm of 11] {\s{b,c}};

	\draw[gfa] (12) to             node[el,anchor=east] {\m{a}} (11);
	\draw[gfa] (13) to[bend right] node[el,anchor=east] {\m{b}} (11);
	\draw[gfa] (13) to[bend left]  node[el,anchor=west] {\m{c}} (11);

	\node[gttn] (12a)  [above = 1.0cm of 12] {\m{(a)}};
	\draw[sgtt] (12a) to node[el] {0} (12);
 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\node (5au) [above = 0.2 of 5a] {};
	\node (3au) [above = 0.2 of 3a] {};
	\draw[se] (12a) to (5au) to (3au) to (2a);

	\node (12u) [above = 0.2 of 12] {};
	\node (5u) [above = 0.2 of 5] {};
	\node (5d) [below = 0.2 of 5] {};
	\node (4u) [above = 0.2 of 4] {};
	\node (4d) [below = 0.2 of 4] {};

	\draw[se] (13) to (12u) to (5u) to (4u) to (3);
	\draw[se] (13) to (12u) to (5u) to (4);

\draw[draw=none, use as bounding box] (current bounding box.north west) rectangle (current bounding box.south east);

\begin{pgfinterruptboundingbox}
	\draw[separator] (3.5cm,-0.7cm) to (3.5cm,5.5cm);
\end{pgfinterruptboundingbox}

\end{tikzpicture}

\caption{
The sources function\\
multiple up-down propagations\\
before \lstinline{add(f(a))}
}
\label{graph_sequential_multi_propagation_pre}
\end{figure}
In ~\ref{graph_sequential_multi_propagation_pre}, we show the relevant sources before adding the term \m{f(a)} to the \node{n_2}.

We now show the post-state, with the propagation paths highlighted:
\begin{figure}[H]
\begin{tikzpicture}
	\node[gttn] (1)              {$()$};
	\node[gl]   (1l) [below = 0 of 1] {\m{n_1}};

	\node[gtn]              (2) [above left = 1.0cm and 1.8cm of 1] {\s{a}};
	\node[gtn,ultra thick]  (3) [above left = 1.0cm and 0.3cm of 1] {\s{b}};
	\node[gtn,ultra thick]  (4) [above right= 1.0cm and 0.3cm of 1] {\s{c}};
	\node[gtn,ultra thick]  (5) [above right= 1.0cm and 1.8cm of 1] {\s{d}};

	\draw[gfa]              (2) to node[el,anchor=east] {\m{a}} (1);
	\draw[gfa]              (3) to node[el,anchor=east] {\m{b}} (1);
	\draw[gfa]              (4) to node[el,anchor=west] {\m{c}} (1);
	\draw[gfa,ultra thick]  (5) to node[el,anchor=west] {\m{d}} (1);

	\node[gttn]             (2a) [above = 1.0cm of 2]    {\m{(a)}};
	\node[gttn,ultra thick] (3a) [above = 1.0cm of 3]    {\m{(b)}};
	\node[gttn,ultra thick] (4a) [above = 1.0cm of 4]    {\m{(c)}};
	\node[gttn,ultra thick] (5a) [above = 1.0cm of 5]    {\m{(d)}};

	\draw[sgtt] (2a) to node[el] {0} (2);
	\draw[sgtt,ultra thick] (3a) to node[el] {0} (3);
	\draw[sgtt,ultra thick] (4a) to node[el] {0} (4);
	\draw[sgtt,ultra thick] (5a) to node[el] {0} (5);

	\node[gtn,ultra thick]  (6)  [above right = 1.0cm and -0.1cm of 2a] {\tiny$\svb{f(a)}{f(b)}$};
	\draw[gfa,ultra thick]  (6) to node[el,anchor=east] {\m{f}} (2a);
	\draw[gfa,ultra thick]  (6) to node[el,anchor=west] {\m{f}} (3a);

	\node[gtn,ultra thick]  (7)  [above left = 1.0cm and -0.1cm of 5a] {\tiny$\svb{f(c)}{f(d)}$};
	\draw[gfa,ultra thick]  (7) to node[el,anchor=east] {\m{f}} (4a);
	\draw[gfa,ultra thick]  (7) to node[el,anchor=west] {\m{f}} (5a);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\node[gttn] (11)  [right = 6cm of 1] {$()$};
	\node[gl]   (11l) [below = 0 of 11]   {\m{n_2}};

	\node[gtn]              (12) [above left  = 1.0cm and 0.8cm of 11] {\s{a}};
	\node[gtn,ultra thick]  (13) [above       = 0.9cm           of 11] {\s{b,c}};
	\node[gtn]              (14) [above right = 1.0cm and 0.8cm of 11] {\s{d}};

	\draw[gfa] (12) to             node[el,anchor=east] {\m{a}} (11);
	\draw[gfa] (13) to[bend right] node[el,anchor=east] {\m{b}} (11);
	\draw[gfa] (13) to[bend left]  node[el,anchor=west] {\m{c}} (11);
	\draw[gfa] (14) to             node[el,anchor=west] {\m{d}} (11);

	\node[gttn] (12a)  [above = 1.0cm of 12] {\m{(a)}};
	\draw[sgtt] (12a) to node[el] {0} (12);

	\node[gttn] (13a)  [above = 1.0cm of 13] {\m{(\s{b,c})}};
	\draw[sgtt] (13a) to node[el] {0} (13);

	\node[gttn] (14a)  [above = 1.0cm of 14] {\m{(d)}};
	\draw[sgtt] (14a) to node[el] {0} (14);
 
	\node[gtn]  (16)  [above = 1.0cm of 13a] {\tiny$\m{f(\s{a,b,c,d}}$};
	\draw[gfa]  (16) to node[el,anchor=east] {\m{f}} (12a);
	\draw[gfa]  (16) to node[el,anchor=east] {\m{f}} (13a);
	\draw[gfa]  (16) to node[el,anchor=west] {\m{f}} (14a);
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\draw[se,ultra thick] (11) to (1);
	\node (5au) [above = 0.2 of 5a] {};
	\node (3au) [above = 0.2 of 3a] {};
	\draw[se,ultra thick] (12a) to (5au) to (3au) to (2a);

	\node (12u) [above = 0.2 of 12] {};
	\node (5u) [above = 0.2 of 5] {};
	\node (5d) [below = 0.2 of 5] {};
	\node (4u) [above = 0.2 of 4] {};
	\node (4d) [below = 0.2 of 4] {};

	\draw[se,ultra thick] (13) to (12u) to (5u) to (4u) to (3);
	\draw[se,ultra thick] (13) to (12u) to (5u) to (4);
	
	
	\node (a1)  [left  = 0.2cm of  2a] {};
	\node (a2)  [above = 0.2cm of  6 ] {};
	\node (a3)  [right = 0.2cm of  3a] {};
	\node (a4)  [above right = 0.0cm and 0.2cm of 3 ] {};
	\node (a5)  [above = 0.0cm of  4u ] {};
	\node (a6)  [above right = 0.0cm and 0.0cm of 12u ] {};
	\node (a7)  [above right = 0.2cm and 0.2cm of 13.180] {};
	\node (a8)  [above = 0.0cm of a7] {};
	\node (a9)  [above = 0.0cm of a6] {};
	\node (a10) [above = 0.0cm of a5] {};
	\node (a11) [left  = 0.0cm of 4a] {};
	\node (a12) [above = 0.2cm of 7] {};
	\node (a13) [right = 0.2cm of 5a] {};
	\node (a14) [right = 0.2cm of 5] {};
	\node (a15) [right = 0.2cm of 1] {};

	\draw[->,thin,green,out=90,in=-90] 
		(a1) to[in=180] (a2) to[out=0,in=90] (a3) to[out=-90,in=180] (a4) to[out=0,in=180] (a5) to[out=0,in=180] (a6) to[out=0,in=180] (a7) 
		to[out=0,in=0]  (a9) to[out=180,in=0] (a10) to[out=180,in=-90] (a11) to[out=90,in=180] (a12) 
		to[out=0,in=90] (a13) to[out=-90,in=90] (a14) to[out=-90,in=45] (a15);
		
\draw[draw=none, use as bounding box] (current bounding box.north west) rectangle (current bounding box.south east);

\begin{pgfinterruptboundingbox}
	\draw[separator] (4.0cm,-0.7cm) to (4.0cm,5.0cm);
\end{pgfinterruptboundingbox}

\end{tikzpicture}

\caption{
The sources function\\
multiple up-down propagations\\
after \lstinline{add(f(a))}
}
\label{graph_sequential_multi_propagation_post}
\end{figure}
The order of traversal would be as depicted by the green line in ~\ref{graph_sequential_multi_propagation_post}.

\subsubsection*{The Sources Invariant}
\begin{figure}[H]
\begin{enumerate}
\item The \textbf{first part} remains as in the sequential case, ensuring we are not missing sources edges:\\
	\m{\forall p \in \preds{n},\fa{f}{t} \in \GFAECs{g_n}, \tup{s} \in \sources{n}{p}{\tup{t}} \cdot }\\
	\m{\fa{f}{s} \in \GFAECs{g_p} \Rightarrow [\fa{f}{s}]_{g_p} \in \sources{n}{p}{[\fa{f}{t}]_{g_n}}}
\item The \textbf{second part} also remains as in the sequential case, ensuring that each of the predecessors has all potential sources as either gfas or rgfas:\\
	\m{\forall p \in \preds{n},\fa{f}{t} \in \GFAECs{g_n} \cup \rgfas{n}, \tup{s} \in \sources{n}{p}{\tup{t}} \cdot}\\
	\m{\fa{f}{t} \in \GFAECs{g_p} \cup \rgfas{p}}
\item The \textbf{third part} is slightly modified - we cannot have an rgfa only if \emph{all} predecessors have a gfa:\\
	\m{\forall \tup{t} \in g_n,f \in \Fs{\sig} \cdot}\\
	\m{(\forall p \in \preds{n} \cdot \exists \tup{s} \in \sources{n}{p}{\tup{t}}\cdot \fa{f}{s} \in g_p) \Rightarrow \fa{f}{t} \notin \rgfas{n})} 
\end{enumerate}
\caption{weak join source invariant}
\label{weak_join_source_invariant}
\end{figure}
All the conditions are still local, and neither joinee can affect the other.

\subsubsection*{The Propagation Invariant}
Remember that the \textbf{propagation invariant} was phrased:\\
\m{\forall n \in cfg,t \in \terms{g_n}, s \in \Ts{\sig} \cdot} \\
\m{s=t \in \sqcup_F(\eqs{g_n},\s{\eqs{g_p}}_{p \in \preds{n}}) \Rightarrow s \in \terms{[t]_{g_n}}}\\
For join nodes we will need some extra state in order to phrase these in terms of graphs, and the invariants will not be EC-graph-local, as we have seen in the examples above.
We will show that, combined with the source invariant, this boils down to two conditions:
\begin{figure}[H]
The \textbf{first condition} ensures eager equality propagation:\\
\m{\forall u,v \in g_n \cdot u \neq v \Rightarrow \sources{n}{p}{u} \cap \sources{n}{p}{v} = \emptyset}\\
That is, each predecessor EC node can be the source of at most one EC node at\node{n} - 
we have seen that this was broken in ~\ref{snippet3.16a_graph3} as the EC node \s{f(a),g(b)} in \node{n_1} 
is the source for both nodes \m{f(\s{a,b}),g(\s{a,b})} at \node{n_2}.\\ 
The \textbf{second condition} ensures \emph{gfa completeness}:\\
\m{\forall u \in g_n, v \in \sources{n}{p}{u}, \fa{f}{s} \in v \cdot}\\
\m{\exists \fa{f}{t} \in u \cdot \tup{s} \in \sources{n}{p}{\tup{t}} }\\
Where it is important to emphasize the meaning of sources for tuple ECs:\\
\m{\forall \tup{t} \in g_n,  \cdot \sources{n}{p}{\tup{t}} = \s{\tup{s} \in g_p \mid \bigwedge\limits_i s_i \in \sources{n}{p}{t_i} }}\\
Where also for tuple ECs:\\
\m{\forall \tup{s},\tup{t} \in g_n \cdot \tup{s} \neq \tup{t} \Rightarrow \sources{n}{p}{\tup{s}} \cap \sources{n}{p}{\tup{t}} = \emptyset}
\caption{weak join propagation invariant}
\label{weak_join_propagation_invariant}
\end{figure}


\subsubsection{Invariants for Join Nodes}
For joins some of the above invariants are still sufficient, but some need to be generalized.\\
Here is a simple example with a join:
\begin{figure}[H]
\begin{lstlisting}
$\node{n_1}:$
assume $\m{f(a)=g(a)}$
assume $\m{f(c)=g(c)}$
	//rgfas       $\m{f(\s{b}),g(\s{b})}$ none with scoping
if (*)
	$\node{n_{2a}}:$
	assume $\m{a=b}$
	//extra terms $\m{f(\s{a,b}),g(\s{a,b})}$
else
	$\node{n_{2b}}:$
	assume $\m{c=b}$
	//extra terms $\m{f(\s{b,c}),g(\s{b,c})}$
$\node{n_3}:$
assert $\m{f(b)=g(b)}$ //negated $\m{f(b) \neq g(b)}$
\end{lstlisting}
\caption{propagation sources}
\label{snippet3.16b}
\end{figure}

In ~\ref{snippet3.16b}, we would need to add \m{f(\s{a,b}),g(\s{a,b})} to \m{g_{n_{2a}}} \\
and \m{f(\s{b,c}),g(\s{b,c})} to \m{g_{n_{2b}}}, as shown in figure ~\ref{snippet3.16b_graph1}.\\
Note 

\begin{figure}[!ht]
\begin{tikzpicture}
	\node[gttn] (1)              {$()$};
	\node[gl]   (1l) [below = 0 of 1] {\m{n_1}};

	\node[gtn]  (2) [above left  = 1cm and 0.5cm of 1] {\s{a}};
	\node[gtn]  (3) [above right = 1cm and 0.5cm of 1] {\s{c}};

	\draw[gfa] (2) to node[el] {\m{a}} (1);
	\draw[gfa] (3) to node[el,anchor=west] {\m{c}} (1);

	\node[gttn] (4)  [above = 1cm of 2]    {\m{(a)}};
	\node[gttn] (5)  [above = 1cm of 3]    {\m{(c)}};

	\draw[sgtt] (4) to node[el] {0} (2);
	\draw[sgtt] (5) to node[el] {0} (3);

	\node[gtn]  (6)  [above = 1cm of 4] {\tiny$\stackB{f(a)}{g(a)}$};
	\draw[gfa]  (6) to[out=-110,in=110] node[el] {\m{f}} (4);
	\draw[gfa]  (6) to[out=- 70,in= 70] node[el,anchor=west] {\m{g}} (4);

	\node[gtn]  (7)  [above = 1cm of 5] {\tiny$\stackB{f(c)}{g(c)}$};
	\draw[gfa]  (7) to[out=-110,in=110] node[el] {\m{f}} (5);
	\draw[gfa]  (7) to[out=- 70,in= 70] node[el,anchor=west] {\m{g}} (5);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\node[gttn] (11)  [above right = 2.5cm and 4.5cm of 1] {$()$};
	\node[gl]   (11l) [below = 0 of 11]   {\m{n_2}};

	\node[gtn]  (12) [above = 1cm of 11] {\s{a,b}};

	\draw[gfa] (12) to[out=-110,in=110] node[el] {\m{a}} (11);
	\draw[gfa] (12) to[out=- 70,in= 70] node[el,anchor=west] {\m{b}} (11);

	\node[gttn] (14)  [above = 1cm of 12]    {\m{f(\s{a,b})}};

	\draw[sgtt] (14) to node[el] {0} (12);

	\node[gtn]  (16)  [above = 3.5cm of 11] {\tiny $\faB{f}{a}{b},\faB{g}{a}{b}$};
	\draw[gfa]  (16) to[out=-100, in= 100] node[el] {\m{f}} (14);
	\draw[gfa]  (16) to[out=- 80 ,in=  80] node[el,anchor=west] {\m{g}} (14);
				
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\node[gttn] (21)  [below right = 2.5cm and 4.5cm of 1] {$()$};
	\node[gl]   (21l) [below = 0 of 21]   {\m{n_3}};

	\node[gtn]  (22) [above = 1cm of 21] {\s{b,c}};

	\draw[gfa] (22) to[out=-110,in=110] node[el]             {\m{b}} (21);
	\draw[gfa] (22) to[out=- 70,in= 70] node[el,anchor=west] {\m{c}} (21);

	\node[gttn] (24)  [above = 1cm of 22]    {\m{f(\s{b,c})}};

	\draw[sgtt] (24) to node[el] {0} (22);

	\node[gtn]  (26)  [above = 3.5cm of 21] {\tiny $\faB{f}{b}{c},\faB{g}{b}{c}$};
	\draw[gfa]  (26) to[out=-100,in=100] node[el]             {\m{f}} (24);
	\draw[gfa]  (26) to[out=- 80,in= 80] node[el,anchor=west] {\m{g}} (24);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

	\node[gttn] (31)  [right = 9cm of 1] {$()$};
	\node[gl]   (31l) [below = 0 of 31]   {\m{n_4}};

	\node (31jl)  [above left = -0.2cm and 0cm of 31] {$\sqcup$};

	\node[gtn] (32) [above = 0.5cm of 31] {\m{b}};

	\draw[gfa] (32) to node[el] {\m{b}} (31);

	\node[gttn] (34)  [above = 0.5cm of 32]    {\m{(b)}};

	\draw[sgtt] (34) to node[el] {0} (32);

	\node[gtn]  (36)  [above = 2.5cm of 31] {\tiny $\stackB{f(b)}{g(b)}$};
	\draw[gfa]  (36) to[out=-100 ,in=100] node[el] {\m{f}} (34);
	\draw[gfa]  (36) to[out=- 80 ,in= 80] node[el,anchor=west] {\m{g}} (34);


	\node (31jl)  [above left = -0.2cm and 0cm of 31] {$\sqcup$};
	\node (32jl)  [above left = -0.2cm and 0cm of 32] {$\sqcup$};
	\node (34jl)  [above left = -0.2cm and 0cm of 34] {$\sqcup$};
	\node (36jl)  [above left = -0.2cm and 0cm of 36] {$\sqcup$};

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\node (11a) [left = 0.3cm of 11] {};
	\draw[se] (11) to[out=180,in=0] (11a) to[out=180,in=0] (1);
	\node (21a) [left = 0.3cm of 21] {};
	\draw[se] (21) to[out=180,in=0] (21a) to[out=180,in=0] (1);

	\node (3c) [above= 0.1cm of 3] {};
	\node (12a) [left = 0.3cm of 12] {};
	\draw[se] ( 12.180) to[out=180,in=0] (12a.0) to[out=180,in=0] (   2.0);
	%  \draw[se] ( 12.180) to[out=180,in=0] (12a.0) to[out=180,in=0] (3c) to[out=180,in=0] (   2.0);


	\node (5c) [above= 0.1cm of 5] {};
	\node (14a) [left = 0.5cm of 14] {};
	\draw[se] (14.180) to[out=180,in=0] (14a.0) to[out=180,in=0]( 4.0);
	%  \draw[se] (14.180) to[out=180,in=0] (14a.0) to[out=180,in=0] (5c) to[out=180,in=0]( 4.0);
	\draw[se] (16) to[out=180,in=0]  (6);

	\node (3d) [below= 0.1cm of 3] {};
	\node (22a) [left = 0.3cm of 22] {};
	\draw[se] ( 22.180) to[out=180,in=0] (22a.0) to[out=180,in=0] (   3.0);

	\node (5d) [below= 0.1cm of 5] {};
	\node (24a) [left = 0.5cm of 24] {};
	%  \draw[se] (24.180) to[out=180,in=0] (24a.0) to[out=180,in=0] (5d) to[out=180,in=0]( 4.0);
	\draw[se] (24.180) to[out=180,in=0] (24a.0) to[out=180,in=0]( 5.0);
	\draw[se] (26.180) to[out=180,in=0]  (7.0);

	\draw[se] (31) to[out=180,in=0] (11);
	\draw[se] (31) to[out=180,in=0] (21);

	\draw[se] (32) to[out=180,in=0] (12);
	\draw[se] (32) to[out=180,in=0] (22);
	\draw[se] (34) to[out=180,in=0] (14);
	\draw[se] (34) to[out=180,in=0] (24);
	\draw[se] (36) to[out=180,in=0] (16);
	\draw[se] (36) to[out=180,in=0] (26);

	\draw[ie] (36) to[loop above] node[el,below] {\m{\neq}} (36);


\draw[draw=none, use as bounding box] (current bounding box.north west) rectangle (current bounding box.south east);

\begin{pgfinterruptboundingbox}
	\draw[separator] (2.5cm,-3.3cm) to (2.5cm,6.9cm);
	\draw[separator] (6.5cm,-3.3cm) to (6.5cm,6.9cm);
\end{pgfinterruptboundingbox}

\end{tikzpicture}

\caption{
Join sources
}
\label{snippet3.16b_graph1}
\end{figure}
We have marked here the outgoing source edges from EC nodes in the join CFG node \node{n_4} with a join symbol as they represent a join of two sets of sources - in the above example all these sets are singletons.

In ~\ref{snippet3.17a_graph} we have a join where some join nodes share a source in one joinee, 
but not in both (not relevant sources and rgfas are ommitted):
\begin{figure}[!ht]
\begin{tikzpicture}
  \node (1)  {};
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \node[gttn] (11)  [above right= 2.5cm and 0cm of 1] {$()$};
	\node[gl]   (11l) [below = 0 of 11]   {\m{n_2}};

  \node[gtn]  (12) [above left  = 1cm and 1cm of 11] {\s{a,b}};
  \node[gtn]  (14) [above right = 1cm and 1cm of 11] {\s{c}};
	
  \draw[gfa] (12)  to[bend right] node[el]             {\m{a}} (11);
  \draw[gfa] (12)  to[bend left]  node[el,anchor=west] {\m{b}} (11);
  \draw[gfa] (14)  to             node[el]             {\m{c}} (11);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \node[gttn] (21)  [below right= 2.5cm and 0cm of 1] {$()$};
	\node[gl]   (21l) [below = 0 of 21]   {\m{n_3}};

  \node[gtn]  (22) [above left  = 1.0cm and 1.0cm of 21] {\s{a}};
  \node[gtn]  (23) [above right = 1.0cm and 1.0cm of 21] {\s{b,c}};
	
  \draw[gfa] (22) to             node[el,anchor=east] {\m{a}} (21);
  \draw[gfa] (23) to[bend right] node[el,anchor=west] {\m{b}} (21);
  \draw[gfa] (23) to[bend left]  node[el,anchor=west] {\m{c}} (21);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \node[gttn] (31)  [right = 6cm of 1] {$()$};
	\node[gl]   (31l) [below = 0 of 31]   {\m{n_4}};

%  \node (31jl)  [above left = -0.2cm and 0cm of 31] {$\sqcup$};

  \node[gtn]  (32) [above left  = 1.0cm and 1.0cm of 31] {\m{a}};
  \node[gtn]  (33) [above       = 0.9cm           of 31] {\m{b}};
  \node[gtn]  (34) [above right = 1.0cm and 1.0cm of 31] {\m{c}};
	
  \draw[gfa]  (32)  to node[el,anchor=east] {\m{a}} (31);
  \draw[gfa]  (33)  to node[el,anchor=west] {\m{b}} (31);
  \draw[gfa]  (34)  to node[el,anchor=west] {\m{c}} (31);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	\draw[se] (31) to[out=180,in=0] (11);
%	\draw[se] (31) to[out=180,in=0] (21);

	\node (12a) [right = 0.5cm of 12] {};
	\node (23a) [right = 0.5cm of 23] {};
	\draw[se] (32) to[out=180,in=0] (12a) to[out=180,in=0] (12);
	\draw[se] (32) to[out=180,in=0] (22);
	\draw[se] (33) to[out=180,in=0] (12a)  to[out=180,in=0] (12);
	\draw[se] (33) to[out=180,in=0] (23a)  to[out=180,in=0] (23);
	\draw[se] (34) to[out=180,in=0] (14);
	\draw[se] (34) to[out=180,in=0] (23a) to[out=180,in=0] (23);

\draw[draw=none, use as bounding box] (current bounding box.north west) rectangle (current bounding box.south east);

\begin{pgfinterruptboundingbox}
	\draw[separator] (3.5cm,-3.3cm) to (3.5cm,6.9cm);
\end{pgfinterruptboundingbox}

\end{tikzpicture}

\caption{
Join shared sources\\
before \lstinline{assume a=c}
}
\label{snippet3.17a_graph}
\end{figure}
Here \m{n_4.\s{b}} shares the source \m{n_2.\s{a,b}} with \m{n_4.\s{a}}, and the source \m{n_3.\s{c,c}} with \m{n_4.\s{c}}.

\noindent
Now we show what happens to ~\ref{snippet3.17a_graph} if we try to \lstinline{assume a=c} at the join:
\begin{figure}[H]
\begin{tikzpicture}
  \node (1)  {};
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \node[gttn] (11)  [above right= 2.5cm and 0cm of 1] {$()$};
	\node[gl]   (11l) [below = 0 of 11]   {\m{n_2}};

  \node[gtn]  (12) [above left  = 1cm and 1cm of 11] {\s{a,b}};
  \node[gtn]  (14) [above right = 1cm and 1cm of 11] {\s{c}};
	
  \draw[gfa] (12)  to[bend right] node[el]             {\m{a}} (11);
  \draw[gfa] (12)  to[bend left]  node[el,anchor=west] {\m{b}} (11);
  \draw[gfa] (14)  to             node[el]             {\m{c}} (11);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \node[gttn] (21)  [below right= 2.5cm and 0cm of 1] {$()$};
	\node[gl]   (21l) [below = 0 of 21]   {\m{n_3}};

  \node[gtn]  (22) [above left  = 1.0cm and 1.0cm of 21] {\s{a}};
  \node[gtn]  (23) [above right = 1.0cm and 1.0cm of 21] {\s{b,c}};
	
  \draw[gfa] (22) to             node[el,anchor=east] {\m{a}} (21);
  \draw[gfa] (23) to[bend right] node[el,anchor=west] {\m{b}} (21);
  \draw[gfa] (23) to[bend left]  node[el,anchor=west] {\m{c}} (21);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \node[gttn] (31)  [right = 6cm of 1] {$()$};
	\node[gl]   (31l) [below = 0 of 31]   {\m{n_4}};

%  \node (31jl)  [above left = -0.2cm and 0cm of 31] {$\sqcup$};

  \node[gtn]  (32) [above left  = 1.0cm and 1.0cm of 31] {\s{a,c}};
  \node[gtn]  (33) [above right = 1.0cm and 1.0cm of 31] {\s{b}};
	
  \draw[gfa]  (32)  to[bend right] node[el,anchor=east] {\m{a}} (31);
  \draw[gfa]  (32)  to[bend left]  node[el,anchor=east] {\m{c}} (31);
  \draw[gfa]  (33)  to             node[el,anchor=west] {\m{b}} (31);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	\draw[se] (31) to[out=180,in=0] (11);
%	\draw[se] (31) to[out=180,in=0] (21);

	\node (12a) [right = 0.5cm of 12] {};
	\node (23a) [right = 0.5cm of 23] {};
	\node (32b) [above left = 0.2cm and 1.0cm of 32] {};
	\node (32c) [below left = 0.2cm and 1.0cm of 32] {};
	\draw[se,ultra thick] (32) to[out=180,in=0] (32b) to[out=180,in=0] (12a) to[out=180,in=0] (12);
	\draw[se] (32) to[out=180,in=0] (32c) to[out=180,in=0] (22);
	\draw[se] (32) to[out=180,in=0] (32b) to[out=180,in=0] (14);
	\draw[se,ultra thick] (32) to[out=180,in=0] (32c) to[out=180,in=0] (23a) to[out=180,in=0] (23);
	\draw[se,ultra thick] (33) to[out=180,in=0] (12a) to[out=180,in=0] (12);
	\draw[se,ultra thick] (33) to[out=180,in=0] (23a) to[out=180,in=0] (23);

\draw[draw=none, use as bounding box] (current bounding box.north west) rectangle (current bounding box.south east);

\begin{pgfinterruptboundingbox}
	\draw[separator] (3.5cm,-3.3cm) to (3.5cm,6.9cm);
\end{pgfinterruptboundingbox}

\end{tikzpicture}

\caption{
Join shared sources\\
after \lstinline{assume a=c} \\
broken
}
\label{snippet3.17b_graph}
\end{figure}
In ~\ref{snippet3.17b_graph} we have highlighted the shared pair of sources for the nodes \s{a,c}, \s{b} at \node{n_4} - 
for joins this means that the first part of the propagation invariant is broken.
The fixed graphs are shown in ~\ref{snippet3.17c_graph}
\begin{figure}[H]
\begin{tikzpicture}
  \node (1)  {};
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \node[gttn] (11)  [above right= 2.5cm and 0cm of 1] {$()$};
	\node[gl]   (11l) [below = 0 of 11]   {\m{n_2}};

  \node[gtn]  (12) [above left  = 1cm and 1cm of 11] {\s{a,b}};
  \node[gtn]  (14) [above right = 1cm and 1cm of 11] {\s{c}};
	
  \draw[gfa] (12)  to[bend right] node[el]             {\m{a}} (11);
  \draw[gfa] (12)  to[bend left]  node[el,anchor=west] {\m{b}} (11);
  \draw[gfa] (14)  to             node[el]             {\m{c}} (11);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \node[gttn] (21)  [below right= 2.5cm and 0cm of 1] {$()$};
	\node[gl]   (21l) [below = 0 of 21]   {\m{n_3}};

  \node[gtn]  (22) [above left  = 1.0cm and 1.0cm of 21] {\s{a}};
  \node[gtn]  (23) [above right = 1.0cm and 1.0cm of 21] {\s{b,c}};
	
  \draw[gfa] (22) to             node[el,anchor=east] {\m{a}} (21);
  \draw[gfa] (23) to[bend right] node[el,anchor=west] {\m{b}} (21);
  \draw[gfa] (23) to[bend left]  node[el,anchor=west] {\m{c}} (21);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \node[gttn] (31)  [right = 5cm of 1] {$()$};
	\node[gl]   (31l) [below = 0 of 31]   {\m{n_4}};

%  \node (31jl)  [above left = -0.2cm and 0cm of 31] {$\sqcup$};

  \node[gtn]  (32) [above= 1.0cmof 31] {\s{a,b,c}};
	
  \draw[gfa]  (32)  to[bend right] node[el,anchor=east] {\m{a}} (31);
  \draw[gfa]  (32)  to             node[el,anchor=west] {\m{b}} (31);
  \draw[gfa]  (32)  to[bend left]  node[el,anchor=west] {\m{c}} (31);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	\draw[se] (31) to[out=180,in=0] (11);
%	\draw[se] (31) to[out=180,in=0] (21);

	\node (12a) [right = 0.5cm of 12] {};
	\node (23a) [right = 0.5cm of 23] {};
	\node (32b) [above left = 0.2cm and 1.0cm of 32] {};
	\node (32c) [below left = 0.2cm and 1.0cm of 32] {};
	\draw[se] (32) to[out=180,in=0] (32b) to[out=180,in=0] (12a) to[out=180,in=0] (12);
	\draw[se] (32) to[out=180,in=0] (32c) to[out=180,in=0] (22);
	\draw[se] (32) to[out=180,in=0] (32b) to[out=180,in=0] (14);
	\draw[se] (32) to[out=180,in=0] (32c) to[out=180,in=0] (23a) to[out=180,in=0] (23);

\draw[draw=none, use as bounding box] (current bounding box.north west) rectangle (current bounding box.south east);

\begin{pgfinterruptboundingbox}
	\draw[separator] (4.0cm,-3.3cm) to (4.0cm,4.2cm);
\end{pgfinterruptboundingbox}

\end{tikzpicture}

\caption{
Join shared sources
}
\label{snippet3.17c_graph}
\end{figure}

The condition for propagation completeness is that separate nodes cannot share a source in all predecessors - this is a generalization of the rule for sequential nodes. We will soon show that this is insufficient, and formalize the complete version of the condition.

Now for gfa completeness - the following example shows a join with the gfa invariant broken:
\begin{figure}[H]
\begin{tikzpicture}
  \node (1)  {};
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \node[gttn] (11)  [above right= 2.5cm and 0cm of 1] {$()$};
	\node[gl]   (11l) [below = 0 of 11]   {\m{n_2}};

	\node[gtn]  (12) [above left  = 1cm and 1cm of 11] {\s{a}};
	\node[gtn]  (14) [above right = 1cm and 1cm of 11] {\s{b}};
	
	\draw[gfa] (12)  to node[el]  {\m{a}} (11);
	\draw[gfa] (14)  to node[el]  {\m{b}} (11);

	\node[gttn] (15)  [above = 1cm of 12]    {\m{(a)}};
	\node[gttn,ultra thick] (17)  [above = 1cm of 14]    {\m{(b)}};

	\draw[sgtt] (15) to node[el] {0} (12);
	\draw[sgtt] (17) to node[el] {0} (14);

	\node[gtn,ultra thick]  (18) [above = 3cm of 11] {\tiny$\faB{f}{a}{b}$};
	\draw[gfa]  (18) to node[el] {\m{f}} (15);
	\draw[gfa,ultra thick]  (18) to node[el,anchor=west] {\m{f}} (17);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\node[gttn] (21)  [below right= 3.0cm and 0cm of 1] {$()$};
	\node[gl]   (21l) [below = 0 of 21]   {\m{n_3}};

  \node[gtn]  (22) [above  = 1.0cm of 21] {\s{a,b}};
	
  \draw[gfa] (22) to[bend right] node[el,anchor=east] {\m{a}} (21);
  \draw[gfa] (22) to[bend left]  node[el,anchor=west] {\m{b}} (21);

	\node[gttn,ultra thick] (25)  [above = 1cm of 22]    {\m{(\s{a,b})}};

	\draw[sgtt] (25) to node[el] {0} (22);

  \node[gtn,ultra thick]  (28) [above = 1cm of 25] {\tiny$\faB{f}{a}{b}$};
	\draw[gfa,ultra thick]  (28) to node[el] {\m{f}} (25);
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \node[gttn] (31)  [right = 6cm of 1] {$()$};
	\node[gl]   (31l) [below = 0 of 31]   {\m{n_4}};

  \node[gtn]  (32) [above left  = 1cm and 1cm of 31] {\s{a}};
  \node[gtn]  (34) [above right = 1cm and 1cm of 31] {\s{b}};

  \draw[gfa]  (32)  to node[el,anchor=east]  {\m{a}} (31);
  \draw[gfa]  (34)  to node[el,anchor=west]  {\m{b}} (31);

	\node[gttn] (35)  [above = 1cm of 32]    {\m{(a)}};
	\node[gttn] (37)  [above = 1cm of 34]    {\m{(b)}};

	\draw[sgtt] (35) to node[el] {0} (32);
	\draw[sgtt] (37) to node[el] {0} (34);

	\node[gtn,ultra thick]  (38) [above right = 1cm and 1cm of 35] {$\m{f(a)}$};
	\draw[gfa]  (38) to node[el,anchor=east] {\m{f}} (35);
	\draw[mgfa,ultra thick] (38) to node[ml,anchor=west] {\m{f}} (37);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\node (15a) [right = 0.5cm of 15] {};
	\node (35b) [above left = 0.2cm and 1.5cm of 35] {};
	\node (35c) [below left = 0.2cm and 1.5cm of 35] {};
	\node (37b) [above left = 0.2cm and 1.5cm of 37] {};
	\node (37c) [below left = 0.2cm and 1.5cm of 37] {};
	\draw[se,ultra thick] (37) to[out=180,in=0] (37b) to[out=180,in=0] (17);
	\draw[se,ultra thick] (37) to[out=180,in=0] (37c) to[out=180,in=0] (25);

	\node (18a) [right = 0.5cm of 18] {};
	\node (38b) [above left = 0.2cm and 1.5cm of 38] {};
	\node (38c) [below left = 0.2cm and 1.5cm of 38] {};
	\draw[se,ultra thick] (38) to[out=180,in=0] (38b) to[out=180,in=0] (18a) to[out=180,in=0] (18);
	\draw[se,ultra thick] (38) to[out=180,in=0] (38c) to[out=180,in=0] (28);

\draw[draw=none, use as bounding box] (current bounding box.north west) rectangle (current bounding box.south east);

\begin{pgfinterruptboundingbox}
	\draw[separator] (3.5cm,-3.3cm) to (3.5cm,6.5cm);
\end{pgfinterruptboundingbox}

\end{tikzpicture}

\caption{
Join gfa completeness
}
\label{snippet3.18a_graph}
\end{figure}
Here we see that if a gfa with the same function symbol exists in the source (here source for \m{f(a)}) all joinees, 
where the gfa tuples in all joinees are the source for a tuple in the join node (here \s{(b)}), then we must have that gfa also in the join. Again this is a generalization of the condition for sequential nodes.\\
However, for downward propagation the situation becomes somewhat more delicate - compare ~\ref{snippet3.18a_graph} and ~\ref{snippet3.19_graph}:
\begin{figure}[H]
\begin{tikzpicture}
  \node (1)  {};
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \node[gttn] (11)  [above right= 2.5cm and 0cm of 1] {$()$};
	\node[gl]   (11l) [below = 0 of 11]   {\m{n_2}};

	\node[gtn]              (12) [above left  = 1cm and 1cm of 11] {\s{a}};
	\node[gtn,ultra thick]  (14) [above right = 1cm and 1cm of 11] {\s{b}};
	
	\draw[gfa]              (12)  to node[el,anchor=east]  {\m{a}} (11);
	\draw[mgfa,ultra thick] (14)  to node[el,anchor=west]  {\color{red}\m{\mathbf{b}}} (11);

	\node[gttn]             (12a)  [above = 1cm of 12]    {\m{(a)}};
	\node[gttn,ultra thick] (14a)  [above = 1cm of 14]    {\m{(b)}};

	\draw[sgtt]             (12a) to node[el,anchor=east] {0} (12);
	\draw[sgtt,ultra thick] (14a) to node[el,anchor=west] {\textbf{0}} (14);

	\node[gtn,ultra thick]  (15) [above = 3cm of 11] {\tiny$\faB{f}{a}{b}$};
	\draw[gfa]              (15) to node[el,anchor=east] {\m{f}} (12a);
	\draw[gfa,ultra thick]  (15) to node[el,anchor=west] {\m{\mathbf{f}}} (14a);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\node[gttn] (21)  [below right= 3.0cm and 0cm of 1] {$()$};
	\node[gl]   (21l) [below = 0 of 21]   {\m{n_3}};

  \node[gtn,ultra thick]  (22) [above  = 1.0cm of 21] {\s{a,c}};
	
  \draw[gfa]              (22) to[bend right] node[el,anchor=east] {\m{a}} (21);
  \draw[mgfa,ultra thick] (22) to[bend left]  node[el,anchor=west] {\color{red}\m{c}} (21);

	\node[gttn,ultra thick] (22a)  [above = 1cm of 22]    {\m{(\s{a,c})}};

	\draw[sgtt,ultra thick] (22a) to node[el,anchor=west] {\textbf{0}} (22);

  \node[gtn,ultra thick]  (25) [above = 1cm of 22a] {\tiny$\faB{f}{a}{c}$};
	\draw[gfa,ultra thick]  (25) to node[el,anchor=west] {\m{\mathbf{f}}} (22a);
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \node[gttn] (31)  [right = 6cm of 1] {$()$};
	\node[gl]   (31l) [below = 0 of 31]   {\m{n_4}};

  \node[gtn]  (32) [above = 1cm of 31] {\s{a}};

  \draw[gfa]  (32)  to node[el,anchor=east]  {\m{a}} (31);

	\node[gttn] (32a)  [above = 1cm of 32]    {\m{(a)}};

	\draw[sgtt] (32a) to node[el] {0} (32);

	\node[gtn]  (35) [above = 1cm of 32a] {$\m{f(a)}$};
	\draw[gfa]  (35) to node[el,anchor=east] {\m{f}} (32a);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\node (18a) [right = 0.5cm of 18] {};
	\node (35b) [above left = 0.2cm and 1.5cm of 35] {};
	\node (35c) [below left = 0.2cm and 1.5cm of 35] {};
	\draw[se] (35) to (35b) to (15);
	\draw[se] (35) to (35c) to (25);

\draw[draw=none, use as bounding box] (current bounding box.north west) rectangle (current bounding box.south east);

\begin{pgfinterruptboundingbox}
	\draw[separator] (3.5cm,-3.3cm) to (3.5cm,6.5cm);
\end{pgfinterruptboundingbox}

\end{tikzpicture}

\caption{
Join gfa completeness\\
downward propagation path infeasible
}
\label{snippet3.19_graph}
\end{figure}
Here we can see that if we try to traverse the gfa in lock-step between the two joinees, 
from \m{f(\s{b})} in \m{n_2} and \m{f(\s{a,c})} in \m{n_3}, we will get stuck when the labels \m{b} and \m{c} do not match.\\
This example will have indistinguishable traversal from the one in ~\ref{snippet3.18a_graph} until the last edge 
(remember that node labels are only here for convenience, and are not always representable as a finite or compact set - 
we only match edge labels when traversing), hence we could, in theory perform many unnecessary such traversals that will produce no new nodes.\\
Worse still, consider the following example:
\begin{figure}[H]
\begin{tikzpicture}
  \node (1)  {};
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \node[gttn] (11)  [above right= 2.5cm and 0cm of 1] {$()$};
	\node[gl]   (11l) [below = 0 of 11]   {\m{n_2}};

  \node[gtn]  (13) [above left  = 1cm and 1cm of 11] {\s{b}};
  \node[gtn]  (14) [above       = 0.95cm      of 11] {\s{c}};
  \node[gtn]  (15) [above right = 1cm and 1cm of 11] {\s{d}};
	
  \draw[gfa] (13)  to node[el]             {\m{b}} (11);
  \draw[gfa] (14)  to node[el,anchor=west] {\m{c}} (11);
  \draw[gfa] (15)  to node[el]             {\m{d}} (11);

  \node[gttn] (13a) [above =1.0cm of 13] {$\m{(b)}$};
  \node[gttn] (14a) [above =1.0cm of 14] {$\m{(c)}$};
  \node[gttn] (15a) [above =1.0cm of 15] {$\m{(d)}$};
	
  \draw[sgtt] (13a)  to node[el]          {\m{0}} (13)
						  (14a)  to node[el]          {\m{0}} (14)
	            (15a)  to node[el]          {\m{0}} (15);
	
  \node[gtn] (16)  [above = 1cm of 14a] {\s{a,f(b),f(c),f(d)}};
  \draw[gfa] (16)  to node[el,anchor=east] {\m{f}} (13a);
  \draw[gfa] (16)  to node[el,anchor=west] {\m{f}} (14a);
  \draw[gfa] (16)  to node[el,anchor=west] {\m{f}} (15a);
	\draw[gfa] (16)  to[bend right=35] node[el,anchor=east] {\m{a}} (11);
	
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \node[gttn] (21)  [below right= 2.5cm and 0cm of 1] {$()$};
	\node[gl]   (21l) [below = 0 of 21]   {\m{n_3}};

  \node[gtn]  (23) [above left  = 1cm and 1cm of 21] {\s{x}};
  \node[gtn]  (24) [above       = 0.95cm      of 21] {\s{y}};
  \node[gtn]  (25) [above right = 1cm and 1cm of 21] {\s{z}};
	
  \draw[gfa] (23)  to node[el]             {\m{x}} (21);
  \draw[gfa] (24)  to node[el,anchor=west] {\m{y}} (21);
  \draw[gfa] (25)  to node[el]             {\m{z}} (21);

  \node[gttn] (23a) [above =1.0cm of 23] {$\m{(x)}$};
  \node[gttn] (24a) [above =1.0cm of 24] {$\m{(y)}$};
  \node[gttn] (25a) [above =1.0cm of 25] {$\m{(z)}$};
	
  \draw[sgtt] (23a)  to node[el]          {\m{0}} (23)
						  (24a)  to node[el]          {\m{0}} (24)
	            (25a)  to node[el]          {\m{0}} (25);
	
  \node[gtn] (26)  [above = 1cm of 24a] {\s{a,f(x),f(y),f(z)}};
  \draw[gfa] (26)  to node[el,anchor=east] {\m{f}} (23a);
  \draw[gfa] (26)  to node[el,anchor=west] {\m{f}} (24a);
  \draw[gfa] (26)  to node[el,anchor=west] {\m{f}} (25a);
	\draw[gfa] (26)  to[bend right=35] node[el,anchor=east] {\m{a}} (21);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \node[gttn] (31)  [right = 5cm of 1] {$()$};
	\node[gl]   (31l) [below = 0 of 31]   {\m{n_4}};

%  \node (31jl)  [above left = -0.2cm and 0cm of 31] {$\sqcup$};

  \node[gtn]  (32) [above= 1.0cm of 31] {\s{a}};
	
  \draw[gfa]  (32)  to[bend right] node[el,anchor=east] {\m{a}} (31);
  \draw[gfa]  (32)  to             node[el,anchor=west] {\m{b}} (31);
  \draw[gfa]  (32)  to[bend left]  node[el,anchor=west] {\m{c}} (31);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\draw[se] (31) to[out=180,in=0] (11);
	\draw[se] (31) to[out=180,in=0] (21);

	\draw[se] (32) to[out=180,in=0] (16);
	\draw[se] (32) to[out=180,in=0] (26);

	%\node (12a) [right = 0.5cm of 12] {};
	%\node (23a) [right = 0.5cm of 23] {};
	%\node (32b) [above left = 0.2cm and 1.0cm of 32] {};
	%\node (32c) [below left = 0.2cm and 1.0cm of 32] {};
	%\draw[se] (32) to[out=180,in=0] (32b) to[out=180,in=0] (12a) to[out=180,in=0] (12);
	%\draw[se] (32) to[out=180,in=0] (32c) to[out=180,in=0] (22);
	%\draw[se] (32) to[out=180,in=0] (32b) to[out=180,in=0] (14);
	%\draw[se] (32) to[out=180,in=0] (32c) to[out=180,in=0] (23a) to[out=180,in=0] (23);

\draw[draw=none, use as bounding box] (current bounding box.north west) rectangle (current bounding box.south east);

\begin{pgfinterruptboundingbox}
	\draw[separator] (4.0cm,-3.3cm) to (4.0cm,4.2cm);
\end{pgfinterruptboundingbox}
\end{tikzpicture}
\caption{
Join shared sources
}
\label{snippet3.20_graph}
\end{figure}
The graphs in ~\ref{snippet3.20_graph} are actually source and propagation complete, 
but if we tried to check that by following matching paths from the top down 
(that is, from \m{n_2.\s{a,f(b),f(c),f(g)}} and \m{n_3.\s{a,f(x),f(y),f(z)}}), we would end up with 9 different paths that produce no nodes - generally quadratic in the size of the joined graphs (essentially we need to consider a pair of nodes, one from each joinee, at most once). In some cases the join itself would be quadratic if we want a complete join as per our completeness definitions (we will discuss this in the following), but in general we do not want a sub-quadratic result to take a quadratic time to produce.\\
In light of this the join algorithm will be slightly more complex, propagating upward and downwards in order to prevent an unnecesary quadratic explosion.

\noindent
However, there is another completeness problem peculiar to joins, alluded to before - consider again ~\ref{snippet3.3}, whose graph is as follows:
\begin{figure}[H]
\begin{tikzpicture}
  \node (1)  {};
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \node[gttn] (11)  [above right= 2.5cm and 0cm of 1] {$()$};
	\node[gl]   (11l) [below = 0 of 11]   {\m{p_0}};

	\node[gtn]  (12) [above left  = 1cm and 1cm of 11] {\s{a}};
	\node[gtn]  (14) [above right = 1cm and 1cm of 11] {\s{b}};
	
	\draw[gfa]  (12)  to node[el,anchor=east]  {\m{a}} (11);
	\draw[gfa]  (14)  to node[el,anchor=west]  {\m{b}} (11);

	\node[gttn] (12a)  [above = 1cm of 12]    {\m{(a)}};
	\node[gttn] (14a)  [above = 1cm of 14]    {\m{(b)}};

	\draw[sgtt] (12a) to node[el,anchor=east] {0} (12);
	\draw[sgtt] (14a) to node[el,anchor=west] {0} (14);

	\node[gtn]  (15) [above = 3cm of 11] {\tiny$\faB{f}{a}{b}$};
	\draw[gfa]  (15) to node[el,anchor=east] {\m{f}} (12a);
	\draw[gfa]  (15) to node[el,anchor=west] {\m{f}} (14a);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\node[gttn] (21)  [below right= 3.0cm and 0cm of 1] {$()$};
	\node[gl]   (21l) [below = 0 of 21]   {\m{p_1}};

  \node[gtn]  (22) [above  = 1.0cm of 21] {\s{a,b}};
	
  \draw[gfa] (22) to[bend right] node[el,anchor=east] {\m{a}} (21);
  \draw[gfa] (22) to[bend left]  node[el,anchor=west] {\m{b}} (21);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \node[gttn] (31)  [right = 6cm of 1] {$()$};
	\node[gl]   (31l) [below = 0 of 31]   {\m{n}};

  \node[gtn]  (32) [above = 1cm of 31] {\s{a}};

  \draw[gfa]  (32)  to node[el,anchor=east]  {\m{a}} (31);

	\node[gttn] (32a)  [above = 1cm of 32]    {\m{(a)}};

	\draw[sgtt] (32a) to node[el] {0} (32);

%	\node[gtn]  (35) [above = 1cm of 32a] {$\m{f(a)}$};
%	\draw[gfa]  (35) to node[el,anchor=east] {\m{f}} (32a);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\node (32u) [above left = 0.2cm and 1.0cm of 32] {};
	\node (32d) [below left = 0.2cm and 1.0cm of 32] {};
	\draw[se] (32) to (32u) to (12);
	\draw[se] (32) to (32u) to (13);
	\draw[se] (32) to (32d) to (22);

	\node (32au) [above left = 0.2cm and 1.0cm of 32a] {};
%	\node (32ad) [below left = 0.2cm and 1.5cm of 32a] {};
	\draw[se] (32a) to (32au) to (12a);
%	\draw[se] (32a) to (32au) to (14a);
%	\draw[se] (32a) to (32d) to (22);
\draw[draw=none, use as bounding box] (current bounding box.north west) rectangle (current bounding box.south east);

\begin{pgfinterruptboundingbox}
	\draw[separator] (3.5cm,-3.3cm) to (3.5cm,6.5cm);
\end{pgfinterruptboundingbox}

\end{tikzpicture}

\caption{
Join gfa completeness missing paths\\
before $\m{n}$.\lstinline{add(f(a))}
}
\label{snippet3.20_graph2}
\end{figure}
Clearly, if we want to \lstinline{add(f(a))} to \m{n}, just following gfa paths downwards will not do.\\
Our solution is, essentially, to traverse and mark, at \m{p_0}, the path \s{f(a),f(b)} - \s{(b)} - \s{b} - \s{()} until we hit a node that is a common source with one from \m{p_1} - in this case \s{()}, 
now we can traverse up the marked path in lock-step as long as both joinees agree - so we get to the pair \m{[\s{b},\s{a,b}]}, 
and now we cannot traverse in lock-step anymore, but we can see that \s{a,b} would be the source of \s{b} at \m{n}, 
but also of \s{a}, which has \s{a} at \m{p_0} as a source - so we know that applying the function \m{f} to both at \m{p_0} 
would give the same result (same node, if we were to create it) at \m{p_1} - 
so now we traverse the nodes \s{a} and \s{b} at \m{p_0} in lock-step as long as one has a marked path and they agree on edge labels, until we reach \s{f(a),f(b)} - here they converge and so we know they should lead to the same node at the join - we end up with:
\begin{figure}[H]
\begin{tikzpicture}
  \node (1)  {};
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \node[gttn] (11)  [above right= 2.5cm and 0cm of 1] {$()$};
	\node[gl]   (11l) [below = 0 of 11]   {\m{p_1}};

	\node[gtn]  (12) [above left  = 1cm and 1cm of 11] {\s{a}};
	\node[gtn]  (14) [above right = 1cm and 1cm of 11] {\s{b}};
	
	\draw[gfa]  (12)  to node[el,anchor=east]  {\m{a}} (11);
	\draw[gfa]  (14)  to node[el,anchor=west]  {\m{b}} (11);

	\node[gttn] (12a)  [above = 1cm of 12]    {\m{(a)}};
	\node[gttn] (14a)  [above = 1cm of 14]    {\m{(b)}};

	\draw[sgtt] (12a) to node[el,anchor=east] {0} (12);
	\draw[sgtt] (14a) to node[el,anchor=west] {0} (14);

	\node[gtn]  (15) [above = 3cm of 11] {\tiny$\faB{f}{a}{b}$};
	\draw[gfa]  (15) to node[el,anchor=east] {\m{f}} (12a);
	\draw[gfa]  (15) to node[el,anchor=west] {\m{f}} (14a);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\node[gttn] (21)  [below right= 3.0cm and 0cm of 1] {$()$};
	\node[gl]   (21l) [below = 0 of 21]   {\m{p_2}};

  \node[gtn]  (22) [above  = 1.0cm of 21] {\s{a,b}};
	
  \draw[gfa] (22) to[bend right] node[el,anchor=east] {\m{a}} (21);
  \draw[gfa] (22) to[bend left]  node[el,anchor=west] {\m{b}} (21);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \node[gttn] (31)  [right = 6cm of 1] {$()$};
	\node[gl]   (31l) [below = 0 of 31]   {\m{n}};

	\node[gtn]  (32) [above left  = 1cm and 1cm of 31] {\s{a}};
	\node[gtn]  (34) [above right = 1cm and 1cm of 31] {\s{b}};
	
	\draw[gfa]  (32)  to node[el,anchor=east]  {\m{a}} (31);
	\draw[gfa]  (34)  to node[el,anchor=west]  {\m{b}} (31);

	\node[gttn] (32a)  [above = 1cm of 32]    {\m{(a)}};
	\node[gttn] (34a)  [above = 1cm of 34]    {\m{(b)}};

	\draw[sgtt] (32a) to node[el,anchor=east] {0} (32);
	\draw[sgtt] (34a) to node[el,anchor=west] {0} (34);

	\node[gtn]  (35) [above = 3.5cm of 31] {\tiny$\faB{f}{a}{b}$};
	\draw[gfa]  (35) to node[el,anchor=east] {\m{f}} (32a);
	\draw[gfa]  (35) to node[el,anchor=west] {\m{f}} (34a);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\node (32u) [above left = 0.2cm and 1.0cm of 32] {};
	\node (32d) [below left = 0.2cm and 1.0cm of 32] {};
	\draw[se] (32) to (32u) to (12);
	\draw[se] (32) to (32d) to (22);

	\node (34u) [above left = 0.2cm and 2.5cm of 34] {};
	\node (34d) [below left = 0.2cm and 2.5cm of 34] {};
	\draw[se] (34) to (34u) to (14);
	\draw[se] (34) to (34d) to (22);

	\node (32au) [above left = 2.2cm and 2.5cm of 32a] {};
	\draw[se] (32a) to[in=-10] (32au) to[out=170] (12a);

	\node (34au) [above left = 0.0cm and 2.0cm of 34a] {};
	\draw[se] (34a) to (34au) to (14a);


	\node (35u) [above left = 0.2cm and 1.0cm of 35] {};
	\draw[se] (35) to (15);

	\draw[green] (32a.0) to node[el,anchor=north,text=green] {$\m{p_1}$} (34a.180);
\draw[draw=none, use as bounding box] (current bounding box.north west) rectangle (current bounding box.south east);

\begin{pgfinterruptboundingbox}
	\draw[separator] (3.5cm,-3.3cm) to (3.5cm,6.5cm);
\end{pgfinterruptboundingbox}
\end{tikzpicture}
\caption{
Join gfa completeness missing paths\\
after $\m{n}$.\lstinline{add(f(a))}
}
\label{snippet3.20_graph3}
\end{figure}
\noindent
As expected.\\
The green line between \s{(a)} and \s{(b)} labeled \m{n} means that any super-term of of these tuples will be equal in \m{p_1} - 
we remember this fact so that we do not need to recalculate it - the full details are in the algorithm description in the next section.

\subsubsection*{The Source Invariant for Join Nodes}
The graph based source invariant for join nodes is slightly more complicated than the one for sequential nodes:\\
The issue is that in the sequential case we are assured that all equalities that hold in the predecessor node also hold in the successor node, hence for each term in the predecessor EC there will be a term in successor node.
If we were to translate this to the join case we would get (first part):\\
\m{\forall \fa{f}{t} \in \GFAECs{g_n}, \tup{s} \in \sources{n}{p}{\tup{t}} \cdot }\\
\m{\fa{f}{s} \in \GFAECs{g_p} \Rightarrow [\fa{f}{s}]_{g_p} \in \sources{n}{p}{[\fa{f}{t}]_{g_n}}}\\
However, consider the following example:\\
\m{\s{a=f(b),f(c)=d} \sqcup \s{}} where at the join node we have \m{b=c}:
\begin{figure}[H]
\begin{tikzpicture}
  \node (1)  {};
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \node[gttn] (11)  [above right= 2.5cm and 0cm of 1] {$()$};
	\node[gl]   (11l) [below = 0 of 11]   {\m{p_0}};

	\node[gtn]  (12) [above left  = 1cm and 1cm of 11] {\s{b}};
	\node[gtn]  (14) [above right = 1cm and 1cm of 11] {\s{c}};
	
	\draw[gfa]  (12)  to node[el,anchor=east]  {\m{b}} (11);
	\draw[gfa]  (14)  to node[el,anchor=west]  {\m{c}} (11);

	\node[gttn] (12a)  [above = 1cm of 12]    {\m{(b)}};
	\node[gttn] (14a)  [above = 1cm of 14]    {\m{(c)}};

	\draw[sgtt] (12a) to node[el,anchor=east] {0} (12);
	\draw[sgtt] (14a) to node[el,anchor=west] {0} (14);

	\node[gtn]  (15) [above = 1cm of 12a] {\tiny$\svb{a}{f(b)}$};
	\draw[gfa]  (15) to node[el,anchor=east] {\m{f}} (12a);
	\draw[gfa]  (15) to node[el,anchor=east] {\m{a}} (11);
	\node[gtn]  (16) [above = 1cm of 14a] {\tiny$\svb{d}{f(c)}$};
	\draw[gfa]  (16) to node[el,anchor=west] {\m{f}} (14a);
	\draw[gfa]  (16) to node[el,anchor=west] {\m{d}} (11);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\node[gttn] (21)  [below right= 3.0cm and 0cm of 1] {$()$};
	\node[gl]   (21l) [below = 0 of 21]   {\m{p_1}};

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \node[gttn] (31)  [right = 6cm of 1] {$()$};
	\node[gl]   (31l) [below = 0 of 31]   {\m{n}};

	\node[gtn]  (32) [above left  = 3cm and 1cm of 31] {\s{a}};
	\node[gtn]  (34) [above right = 1cm and 1cm of 31] {\s{b,c}};
	
	\draw[gfa]  (32)  to node[el,anchor=east]  {\m{a}} (31);
	\draw[gfa]  (34)  to[bend left]  node[el,anchor=west]  {\m{b}} (31);
	\draw[gfa]  (34)  to[bend right] node[el,anchor=west]  {\m{c}} (31);

%	\node[gttn] (32a)  [above = 1cm of 32]    {\m{(a)}};
%	\node[gttn] (34a)  [above = 1cm of 34]    {\m{(b)}};

%	\draw[sgtt] (32a) to node[el,anchor=east] {0} (32);
%	\draw[sgtt] (34a) to node[el,anchor=west] {0} (34);

%	\node[gtn]  (35) [above = 1cm of 32a] {\tiny$\s{f(a)}$};
%	\draw[gfa]  (35) to node[el,anchor=east] {\m{f}} (32a);
%	\draw[gfa]  (35) to node[el,anchor=west] {\m{f}} (34a);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\node (32nw) [above left = 0.6cm and 1.5cm of 32] {};
%	\node (32d) [below left = 0.2cm and 1.0cm of 32] {};
	\draw[se] (32) to (32nw) to (15);
%	\draw[se] (32) to (32d) to (22);

	\node (34u) [above left = 0.2cm and 2.5cm of 34] {};
	\node (34d) [below left = 0.2cm and 2.5cm of 34] {};
	\draw[se] (34) to (34u) to (12);
	\draw[se] (34) to (34u) to (14);
%	\draw[se] (34) to (34d) to (22);

%	\node (32au) [above left = 2.2cm and 2.5cm of 32a] {};
%	\draw[se] (32a) to[in=-10] (32au) to[out=170] (12a);

%	\node (34au) [above left = 0.0cm and 2.0cm of 34a] {};
%	\draw[se] (34a) to (34au) to (14a);


%	\node (35u) [above left = 0.2cm and 1.0cm of 35] {};
%	\draw[se] (35) to (15);

%	\draw[green] (32a.0) to node[el,anchor=north,text=green] {$\m{p_1}$} (34a.180);
\draw[draw=none, use as bounding box] (current bounding box.north west) rectangle (current bounding box.south east);

\begin{pgfinterruptboundingbox}
	\draw[separator] (3.5cm,-3.3cm) to (3.5cm,6.5cm);
\end{pgfinterruptboundingbox}
\end{tikzpicture}
\caption{
Join gfa completeness missing paths
}
\label{snippet3.22_graph1}
\end{figure}
Here actually \m{p_0,n \models a=d} and so we expect \m{[d]_{p_0} \in \sources{n}{p_0}{[a]_{n}}}.\\
One might consider this source unnecessary, as it does not contribute any node or edge to \m{g_n}, 
but in the incremental setting it is important - consider the case where \m{p_1} had, 
at the last time we had updated \m{g_n} :\\
\s{a=g(b), g(c), d}\\
As depicted below:
\begin{figure}[H]
\begin{tikzpicture}
  \node (1)  {};
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \node[gttn] (11)  [above right= 2.5cm and 0cm of 1] {$()$};
	\node[gl]   (11l) [below = 0 of 11]   {\m{p_0}};

	\node[gtn]  (12) [above left  = 1cm and 1cm of 11] {\s{b}};
	\node[gtn]  (14) [above right = 1cm and 1cm of 11] {\s{c}};
	
	\draw[gfa]  (12)  to node[el,anchor=east]  {\m{b}} (11);
	\draw[gfa]  (14)  to node[el,anchor=west]  {\m{c}} (11);

	\node[gttn] (12a)  [above = 1cm of 12]    {\m{(b)}};
	\node[gttn] (14a)  [above = 1cm of 14]    {\m{(c)}};

	\draw[sgtt] (12a) to node[el,anchor=east] {0} (12);
	\draw[sgtt] (14a) to node[el,anchor=west] {0} (14);

	\node[gtn]  (15) [above = 1cm of 12a] {\tiny$\svb{a}{f(b)}$};
	\draw[gfa]  (15) to node[el,anchor=east] {\m{f}} (12a);
	\draw[gfa]  (15) to node[el,anchor=east] {\m{a}} (11);
	\node[gtn]  (16) [above = 1cm of 14a] {\tiny$\svb{d}{f(c)}$};
	\draw[gfa]  (16) to node[el,anchor=west] {\m{f}} (14a);
	\draw[gfa]  (16) to node[el,anchor=west] {\m{d}} (11);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\node[gttn] (21)  [below right= 3.0cm and 0cm of 1] {$()$};
	\node[gl]   (21l) [below = 0 of 21]   {\m{p_1}};

	\node[gtn]  (22) [above left  = 1cm and 1cm of 21] {\s{b}};
	\node[gtn]  (24) [above right = 1cm and 1cm of 21] {\s{c}};
	
	\draw[gfa]  (22)  to node[el,anchor=east]  {\m{b}} (21);
	\draw[gfa]  (24)  to node[el,anchor=west]  {\m{c}} (21);

	\node[gttn] (22a)  [above = 1cm of 22]    {\m{(b)}};
	\node[gttn] (24a)  [above = 1cm of 24]    {\m{(c)}};

	\draw[sgtt] (22a) to node[el,anchor=east] {0} (22);
	\draw[sgtt] (24a) to node[el,anchor=west] {0} (24);

	\node[gtn]  (25) [above = 1cm of 22a] {\tiny$\svb{a}{g(b)}$};
	\draw[gfa]  (25) to node[el,anchor=east] {\m{g}} (22a);
	\draw[gfa]  (25) to node[el,anchor=east] {\m{a}} (21);
	\node[gtn]  (26) [above = 1cm of 24a] {\tiny$\s{g(c)}$};
	\draw[gfa]  (26) to node[el,anchor=west] {\m{g}} (24a);
%	\draw[gfa]  (26) to node[el,anchor=west] {\m{d}} (21);
	
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \node[gttn] (31)  [right = 6cm of 1] {$()$};
	\node[gl]   (31l) [below = 0 of 31]   {\m{n}};

	\node[gtn]  (32) [above left  = 3cm and 1cm of 31] {\s{a}};
	\node[gtn]  (34) [above right = 1cm and 1cm of 31] {\s{b,c}};
	
	\draw[gfa]  (32)  to node[el,anchor=east]  {\m{a}} (31);
	\draw[gfa]  (34)  to[bend left]  node[el,anchor=west]  {\m{b}} (31);
	\draw[gfa]  (34)  to[bend right] node[el,anchor=west]  {\m{c}} (31);

%	\node[gttn] (32a)  [above = 1cm of 32]    {\m{(a)}};
%	\node[gttn] (34a)  [above = 1cm of 34]    {\m{(b)}};

%	\draw[sgtt] (32a) to node[el,anchor=east] {0} (32);
%	\draw[sgtt] (34a) to node[el,anchor=west] {0} (34);

%	\node[gtn]  (35) [above = 1cm of 32a] {\tiny$\s{f(a)}$};
%	\draw[gfa]  (35) to node[el,anchor=east] {\m{f}} (32a);
%	\draw[gfa]  (35) to node[el,anchor=west] {\m{f}} (34a);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\node (32nw) [above left = 0.6cm and 1.5cm of 32] {};
	\node (32sw) [below left = 0.6cm and 1.5cm of 32] {};
%	\node (32d) [below left = 0.2cm and 1.0cm of 32] {};
	\draw[se] (32) to (32nw) to (15);
	\draw[se] (32) to (32sw) to (25);

	\node (34nw) [above left = 0.2cm and 1.5cm of 34] {};
	\node (34sw) [below left = 0.2cm and 1.5cm of 34] {};
	\draw[se] (34) to (34nw) to (12);
	\draw[se] (34) to (34nw) to (14);
	\draw[se] (34) to (34sw) to (22);
	\draw[se] (34) to (34sw) to (24);
%	\draw[se] (34) to (34d) to (22);

%	\node (32au) [above left = 2.2cm and 2.5cm of 32a] {};
%	\draw[se] (32a) to[in=-10] (32au) to[out=170] (12a);

%	\node (34au) [above left = 0.0cm and 2.0cm of 34a] {};
%	\draw[se] (34a) to (34au) to (14a);


%	\node (35u) [above left = 0.2cm and 1.0cm of 35] {};
%	\draw[se] (35) to (15);

%	\draw[green] (32a.0) to node[el,anchor=north,text=green] {$\m{p_1}$} (34a.180);
\draw[draw=none, use as bounding box] (current bounding box.north west) rectangle (current bounding box.south east);

\begin{pgfinterruptboundingbox}
	\draw[separator] (3.5cm,-3.3cm) to (3.5cm,6.5cm);
\end{pgfinterruptboundingbox}
\end{tikzpicture}
\caption{
Join gfa completeness missing paths\\
before $\m{p_1}$.\lstinline{assume(g(c)=d)}
}
\label{snippet3.22_graph2}
\end{figure}

Now we perform \m{p_1}.\lstinline{assume(g(c)=d)} to get:
\begin{figure}[H]
\begin{tikzpicture}
  \node (1)  {};
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \node[gttn] (11)  [above right= 2.5cm and 0cm of 1] {$()$};
	\node[gl]   (11l) [below = 0 of 11]   {\m{p_0}};

	\node[gtn]  (12) [above left  = 1cm and 1cm of 11] {\s{b}};
	\node[gtn]  (14) [above right = 1cm and 1cm of 11] {\s{c}};
	
	\draw[gfa]  (12)  to node[el,anchor=east]  {\m{b}} (11);
	\draw[gfa]  (14)  to node[el,anchor=west]  {\m{c}} (11);

	\node[gttn] (12a)  [above = 1cm of 12]    {\m{(b)}};
	\node[gttn] (14a)  [above = 1cm of 14]    {\m{(c)}};

	\draw[sgtt] (12a) to node[el,anchor=east] {0} (12);
	\draw[sgtt] (14a) to node[el,anchor=west] {0} (14);

	\node[gtn]  (15) [above = 1cm of 12a] {\tiny$\svb{a}{f(b)}$};
	\draw[gfa]  (15) to node[el,anchor=east] {\m{f}} (12a);
	\draw[gfa]  (15) to node[el,anchor=east] {\m{a}} (11);
	\node[gtn]  (16) [above = 1cm of 14a] {\tiny$\svb{d}{f(c)}$};
	\draw[gfa]  (16) to node[el,anchor=west] {\m{f}} (14a);
	\draw[gfa]  (16) to node[el,anchor=west] {\m{d}} (11);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\node[gttn] (21)  [below right= 3.0cm and 0cm of 1] {$()$};
	\node[gl]   (21l) [below = 0 of 21]   {\m{p_1}};

	\node[gtn]  (22) [above left  = 1cm and 1cm of 21] {\s{b}};
	\node[gtn]  (24) [above right = 1cm and 1cm of 21] {\s{c}};
	
	\draw[gfa]  (22)  to node[el,anchor=east]  {\m{b}} (21);
	\draw[gfa]  (24)  to node[el,anchor=west]  {\m{c}} (21);

	\node[gttn] (22a)  [above = 1cm of 22]    {\m{(b)}};
	\node[gttn] (24a)  [above = 1cm of 24]    {\m{(c)}};

	\draw[sgtt] (22a) to node[el,anchor=east] {0} (22);
	\draw[sgtt] (24a) to node[el,anchor=west] {0} (24);

	\node[gtn]  (25) [above = 1cm of 22a] {\tiny$\svb{a}{g(b)}$};
	\draw[gfa]  (25) to node[el,anchor=east] {\m{g}} (22a);
	\draw[gfa]  (25) to node[el,anchor=east] {\m{a}} (21);
	\node[gtn]  (26) [above = 1cm of 24a] {\tiny$\svb{\mathbf{d}}{g(c)}$};
	\draw[gfa]  (26) to node[el,anchor=west] {\m{g}} (24a);
	\draw[gfa,ultra thick]  (26) to[ultra thick] node[el,anchor=west] {\m{\mathbf{d}}} (21);
	
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \node[gttn] (31)  [right = 6cm of 1] {$()$};
	\node[gl]   (31l) [below = 0 of 31]   {\m{n}};

	\node[gtn]  (32) [above left  = 3cm and 1cm of 31] {\s{a}};
	\node[gtn]  (34) [above right = 1cm and 1cm of 31] {\s{b,c}};
	
	\draw[gfa]  (32)  to node[el,anchor=east]  {\m{a}} (31);
	\draw[gfa]  (34)  to[bend left]  node[el,anchor=west]  {\m{b}} (31);
	\draw[gfa]  (34)  to[bend right] node[el,anchor=west]  {\m{c}} (31);

%	\node[gttn] (32a)  [above = 1cm of 32]    {\m{(a)}};
%	\node[gttn] (34a)  [above = 1cm of 34]    {\m{(b)}};

%	\draw[sgtt] (32a) to node[el,anchor=east] {0} (32);
%	\draw[sgtt] (34a) to node[el,anchor=west] {0} (34);

%	\node[gtn]  (35) [above = 1cm of 32a] {\tiny$\s{f(a)}$};
%	\draw[gfa]  (35) to node[el,anchor=east] {\m{f}} (32a);
%	\draw[gfa]  (35) to node[el,anchor=west] {\m{f}} (34a);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\node (32nw) [above left = 0.6cm and 1.5cm of 32] {};
	\node (32sw) [below left = 0.6cm and 1.5cm of 32] {};
%	\node (32d) [below left = 0.2cm and 1.0cm of 32] {};
	\draw[se] (32) to (32nw) to (15);
	\draw[se] (32) to (32sw) to (25);

	\node (34nw) [above left = 0.2cm and 1.5cm of 34] {};
	\node (34sw) [below left = 0.2cm and 1.5cm of 34] {};
	\draw[se] (34) to (34nw) to (12);
	\draw[se] (34) to (34nw) to (14);
	\draw[se] (34) to (34sw) to (22);
	\draw[se] (34) to (34sw) to (24);
%	\draw[se] (34) to (34d) to (22);

%	\node (32au) [above left = 2.2cm and 2.5cm of 32a] {};
%	\draw[se] (32a) to[in=-10] (32au) to[out=170] (12a);

%	\node (34au) [above left = 0.0cm and 2.0cm of 34a] {};
%	\draw[se] (34a) to (34au) to (14a);


%	\node (35u) [above left = 0.2cm and 1.0cm of 35] {};
%	\draw[se] (35) to (15);

%	\draw[green] (32a.0) to node[el,anchor=north,text=green] {$\m{p_1}$} (34a.180);
\draw[draw=none, use as bounding box] (current bounding box.north west) rectangle (current bounding box.south east);

\begin{pgfinterruptboundingbox}
	\draw[separator] (3.5cm,-3.3cm) to (3.5cm,6.5cm);
\end{pgfinterruptboundingbox}
\end{tikzpicture}
\caption{
Join gfa completeness missing paths\\
after $\m{p_1}$.\lstinline{assume(g(c)=d)}\\
before $\m{n}$.\lstinline{update}
}
\label{snippet3.22_graph3}
\end{figure}
And now the only change that \m{g_n} can observe is at a node which is not the source to any node currently at \m{g_n}.\\
In this example the modified node at \m{g_{p_1}} is a direct super-node of a node that is a source (\m{[c]_{g_{p_1}}}),
but we could have the same example replacing \m{g(b),g(c)} by \m{g^2(b),g^2(c)} (omitted here to make the diagram clearer), 
and then, if \m{g_{p_1}} reports a changeset of \s{[f(c)]_{g_{p_1}}} there is no obvious way for \m{g_{n}} to establish \m{a=d} except for scanning a large portion of the graph \m{g_{p_1}} (the gfa \m{d()} could also be replaced by, e.g. \m{h^2(d)} (in both \m{p_0,p_1}, so that we could not detect the change adjacent to the gfa \m{d()}).\\
For example, if, before \m{g_n} performs \lstinline{update}, 
we also had \m{g_{p_0}}.\lstinline{assume e=f(i)},  \m{g_{p_0}}.\lstinline{assume e=f(k)}, these are both irrelevant, and we want the complexity of the \lstinline{update} operation to be independent of these additional changes.\\
If we had calculated complete sources at the last \lstinline{update} at \m{g_n}, we would know that:\\
\m{[d]_{p_0} \in \sources{n}{p_0}{[a]_{n}}} and \m{[f(c)]_{p_1} \in \sources{n}{p_1}{[a]_{n}}},
and as \m{[f(c)]_{p_1}} is in the change-set, we can detect (as explained in the next sub section about gfa completeness) that 
\m{a=d}.\\
Here is the state before the update operation when we have complete sources:
\begin{figure}[H]
\begin{tikzpicture}
  \node (1)  {};
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \node[gttn] (11)  [above right= 2.5cm and 0cm of 1] {$()$};
	\node[gl]   (11l) [below = 0 of 11]   {\m{p_0}};

	\node[gtn]  (12) [above left  = 1cm and 1cm of 11] {\s{b}};
	\node[gtn]  (14) [above right = 1cm and 1cm of 11] {\s{c}};
	
	\draw[gfa]  (12)  to node[el,anchor=east]  {\m{b}} (11);
	\draw[gfa]  (14)  to node[el,anchor=west]  {\m{c}} (11);

	\node[gttn] (12a)  [above = 1cm of 12]    {\m{(b)}};
	\node[gttn] (14a)  [above = 1cm of 14]    {\m{(c)}};

	\draw[sgtt] (12a) to node[el,anchor=east] {0} (12);
	\draw[sgtt] (14a) to node[el,anchor=west] {0} (14);

	\node[gtn]  (15) [above = 1cm of 12a] {\tiny$\svb{a}{f(b)}$};
	\draw[gfa]  (15) to node[el,anchor=east] {\m{f}} (12a);
	\draw[gfa]  (15) to node[el,anchor=east] {\m{a}} (11);
	\node[gtn]  (16) [above = 1cm of 14a] {\tiny$\svb{d}{f(c)}$};
	\draw[gfa]  (16) to node[el,anchor=west] {\m{f}} (14a);
	\draw[gfa]  (16) to node[el,anchor=west] {\m{d}} (11);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\node[gttn] (21)  [below right= 3.0cm and 0cm of 1] {$()$};
	\node[gl]   (21l) [below = 0 of 21]   {\m{p_1}};

	\node[gtn]  (22) [above left  = 1cm and 1cm of 21] {\s{b}};
	\node[gtn]  (24) [above right = 1cm and 1cm of 21] {\s{c}};
	
	\draw[gfa]  (22)  to node[el,anchor=east]  {\m{b}} (21);
	\draw[gfa]  (24)  to node[el,anchor=west]  {\m{c}} (21);

	\node[gttn] (22a)  [above = 1cm of 22]    {\m{(b)}};
	\node[gttn] (24a)  [above = 1cm of 24]    {\m{(c)}};

	\draw[sgtt] (22a) to node[el,anchor=east] {0} (22);
	\draw[sgtt] (24a) to node[el,anchor=west] {0} (24);

	\node[gtn]  (25) [above = 1cm of 22a] {\tiny$\svb{a}{g(b)}$};
	\draw[gfa]  (25) to node[el,anchor=east] {\m{g}} (22a);
	\draw[gfa]  (25) to node[el,anchor=east] {\m{a}} (21);
	\node[gtn]  (26) [above = 1cm of 24a] {\tiny$\svb{\mathbf{d}}{g(c)}$};
	\draw[gfa]  (26) to node[el,anchor=west] {\m{g}} (24a);
	\draw[gfa,ultra thick]  (26) to[ultra thick] node[el,anchor=west] {\m{\mathbf{d}}} (21);
	
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \node[gttn] (31)  [right = 6cm of 1] {$()$};
	\node[gl]   (31l) [below = 0 of 31]   {\m{n}};

	\node[gtn]  (32) [above left  = 3cm and 1cm of 31] {\s{a}};
	\node[gtn]  (34) [above right = 1cm and 1cm of 31] {\s{b,c}};
	
	\draw[gfa]  (32)  to node[el,anchor=east]  {\m{a}} (31);
	\draw[gfa]  (34)  to[bend left]  node[el,anchor=west]  {\m{b}} (31);
	\draw[gfa]  (34)  to[bend right] node[el,anchor=west]  {\m{c}} (31);

	\draw[gfa,green]  (32)  to[out=-20,in=90]  node[el,anchor=south west,text=green]  {\m{f_0}} (34);
	\draw[gfa,green]  (32)  to[out=-40,in=110] node[el,anchor=north east,text=green]  {\m{g_1}} (34);
%	\node[gttn] (32a)  [above = 1cm of 32]    {\m{(a)}};
%	\node[gttn] (34a)  [above = 1cm of 34]    {\m{(b)}};

%	\draw[sgtt] (32a) to node[el,anchor=east] {0} (32);
%	\draw[sgtt] (34a) to node[el,anchor=west] {0} (34);

%	\node[gtn]  (35) [above = 1cm of 32a] {\tiny$\s{f(a)}$};
%	\draw[gfa]  (35) to node[el,anchor=east] {\m{f}} (32a);
%	\draw[gfa]  (35) to node[el,anchor=west] {\m{f}} (34a);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\node (32nw) [above left = 0.6cm and 1.5cm of 32] {};
	\node (32sw) [below left = 0.6cm and 1.5cm of 32] {};
%	\node (32d) [below left = 0.2cm and 1.0cm of 32] {};
	\draw[se] (32) to (32nw) to (15);
	\draw[se] (32) to (32nw) to (16);
	\draw[se] (32) to (32sw) to (25);
	\draw[se] (32) to (32sw) to (26);

	\node (34nw) [above left = 0.2cm and 1.5cm of 34] {};
	\node (34sw) [below left = 0.2cm and 1.5cm of 34] {};
	\draw[se] (34) to (34nw) to (12);
	\draw[se] (34) to (34nw) to (14);
	\draw[se] (34) to (34sw) to (22);
	\draw[se] (34) to (34sw) to (24);
%	\draw[se] (34) to (34d) to (22);

%	\node (32au) [above left = 2.2cm and 2.5cm of 32a] {};
%	\draw[se] (32a) to[in=-10] (32au) to[out=170] (12a);

%	\node (34au) [above left = 0.0cm and 2.0cm of 34a] {};
%	\draw[se] (34a) to (34au) to (14a);


%	\node (35u) [above left = 0.2cm and 1.0cm of 35] {};
%	\draw[se] (35) to (15);

%	\draw[green] (32a.0) to node[el,anchor=north,text=green] {$\m{p_1}$} (34a.180);
\draw[draw=none, use as bounding box] (current bounding box.north west) rectangle (current bounding box.south east);

\begin{pgfinterruptboundingbox}
	\draw[separator] (3.5cm,-3.3cm) to (3.5cm,6.5cm);
\end{pgfinterruptboundingbox}
\end{tikzpicture}
\caption{
Join gfa completeness missing paths\\
before $\m{n}$.\lstinline{update}
}
\label{snippet3.22_graph4}
\end{figure}
The two green lines represent gfas that hold in only one predecessor, hence the line \m{f_0} means \m{n,p_0 \models a = f(b)} (and similarly for each combination of member of the equivalence classes of \m{[a]_{g_n},[b]_{g_n}}.\\
We maintain these as part of the state of \m{g_n} in order to enable optimal incremental updates.

And the final result will be: 
\begin{figure}[H]
\begin{tikzpicture}
  \node (1)  {};
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \node[gttn] (11)  [above right= 2.5cm and 0cm of 1] {$()$};
	\node[gl]   (11l) [below = 0 of 11]   {\m{p_0}};

	\node[gtn]  (12) [above left  = 1cm and 1cm of 11] {\s{b}};
	\node[gtn]  (14) [above right = 1cm and 1cm of 11] {\s{c}};
	
	\draw[gfa]  (12)  to node[el,anchor=east]  {\m{b}} (11);
	\draw[gfa]  (14)  to node[el,anchor=west]  {\m{c}} (11);

	\node[gttn] (12a)  [above = 1cm of 12]    {\m{(b)}};
	\node[gttn] (14a)  [above = 1cm of 14]    {\m{(c)}};

	\draw[sgtt] (12a) to node[el,anchor=east] {0} (12);
	\draw[sgtt] (14a) to node[el,anchor=west] {0} (14);

	\node[gtn]  (15) [above = 1cm of 12a] {\tiny$\svb{a}{f(b)}$};
	\draw[gfa]  (15) to node[el,anchor=east] {\m{f}} (12a);
	\draw[gfa]  (15) to node[el,anchor=east] {\m{a}} (11);
	\node[gtn]  (16) [above = 1cm of 14a] {\tiny$\svb{d}{f(c)}$};
	\draw[gfa]  (16) to node[el,anchor=west] {\m{f}} (14a);
	\draw[gfa]  (16) to node[el,anchor=west] {\m{d}} (11);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\node[gttn] (21)  [below right= 3.0cm and 0cm of 1] {$()$};
	\node[gl]   (21l) [below = 0 of 21]   {\m{p_1}};

	\node[gtn]  (22) [above left  = 1cm and 1cm of 21] {\s{b}};
	\node[gtn]  (24) [above right = 1cm and 1cm of 21] {\s{c}};
	
	\draw[gfa]  (22)  to node[el,anchor=east]  {\m{b}} (21);
	\draw[gfa]  (24)  to node[el,anchor=west]  {\m{c}} (21);

	\node[gttn] (22a)  [above = 1cm of 22]    {\m{(b)}};
	\node[gttn] (24a)  [above = 1cm of 24]    {\m{(c)}};

	\draw[sgtt] (22a) to node[el,anchor=east] {0} (22);
	\draw[sgtt] (24a) to node[el,anchor=west] {0} (24);

	\node[gtn]  (25) [above = 1cm of 22a] {\tiny$\svb{a}{g(b)}$};
	\draw[gfa]  (25) to node[el,anchor=east] {\m{g}} (22a);
	\draw[gfa]  (25) to node[el,anchor=east] {\m{a}} (21);
	\node[gtn]  (26) [above = 1cm of 24a] {\tiny$\svb{d}{g(c)}$};
	\draw[gfa]  (26) to node[el,anchor=west] {\m{g}} (24a);
	\draw[gfa]  (26) to node[el,anchor=west] {\m{d}} (21);
	
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \node[gttn] (31)  [right = 6cm of 1] {$()$};
	\node[gl]   (31l) [below = 0 of 31]   {\m{n}};

	\node[gtn]  (32) [above left  = 3cm and 1cm of 31] {\s{a,\mathbf{d}}};
	\node[gtn]  (34) [above right = 1cm and 1cm of 31] {\s{b,c}};
	
	\draw[gfa,ultra thick]  (32)  to[out=-80,in=80]  node[el,anchor=south west,pos=0.4]  {\m{\mathbf{d}}} (31);
	\draw[gfa]  (32)  to[out=-90,in=100] node[el,anchor=east]  {\m{a}} (31);
	\draw[gfa]  (34)  to[bend left]  node[el,anchor=east]  {\m{b}} (31);
	\draw[gfa]  (34)  to[bend right] node[el,anchor=west]  {\m{c}} (31);

	\draw[gfa,green]  (32)  to[out=-20,in=90]  node[el,anchor=south west,text=green]  {\m{f_0}} (34);
	\draw[gfa,green]  (32)  to[out=-40,in=110] node[el,anchor=north east,text=green]  {\m{g_1}} (34);

%	\node[gttn] (32a)  [above = 1cm of 32]    {\m{(a)}};
%	\node[gttn] (34a)  [above = 1cm of 34]    {\m{(b)}};

%	\draw[sgtt] (32a) to node[el,anchor=east] {0} (32);
%	\draw[sgtt] (34a) to node[el,anchor=west] {0} (34);

%	\node[gtn]  (35) [above = 1cm of 32a] {\tiny$\s{f(a)}$};
%	\draw[gfa]  (35) to node[el,anchor=east] {\m{f}} (32a);
%	\draw[gfa]  (35) to node[el,anchor=west] {\m{f}} (34a);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\node (32nw) [above left = 0.6cm and 1.5cm of 32] {};
	\node (32sw) [below left = 0.6cm and 1.5cm of 32] {};
%	\node (32d) [below left = 0.2cm and 1.0cm of 32] {};
	\draw[se] (32) to (32nw) to (15);
	\draw[se] (32) to (32nw) to (16);
	\draw[se] (32) to (32sw) to (25);
	\draw[se] (32) to (32sw) to (26);

	\node (34nw) [above left = 0.2cm and 1.5cm of 34] {};
	\node (34sw) [below left = 0.2cm and 1.5cm of 34] {};
	\draw[se] (34) to (34nw) to (12);
	\draw[se] (34) to (34nw) to (14);
	\draw[se] (34) to (34sw) to (22);
	\draw[se] (34) to (34sw) to (24);
%	\draw[se] (34) to (34d) to (22);

%	\node (32au) [above left = 2.2cm and 2.5cm of 32a] {};
%	\draw[se] (32a) to[in=-10] (32au) to[out=170] (12a);

%	\node (34au) [above left = 0.0cm and 2.0cm of 34a] {};
%	\draw[se] (34a) to (34au) to (14a);


%	\node (35u) [above left = 0.2cm and 1.0cm of 35] {};
%	\draw[se] (35) to (15);

%	\draw[green] (32a.0) to node[el,anchor=north,text=green] {$\m{p_1}$} (34a.180);
\draw[draw=none, use as bounding box] (current bounding box.north west) rectangle (current bounding box.south east);

\begin{pgfinterruptboundingbox}
	\draw[separator] (3.5cm,-3.3cm) to (3.5cm,6.5cm);
\end{pgfinterruptboundingbox}
\end{tikzpicture}
\caption{
Join gfa completeness missing paths\\
after $\m{n}$.\lstinline{update}
}
\label{snippet3.22_graph5}
\end{figure}
The important point here is that we did not need to consider the node \m{[b]_{g_n}} and its edges at all during the update operation.\\
In all existing join algorithms, this node would have to be considered both initially and during the last \lstinline{update}.\\
In this case it is just one node with two gfas, but in general it could be any size of a sub-graph (e.g. replace \m{g(b),g(c)} by \m{g^n(b),g^n(c)} ) that would be evaluated twice.\\
If the above predecessor specific gfas (green lines) were actually a sub-graph - e.g. \m{g^2(b),g^2(c)} - then we need corresponding 
predecessor specific nodes that represent information we have gathered in previous operation on \m{g_n}, that have not resulted in any node
at \m{g_n}, but that we do not want to repeat - as shown in the graph:
\begin{figure}[H]
\begin{tikzpicture}
  \node (1)  {};
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \node[gttn] (11)  [above right= 2.5cm and 0cm of 1] {$()$};
	\node[gl]   (11l) [below = 0 of 11]   {\m{p_0}};

	\node[gtn]  (12) [above left  = 1cm and 1cm of 11] {\s{b}};
	\node[gtn]  (14) [above right = 1cm and 1cm of 11] {\s{c}};
	
	\draw[gfa]  (12)  to node[el,anchor=east]  {\m{b}} (11);
	\draw[gfa]  (14)  to node[el,anchor=west]  {\m{c}} (11);

	\node[gttn] (12a)  [above = 1cm of 12]    {\m{(b)}};
	\node[gttn] (14a)  [above = 1cm of 14]    {\m{(c)}};

	\draw[sgtt] (12a) to node[el,anchor=east] {0} (12);
	\draw[sgtt] (14a) to node[el,anchor=west] {0} (14);

	\node[gtn]  (15) [above = 1cm of 12a] {\tiny$\s{f(b)}$};
	\draw[gfa]  (15) to node[el,anchor=east] {\m{f}} (12a);
	\node[gtn]  (16) [above = 1cm of 14a] {\tiny$\s{f(c)}$};
	\draw[gfa]  (16) to node[el,anchor=west] {\m{f}} (14a);

	\node[gttn] (15a)  [above = 1cm of 15]    {\m{(f(b))}};
	\node[gttn] (16a)  [above = 1cm of 16]    {\m{(f(c))}};

	\draw[sgtt] (15a) to node[el,anchor=east] {0} (15);
	\draw[sgtt] (16a) to node[el,anchor=west] {0} (16);

	\node[gtn]  (17) [above = 1cm of 15a] {\tiny$\svb{a}{f(f(b))}$};
	\draw[gfa]  (17) to node[el,anchor=east] {\m{f}} (15a);
	\draw[gfa]  (17) to[out = -60,in=90] node[el,anchor=east] {\m{a}} (11);
	\node[gtn]  (18) [above = 1cm of 16a] {\tiny$\svb{d}{f(f(c))}$};
	\draw[gfa]  (18) to node[el,anchor=west] {\m{f}} (16a);
	\draw[gfa]  (18) to[out = -120,in=90] node[el,anchor=west] {\m{d}} (11);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\node[gttn] (21)  [below right= 3.0cm and 0cm of 1] {$()$};
	\node[gl]   (21l) [below = 0 of 21]   {\m{p_1}};

	\node[gtn]  (22) [above left  = 1cm and 1cm of 21] {\s{b}};
	\node[gtn]  (24) [above right = 1cm and 1cm of 21] {\s{c}};
	
	\draw[gfa]  (22)  to node[el,anchor=east]  {\m{b}} (21);
	\draw[gfa]  (24)  to node[el,anchor=west]  {\m{c}} (21);

	\node[gttn] (22a)  [above = 1cm of 22]    {\m{(b)}};
	\node[gttn] (24a)  [above = 1cm of 24]    {\m{(c)}};

	\draw[sgtt] (22a) to node[el,anchor=east] {0} (22);
	\draw[sgtt] (24a) to node[el,anchor=west] {0} (24);

	\node[gtn]  (25) [above = 1cm of 22a] {\tiny$\svb{a}{g(b)}$};
	\draw[gfa]  (25) to node[el,anchor=east] {\m{g}} (22a);
	\draw[gfa]  (25) to node[el,anchor=east] {\m{a}} (21);
	\node[gtn]  (26) [above = 1cm of 24a] {\tiny$\svb{d}{g(c)}$};
	\draw[gfa]  (26) to node[el,anchor=west] {\m{g}} (24a);
	\draw[gfa]  (26) to node[el,anchor=west] {\m{d}} (21);
	
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \node[gttn] (31)  [right = 7cm of 1] {$()$};
	\node[gl]   (31l) [below = 0 of 31]   {\m{n}};

	\node[gtn]  (32) [above left  = 6cm and 1cm of 31] {\s{a}};
	\node[gtn]  (34) [above right = 1cm and 1cm of 31] {\s{b,c}};
	
%	\draw[gfa,ultra thick]  (32)  to[out=-80,in=80]  node[el,anchor=south west,pos=0.4]  {\m{\mathbf{d}}} (31);
	\draw[gfa]  (32)  to[out=-90,in=100] node[el,anchor=east]  {\m{a}} (31);
	\draw[gfa]  (34)  to[bend left]  node[el,anchor=east]  {\m{b}} (31);
	\draw[gfa]  (34)  to[bend right] node[el,anchor=west]  {\m{c}} (31);

	\node[gttn,green] (34a)  [above = 1cm of 34]    {\m{p_0}};
	\draw[sgtt,green] (34a) to node[el,anchor=east,text=green] {0} (34);

	\node[gtn,green]  (36) [above = 1cm of 34a] {\m{p_0}};
	\draw[gfa,green]  (36)  to  node[el,anchor=south west,text=green]  {\m{f_0}} (34a);

	\node[gttn,green] (36a)  [above = 1cm of 36]    {\m{p_0}};
	\draw[sgtt,green] (36a) to node[el,anchor=east,text=green] {0} (36);

	\draw[gfa,green]  (32.-90)  to[out=-45,in=90]  node[el,anchor=south west,text=green]  {\m{f_0}} (36a);
	\draw[gfa,green]  (32.-90)  to node[el,anchor=north east,text=green]  {\m{g_1}} (34);

%	\node[gttn] (32a)  [above = 1cm of 32]    {\m{(a)}};
%	\node[gttn] (34a)  [above = 1cm of 34]    {\m{(b)}};

%	\draw[sgtt] (32a) to node[el,anchor=east] {0} (32);
%	\draw[sgtt] (34a) to node[el,anchor=west] {0} (34);

%	\node[gtn]  (35) [above = 1cm of 32a] {\tiny$\s{f(a)}$};
%	\draw[gfa]  (35) to node[el,anchor=east] {\m{f}} (32a);
%	\draw[gfa]  (35) to node[el,anchor=west] {\m{f}} (34a);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\node (32nw) [above left = 0.8cm and 1.0cm of 32] {};
	\node (32nww) [left = 2cm of 32nw] {};
	\node (32sw) [below left = 0.8cm and 1.0cm of 32] {};
%	\node (32d) [below left = 0.2cm and 1.0cm of 32] {};
	\draw[se] (32) to (32nw) to (32nww) to (17);
	\draw[se] (32) to (32nw) to (18);
	\draw[se] (32) to (32sw) to (25);
	\draw[se] (32) to (32sw) to (26);

	\node (36nw) [above left = 0.4cm and 1.5cm of 36] {};
	\draw[se] (36) to (36nw) to (15);
	\draw[se] (36) to (36nw) to (16);

	%\node (34nw) [above left = 0.2cm and 1.5cm of 34] {};
	%\node (34sw) [below left = 0.2cm and 1.5cm of 34] {};
	%\draw[se] (34) to (34nw) to (12);
	%\draw[se] (34) to (34nw) to (14);
	%\draw[se] (34) to (34sw) to (22);
	%\draw[se] (34) to (34sw) to (24);
%	\draw[se] (34) to (34d) to (22);

%	\node (32au) [above left = 2.2cm and 2.5cm of 32a] {};
%	\draw[se] (32a) to[in=-10] (32au) to[out=170] (12a);

%	\node (34au) [above left = 0.0cm and 2.0cm of 34a] {};
%	\draw[se] (34a) to (34au) to (14a);


%	\node (35u) [above left = 0.2cm and 1.0cm of 35] {};
%	\draw[se] (35) to (15);

%	\draw[green] (32a.0) to node[el,anchor=north,text=green] {$\m{p_1}$} (34a.180);
\draw[draw=none, use as bounding box] (current bounding box.north west) rectangle (current bounding box.south east);

\begin{pgfinterruptboundingbox}
	\draw[separator] (3.5cm,-3.3cm) to (3.5cm,9.5cm);
\end{pgfinterruptboundingbox}
\end{tikzpicture}
\caption{
Join gfa completeness missing paths\\
before $\m{n}$.\lstinline{update}
}
\label{snippet3.22_graph6}
\end{figure}
Here the green nodes with sources represent sets of EC-nodes from \m{g_{p_0}}, essentially encoding the difference between,
\s{s=t \mid  \models s =_{n,p_0} t} and \\
\m{ \s{s=t \mid s=_{n,p_0} t} \cup \s{s=t \mid s=_{n,p_1} t}}\\
restricted to \emph{relevant terms} - terms represented in nodes of \m{g_{p_0}} that are reachable through gfa edges from the range of the \m{sources(n)(p_0)} function, and their equivalence class under \m{=_{n,p_0}}.\\
The actual representation of this information would be a partition of the set of relevant terms (set of pairwise disjoint sets), so it does not increase the space complexity asymptotically. We write \m{s=_{n,p_0} t} when the term-EC-nodes \m{s,t \in g_{p_0}} are in the same partition.\\
The green line we have seen at ~\ref{snippet3.20_graph3}, between two \m{g_n} term-EC-nodes \m{s,t} essentially means that
these two nodes are equal under \m{m,p_0} \\
(that is,\m{\exists u \in \terms{s}, v \in \terms{t} \cdot n,p_0 \models u=v}).\\
We overload the notation and write \m{s =_{n,p_0} t} in this case (this time for \m{g_n} nodes).\\
This property can be established in two ways:\\
either directly - \m{\exists u \in \sources{n}{p_0}{s},v \in \sources{n}{p_0}{t} \cdot u =_{n,p_0} v}, \\
or the equality was established indirectly through congruence closure - that is, \\
\m{\exists \fa{f}{u} \in s, \fa{f}{v} \in t \cdot \tup{u} =_{n,p_0} \tup{v}}

Note, for graph locality we do not need the green edges (gfa) as well, as they only copy information from the corresponding gfa edges in \m{g_{p_0}}, which is reachable in O(1) through source edges, but, as we will show when discussing complexity, when we need to enumerate or search through incoming or outgoing gfa edges, copying and indexing these edges helps ensure the overall complexity is bounded only by relevant terms.

We will denote the set of relevant terms of a join node \m{n} for the predecessor \m{p_i} by \rt{n}{i}.\\
We will use the notation \m{g_n \models s=_{0} t} for both cases above:\\
For \m{s,t \in g_{p_i}} to mean that \m{s,t \in \rt{n}{i}} and that they share the same \m{p_i} equivalence class -\m{[s]_{g_n}^i = [t]_{g_n}^i}\\
And\\
For \m{s,t \in g_{n}} to mean that \m{s,t} are marked as equal under \m{n,p_i} (the horizontal green line of ~\ref{snippet3.20_graph3}).\\
We assume both of these are always reflexive, and extend them in the standard way to tuples.\\
No we can state the source completeness invariant, which comes in 3 parts, per predecessor \m{p_i} and join node \m{n}:\\
We need to ensure propagation as before:\\
\m{\forall \fa{f}{u} \in \GFAECs{g_n} \cup \rgfas{n}, \tup{v} \in \sources{n}{p_i}{u} \cdot}\\
\m{\fa{f}{v} \in \rgfas{p_i} \cup \GFAECs{p_i}}\\
And\\
\m{(\forall p \in \predsto{n} \cdot \exists \tup{s} \in \sources{n}{p}{\tup{t}}\cdot \fa{f}{s} \in g_p) \Rightarrow \fa{f}{t} \notin \rgfas{n})}

\begin{figure}
\begin{enumerate}
	\item We need to make sure that all sources are marked as relevant terms:\\
		\m{\forall s \in g_n, u \in \sources{n}{p_i}{s} \cdot u \in \rt{n}{i}}
	\item All relevant terms are downward closed:\\
		\m{\forall s \in \rt{n}{i}, \fa{f}{u} \in s \cdot \tup{u} \in \rt{n}{i}}
	\item Two relevant terms that share a \m{g_n} node are in the same \m{p_i} EC:\\
		\m{\forall s \in g_n, u,v \in \sources{n}{p_i}{s}, [u]_{g_n}^i = [v]_{g_n}^i}
	\item Relevant term ECs are congruence closed:\\
		\m{\forall u \in \rt{n}{i}, \fa{f}{s} \in u, \tup{t} \in [\tup{s}]_{g_n}^i, v \in g_{p_i} \cdot }\\
		\m{\fa{f}{t} \in v \Rightarrow (v \in \rt{n}{i} \land [u]_{g_n}^i = [v]_{g_n}^i)}
	\item And here we need also to ensure we have all relevant transitive equality information:\\
		\m{\forall t \in \rt{n}{i}, \fa{f}{u} \in t, \tup{v} \in [\tup{u}]_{g_n}^i \cdot}
		\m{\fa{f}{v} \in \rgfas{p_i} \cup \GFAECs{p_i}}
\end{enumerate}
\caption{strong join relevant terms}
\label{strong_join_relevant_terms}
\end{figure}


Note that the second part implies down propagation, while the fourth part implies upward propagation - 
so we can get the equivalent of ~\ref{graph_sequential_multi_propagation_post} per predecessor.\\
The key that allows us to establish in  ~\ref{snippet3.22_graph4} that \m{[d]_{g_{p_0}} \in \sources{n}{p_0}{[a]_{g_n}}}
is the fourth part:\\
\m{[a]_{g_{p_0}}} = \m{[g(b)]_{g_{p_0}}}, \m{[d]_{g_{p_0}}} = \m{[g(c)]_{g_{p_0}}} \\
\m{[b]_{g_{p_0}} =_{n,0} [c]_{g_{p_0}}} because they are both in \sources{n}{p_0}{[b]_{g_n}} (by part 3)\\
As \m{[g(b)]_{g_{p_0}} \in \rt{n}{0}}, and as \m{g([c]_{p_0}) \in \GFAECs{[g(c)_{p_0}}}, \\
we get that \m{[[g(b)]_{p_0}]_{g_n}^{0} = [[g(c)]_{p_0}]_{g_n}^{0}} by part 4.

\noindent \textbf{Locality:}
All of the above conditions are local, in the sense that we can check each node (in \m{g_n,g_{p_i},\rt{n}{i}}) 
just by considering paths from the node (on all edge types - gfa,source,relevant terms) of constant length (in fact length at most 3).\\
For example, for rule 4, given an \rt{n}{i} node, we need to follow a gfa edge \m{f}, 
find the relevant tuples and for each tuple try look for a corresponding gfa edge \m{f} in \m{g_{p_i}}.

\subsubsection*{The Propagation Invariant for Join Nodes}
As opposed to the sequential case, we can define several different join completeness criteria.\\
The spectrum runs between the weakest join:\\
\m{\forall s \in \terms{g_n}, t \in \Ts{\sig} \cdot }\\
\m{((\forall p \in \preds{n} \cdot (s \in \terms{g_p} \land [s]_{g_p} = [t]_{g_p})) \Rightarrow }\\
\m{(t \in \terms{g_n} \land [s]_{g_n}=[t]_{g_n}))}\\
Which is simply an extension of the sequential case, and the complete join:\\
\m{\forall s \in \terms{g_n}, t \in \Ts{\sig} \cdot }\\
\m{(\forall p \in \preds{n} \cdot \eqs{g_p} \cup \eqs{g_n} \models s=t) \Rightarrow (t \in \terms{g_n} \land [s]_{g_n}=[t]_{g_n})}

Remember that the gfa completeness invariant for the sequential case was:
\m{\forall u \in g_n, v \in \sources{n}{p}{u}, \fa{f}{s} \in v \cdot}\\
\m{\exists \fa{f}{t} \in u \cdot \tup{s} \in \sources{n}{p}{\tup{t}} }

Adapting the above to the join case requires, at the very least, that we match gfas in \emph{all} direct predecessors and only then force the join graph to have a corresponding gfa. Note that in the sequential case we matched the gfa on the function symbol, and then on the source tuple EC. 
For a given EC term node \m{t \in g_n}, assuming we have a source node \m{s_p \in g_p} (\m{s_p \in \sources{n}{p}{t}}) for each predecessor \m{p},
and assuming we have a gfa \m{\fa{f}{v_p} \in s_p} for each predecessor (with the same function symbol), 
then we would need a tuple EC \m{\tup{u} \in g_n} s.t. for each predecessor, \m{\tup{v_p} \in \sources{n}{p}{\tup{u}}},
if such a \tup{u} exists, then obviously \fa{f}{u} should be in \GFAECs{t}, the question is when \emph{should} such a \tup{u} exist?

As an example, consider, on the one hand:\\
\m{ \s{a=f(b)} \sqcup \s{a=f(c),b=c}}\\
and on the other hand:\\
\m{ \s{a=f(b)} \sqcup \s{a=f(c)}}\\
(we will use \m{p_0,p_1} for the predecessor CFG nodes)\\
In the first case, the term EC node for \m{a} at the join node EC graph \m{g_n} would have a source with the gfa \m{f([b]_{g_p})} at each predecessor, and we would expect a term EC node \m{[b]_{g_n}} for \m{b} to exist, 
and hence the term EC node for \m{a} at \m{g_n} to have the  corresponding gfa - that is, \m{f([b]_{g_n}) \in [a]_{g_n}}.\\
In the second case, although the sources for \m{[a]_{g_n}} share a gfa with the same function symbol \m{f}, 
we do not expect to have a node in \m{u \in g_n} s.t. \\
\m{[b]_{g_{p_0}} \in \sources{n}{p_0}{u}} and \m{[c]_{g_{p_1}} \in \sources{n}{p_1}{u}},
as such a node does not correspond to any term that is equal in the join
(unless we have \lstinline{assumed} at \m{n} that \m{b=c}).
We can observe locally that no such term EC node is expected because there is no gfa with a common function symbol between 
\m{[b]_{g_{p_1}}} and \m{[c]_{g_{p_2}}}.

\subsubsection*{Source Pairs}
The key notion here is that of ordered pairs of EC nodes, one from each predecessor.
We will call these pairs source-pairs and will denote them as \gta{t_0,t_1} for a pair of EC nodes \m{t_0 \in g_{p_0},t_1 \in g_{p_1}}\\
We would also overload the notation for terms (as opposed to EC nodes) in order to reduce notations where there is no ambiguity - so e.g. \gta{b}{c} would mean the ordered pair \m{([b]_{p_0},[c]_{p_1})}.

We would write \m{\gta{t_0}{t_1} \in \sourcesB{n}{t}} iff, for each i, \\
\m{[t_i]_{g_{p_i}} \in \sources{n}{p_i}{[t]_{g_n}}}.

As we have seen before, each such pair can be the source of at most one EC node at the join, 
but not all such pairs can be the source of \emph{any} node at the join - for example, \gta{a}{b} 
would not be the source of any node in the above two examples - we would then say that this pair is \emph{infeasible} - it does not represent any term at the join. Note that if we were to \lstinline{assume a=b} at the join then \gta{a}{b} would become feasible, 
so that feasibility can change with added equalities, but only in a monotonic manner.\\
We extend the above source-pairs to source-pairs of tuples, where a tuple-source-pair is feasible iff each pair of its elements is feasible - formally:\\
\m{feasible(\gta{\tup{s}}{\tup{t}}) \triangleq \land_i feasible(\gta{s_i}{t_i})}\\
we would also talk of such pairs of gfas.\\
Now we can define a pair as feasible as follows:\\
\m{feasible(\gta{s_0}{s_1}) \triangleq }\\
\m{(\exists t \in g_n \cdot \gta{s_0}{s_1} \in \sourcesB{n}{t}) \lor}\\
\m{(\exists \fa{f}{u_0} \in s_0,\fa{f}{u_1} \in s_1 \cdot feasible(\gta{\tup{u_0}}{\tup{u_1}}))}\\
That is, a pair is feasible if it is already the source of some term at the join (which covers the above case of \lstinline{assuming b=c} at the \m{n}), or if there is a matching feasible pair of gfas.\\
Using this definition we can now phrase gfa completeness for the weak join:\\
\m{\forall t \in g_n, \gta{s_0}{s_1} \in \sourcesB{n}{t}, f \in \Fs{\sig}, \fa{f}{v_0} \in s_0, \fa{f}{v_1} \in s_1 \cdot}\\
\m{feasible(\gta{\tup{v_0}}{\tup{v_1}}) \Rightarrow \exists \fa{f}{u} \in t \cdot \gta{\tup{v_0}}{\tup{v_1}} \in \sourcesB{n}{\tup{u}}}

However, we do not want to consider all \m{\size{g_{p_0}} \times \size{g_{p_1}}} source-pairs regardless of the terms at \m{g_n} - 
we want the overall complexity to depend on the final result, and so a source-pair that provably cannot contribute to the result should not be considered.\\
We will maintain a set of \emph{evaluated} source pairs per join node - denoted by \gtas{n} for the join node \m{n} (the actual concrete representation in the algorithm will be discussed later).\\
Now we define which source-pairs we consider relevant:
\begin{enumerate}
	\item For each term-EC-node at \m{g_n}, each pair of sources should be considered:\\
	\m{\forall t \in g_n, s_0 \in \sources{n}{p_0}{t}, s_1 \in \sources{n}{p_1}{t} \cdot \gta{s_0}{s_1} \in \gtas{n}}
	\item For each source-pair with a matching gfa pair, all source-pairs of the matching tuple must be considered:\\
	\m{\forall \gta{t_0}{t_1} \in \gtas{n}, \fa{f}{s_0} \in t_0, \fa{f}{s_1} \in t_1,i \cdot \gta{{s_0}_i}{{s_1}_i} \in \gtas{n}}
\end{enumerate}
We will see later a third condition that enforces source pairs.\\
Note that this definition means that checking for feasibility is closed in \gtas{n} (it is sufficient to check feasibility only on source-pairs in \gtas{n}).

\subsubsection*{Incremental Algorithmic Complexity of the Weak Join}
\textbf{Sequential}\\
In the sequential case, the EC-graph based definition of gfa completeness directly hints at an algorithm to ensure it - 
basically, for each EC-node at the join, for each gfa of each of its sources, we should propagate that gfa down (towards the empty tuple)and create all necessary EC-nodes at the join on the way. Whether we create the nodes from the bottom up or top down is one issue that does not affect worst case complexity (more on this later), 
but in order to find which nodes need to be created at the join we traverse the gfa chain at the predecessor \emph{down} from each source of each EC node - doing it the other way could potentially traverse many unneeded nodes.\\
For example - if the predecessor is built from \s{a=f(b),f^n(c)=d}, the successor node has no equalities and we want to create 
\m{[a]_{g_n}}:\\
Top down: we find that \m{[a]_{g_p} \in \sources{n}{p}{[a]_{g_n}}}, and so we traverse down the gfa \fa{f}{[b]_{g_p}}, to reach \m{[b]_{g_p}}, and then down from there to \m{[()]_{g_p}}.\\
Bottom up: we do not know which EC-nodes in \m{g_p} are relevant, so we need to go up the whole chain of \m{f^n{c}}, although it is irrelevant - hence the complexity of adding \emph{each} term to \m{g_n} is potentially \size{g_p}, even if at the end of all additions 
\m{\size{g_p} \gg \size{g_n}} - this would contribute another degree to the polynomial of the complexity of the overall process, 
while the top down approach (with proper bookkeeping) traverses only source gfas that end up in the result - so that the size of the result is proportional to the total number of gfas traversed over the whole verification process (proof will be shown with the algorithm).\\
\textbf{Join}\\
For the join case, this is not anymore the case - consider:\\
\m{\s{a=f^m(b)} \sqcup \s{a=f^m(c), b=c}}, here, when we want to create the term \m{a()} at \m{g_n}, 
we must add the whole chain of \m{f^m(b)}, as \m{\land_i \eqs{p_i} \models a=f^m(b)} - so complexity cannot be lower than \m{m}.
However, consider the following two variants of the join:\\
\m{\s{a=f^m(b)} \sqcup \s{a=f^m(c)}}\\
And\\
\m{\s{a=g(f^m(b))} \sqcup \s{a=f(f^m(c)),b=c}}\\
In the first case, going top down we would need to traverse \m{m} nodes just to find that \gta{b}{c} is not feasible,
in the second case, going bottom up we would need to traverse \m{m} nodes up just to find that, although \gta{f^m(b)}{f^m(c)} is feasible,
the gfa-source-pair \gta{\fa{f}{f^m(b)}}{\fa{g}{f^m(c)}} is not. \\
We can combine these to get:\\
\m{\s{a=f^m(g(f^m(b)))} \sqcup \s{a=f^m(f(f^m(c))),b=c}}\\ 
where traversing either way would cost at least \m{m} steps, while the size of the result is \m{O(1)} (a()'s equivalence class is a singelton at the join).\\
We include just one more example to show the worst case complexity of this problem:\\
\m{\s{a=h(c_1),c_1=f^{m}(c_1),f(c_1)=g(d_1),d_1=f^{m}(d_1),f(d_1)=b} \sqcup}\\
\m{\s{a=h(c_2),c_2=f^{l}(c_2),f(c_2)=\mathbf{g}(d_2),d_2=f^{l}(d_2),f(d_2)=b}}\\
vs\\
\m{\s{a=h(c_1),c_1=f^{m}(c_1),f(c_1)=g(d_1),d_1=f^{m}(d_1),f(d_1)=b} \sqcup}\\
\m{\s{a=h(c_2),c_2=f^{l}(c_2),f(c_2)=\mathbf{g'}(d_2),d_2=f^{l}(d_2),f(d_2)=b}}\\
Illustrated:
\begin{figure}[H]
\begin{tikzpicture}
	\node[gttn] (1)              {$()$};
	\node[gl]   (1l) [below = 0 of 1] {\m{p_0}};

	\node[gtn]  (2) [above = 7cm of 1] {\s{a,...}};
	\node[gtn]  (3) [above right = 1cm and 1cm of 1] {\svb{b}{f(d_1)}};
	\node[gtn]  (4) [above = 1cm of 3] {\s{d_1}};
	\node[gtn]  (5) [above = 1cm of 4] {\svb{f(c_1)}{g(d_1)}};
	\node[gtn]  (6) [above = 1cm of 5] {\s{c_1}};

	\draw[gfa,green]  (2) to[bend right] node[el,anchor=east,text=green] {\m{a}} (1);
	\draw[gfa,green]  (3) to node[el,anchor=west,text=green] {\m{b}} (1);
	
	\node (3e) [right = 0.1cm of 3] {};
	\node (4e) [above = 1.5cm of 3e] {};
	\draw[gfa,green]  (3) to[out=-90,in = -90] (3e) to[out=90,in = -90] node[el,anchor=west,text=green] {\m{f}} (4e) to[out=90,in = 90] (4);
	\draw[gfa]  (4) to[bend right] node[el,anchor=east] {\m{d_1}} (1);
	\draw[gfa,dotted,green]  (4) to node[el,anchor=west,text=green] {\m{f^{m-1}}} (3);


	\node (5e) [right = 0.1cm of 5] {};
	\node (6e) [above = 1.5cm of 5e] {};
	\draw[gfa,green]  (5) to[out=-90,in = -90] (5e) to[out=90,in = -90] node[el,anchor=west,text=green] {\m{f}} (6e) to[out=90,in = 90] (6);
	\draw[mgfa]  (5) to node[ml,anchor=west] {\m{g}} (4);
	\draw[gfa,dotted,green]  (6) to node[el,anchor=west,text=green] {\m{f^{m-1}}} (5);
	\draw[gfa,green]  (2) to node[el,anchor=south west,text=green] {\m{h}} (6);
	\draw[gfa]  (6) to[bend right] node[el,anchor=east] {\m{c_1}} (1);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\node[gttn] (11)  [right = 7cm of 1]{$()$};
	\node[gl]   (11l) [below = 0 of 11]  {\m{p_1}};

	\node[gtn]  (12) [above = 7cm of 11] {\s{a,...}};
	\node[gtn]  (13) [above left = 1cm and 1cm of 11] {\svb{b}{f(d_2)}};
	\node[gtn]  (14) [above = 1cm of 13] {\s{d_2}};
	\node[gtn]  (15) [above = 1cm of 14] {\svb{f(c_2)}{g'(d_2)}};
	\node[gtn]  (16) [above = 1cm of 15] {\s{c_2}};

	\draw[gfa,green]  (12) to[bend left] node[el,anchor=west,text=green] {\m{a}} (11);
	\draw[gfa,green]  (13) to node[el,anchor=east,text=green] {\m{b}} (11);
	
	\node (13e) [left = 0.1cm of 13] {};
	\node (14e) [above = 1.5cm of 13e] {};
	\draw[gfa,green]  (13) to[out=-90,in = -90] (13e) to[out=90,in = -90] node[el,anchor=east,text=green] {\m{f}} (14e) to[out=90,in = 90] (14);
	\draw[gfa]  (14) to[bend left] node[el,anchor=west] {\m{d_2}} (11);
	\draw[gfa,dotted,green]  (14) to node[el,anchor=east,text=green] {\m{f^{l-1}}} (13);


	\node (15e) [left = 0.1cm of 15] {};
	\node (16e) [above = 1.5cm of 15e] {};
	\draw[gfa,green]  (15) to[out=-90,in = -90] (15e) to[out=90,in = -90] node[el,anchor=east,text=green] {\m{f}} (16e) to[out=90,in = 90] (16);
	\draw[mgfa] (15) to node[ml,anchor=west] {\m{g'}} (14);
	\draw[gfa,dotted,green]  (16) to node[el,anchor=east,text=green] {\m{f^{l-1}}} (15);
	\draw[gfa,green]  (12) to node[el,anchor=south east,text=green] {\m{h}} (16);
	\draw[gfa]  (16) to[bend left] node[el,anchor=east] {\m{c_2}} (11);
 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%\draw[se] (16) to  (6);

\end{tikzpicture}

\caption{
\\
\m{\s{a=h(c_1),c_1=f^{m}(c_1),f(c_1)=g(d_1),d_1=f^{m}(d_1),f(d_1)=b} \sqcup}\\
\m{\s{a=h(c_2),c_2=f^{l}(c_2),f(c_2)=\mathbf{g'}(d_2),d_2=f^{l}(d_2),f(d_2)=b}}\\
Tuples are ommitted (but the empty tuple)\\
Green edges match while red edges do not\\
black edges are unique for a predecessor
}
\label{join3.1_graph1}
\end{figure}


Here, when \m{m,l} are co-prime, we would need to consider \m{m \times l} source-pairs in order to determine whether
we have the first case - where we should get \m{a=h(f^{ml-1}(g(f^{ml-1}(b))))} at \m{g_n}, and hence at least \m{2ml} nodes at \m{g_n},
or we have the second case where the EC for \m{a} should be \s{a} at \m{g_n} - so 1 node at \m{g_n}.\\
Regardless of traversal direction, we might need to consider up to \\
\m{O(\size{g_{p_0}} \times \size{g_{p_1}})} number of source-pairs.\\
In this specific case, we could do some pre-processing to see that the function symbols \m{g,g'} are unique to each of \m{p_0,p_1},
but we have not found a way to do this in the general case. \\
This might not make a big difference in the non-incremental case, but in the incremental case, 
for the second join above, if, after the initial join (which cost at least \m{m \times l} steps) \m{p_1} were to 
\lstinline{assume $\m{g_1(d_2)=g_2(d_2)}$} we would need to recognize that now, at \m{g_n},  \m{a=h(f^{ml-1}(g(f^{ml-1}(b))))},
while if \m{p_1} where to \lstinline{assume $\m{g_3(d_2)=g_2(d_2)}$} \m{g_n} should not change, and especially we should not use another
 \m{m \times l} steps to establish that the join has not changed.\\
We would not expect the worst case complexity to be any less than quadratic in $\size{g_{p_0}}+\size{g_{p_1}}$ 
(and linear in \size{g_{n}}), but over the whole verification process, if at \m{n} we have to re-check these \m{O(m \times l)}
source-pairs in each one of \m{o} modification operations on \m{g_n} throughout the verification process, 
we would get \m{\theta(o \times m \times l)} operations, where our objective is nearer to 
\m{O(m \times l + o + maxsize(g_n))} (where \m{maxsize(g_n)} is the maximal size of \m{g_n} at the end of any operation) - that is,
we expect to consider each such source-pair (which is a potential source to a potential node at \m{g_n}) 
at most once and not in each operation.\\
We could keep track of which source-pairs we have already checked for each join point, 
and when a node is added at the join that has a source pair already checked, 
we could mark the newly feasible source-pairs and, if needed, add the relevant term-EC-nodes and gfas where needed to keep the complexity bound so that each source pair is considered at most a constant number of times 
(once marked as relevant, once marked as feasible, once marked as the source of an actual node at the join).\\
Keeping this state, however, could increase the memory complexity of the verifier as e.g. in the above case, where $\size{g_n}=1$
but the number of source-pairs we need to remember is \m{\theta(ml)}, but this increase affects only the join nodes themselves and does not get propagated throughout the CFG.\\
To see the role played by incrementality consider the example in ~\ref{snippet3.23_graph1}:
\begin{figure}[H]
\begin{tikzpicture}
  \node (1)  {};
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \node[gttn] (11)  [above right= 2.5cm and 0cm of 1] {$()$};
	\node[gl]   (11l) [below = 0 of 11]   {\m{p_0}};

	\node[gtn]  (12) [above left  = 1cm and 0.5cm of 11] {\s{a}};
	\node[gtn]  (14) [above right = 1cm and 0.5cm of 11] {\s{b}};
	
	\draw[gfa]  (12)  to node[el,anchor=east]  {\m{a}} (11);
	\draw[gfa]  (14)  to node[el,anchor=west]  {\m{b}} (11);

	\node[gttn] (12a)  [above = 1cm of 12]    {\m{(a)}};
	\node[gttn] (14a)  [above = 1cm of 14]    {\m{(b)}};

	\draw[sgtt] (12a) to node[el,anchor=east] {0} (12);
	\draw[sgtt] (14a) to node[el,anchor=west] {0} (14);

	\node[gtn]  (16) [above = 3cm of 11] {\tiny$\faB{f}{a}{b}$};
	\draw[gfa]  (16) to node[el,anchor=east] {\m{f}} (12a);
	\draw[gfa]  (16) to node[el,anchor=west] {\m{f}} (14a);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\node[gttn] (21)  [below right= 3.0cm and 0cm of 1] {$()$};
	\node[gl]   (21l) [below = 0 of 21]   {\m{p_1}};

	\node[gtn]  (22) [above left  = 1cm and 0.5cm of 21] {\s{a}};
	\node[gtn]  (24) [above right = 1cm and 0.5cm of 21] {\s{c}};
	
	\draw[gfa]  (22)  to node[el,anchor=east]  {\m{a}} (21);
	\draw[gfa]  (24)  to node[el,anchor=west]  {\m{c}} (21);

	\node[gttn] (22a)  [above = 1cm of 22]    {\m{(a)}};
	\node[gttn] (24a)  [above = 1cm of 24]    {\m{(c)}};

	\draw[sgtt] (22a) to node[el,anchor=east] {0} (22);
	\draw[sgtt] (24a) to node[el,anchor=west] {0} (24);

	\node[gtn]  (26) [above = 3cm of 21] {\tiny$\faB{f}{a}{c}$};
	\draw[gfa]  (26) to node[el,anchor=east] {\m{f}} (22a);
	\draw[gfa]  (26) to node[el,anchor=west] {\m{f}} (24a);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \node[gttn] (31)  [right = 6.5cm of 1] {$()$};
	\node[gl]   (31l) [below = 0 of 31]   {\m{n}};

	\node[gtn]  (32) [above left  = 1cm and 0.5cm of 31] {\s{a}};
	\node[pgtn] (33) [above right = 2cm and 0.5cm of 31] {\s{[b,c]}};
	\node[gtn]  (34) [above right = 1cm and 0.0cm of 31] {\s{b}};
	\node[gtn]  (35) [above right = 1cm and 1.5cm of 31] {\s{c}};
	
	\draw[gfa]  (32)  to node[el,anchor=east]  {\m{a}} (31);
	\draw[gfa]  (34)  to node[el,anchor=west]  {\m{b}} (31);
	\draw[gfa]  (35)  to node[el,anchor=west]  {\m{c}} (31);

	\node[gttn] (32a)  [above = 1cm of 32]    {\m{(a)}};
	\node[pgttn](33a)  [above = 0.5cm of 33]    {\m{(b)}};

	\draw[sgtt] (32a) to node[el,anchor=east] {0} (32);
	\draw[psgtt] (33a) to node[pl,anchor=west] {0} (33);

	\node[gtn]  (36) [above = 3.5cm of 31] {\tiny$\m{f(a)}$};
%	\node[gtn]  (36) [above = 1cm of 32a] {\tiny$\m{f(a)}$};
	\draw[gfa]  (36) to node[el,anchor=east] {\m{f}} (32a);
	\draw[pgfa] (36) to node[pl,anchor=west] {\m{f}} (33a);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\node (32u) [above left = 0.2cm and 1.0cm of 32] {};
	\node (32d) [below left = 0.2cm and 1.0cm of 32] {};
%	\draw[se] (32) to (32u) to (12);
%	\draw[se] (32) to (32d) to (22);

	\node (34u) [above left = 0.2cm and 2.5cm of 34] {};
	\node (35d) [below left = 0.3cm and 1.5cm of 35] {};
%	\draw[se] (34) to (34u) to (14);
%	\draw[se] (35) to (35d) to (23);
	\draw[se] (34.180) to[out=160] (14);
	\draw[se] (35.180) to[out=195] (24);

	\node (33w) [left = 0.9cm of 33] {};
	\draw[pe] (33) to (33w) to (14);
	\draw[pe] (33) to (33w) to (24);

	\node (32au) [above left = 2.0cm and 2.2cm of 32a] {};
%	\draw[se] (32a) to (32au) to (12a);

	\node (34au) [above left = 0.0cm and 2.0cm of 34a] {};
%	\draw[se] (34a) to (34au) to (14a);

	\node (36u) [above left = 0.2cm and 1.0cm of 35] {};
%	\draw[se] (36) to (16);

\draw[draw=none, use as bounding box] (current bounding box.north west) rectangle (current bounding box.south east);

\begin{pgfinterruptboundingbox}
	\draw[separator] (3.5cm,-3.3cm) to (3.5cm,6.5cm);
\end{pgfinterruptboundingbox}
\end{tikzpicture}
\caption{
Join source pairs incremental\\
before $\m{n}$.\lstinline{assume(b=c)}
}
\label{snippet3.23_graph1}
\end{figure}
Here the gray dashed lines represent the source pairs that we had to check for feasibility, but found currently infeasible - 
hence we call them \emph{potential} source pairs.\\
Notice that the potential source-pair \m{[b,c]} shares a source in each predecessor with a non-potential EC-node, 
but does not share a source with any EC-node in \emph{all} predecessors.\\
If we now \lstinline{assume(b=c)} at CFG-node \m{n}, we would initially get the situation at ~\ref{snippet3.23_graph2}
\begin{figure}[H]
\begin{tikzpicture}
  \node (1)  {};
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \node[gttn] (11)  [above right= 2.5cm and 0cm of 1] {$()$};
	\node[gl]   (11l) [below = 0 of 11]   {\m{p_0}};

	\node[gtn]  (12) [above left  = 1cm and 0.5cm of 11] {\s{a}};
	\node[gtn]  (14) [above right = 1cm and 0.5cm of 11] {\s{b}};
	
	\draw[gfa]  (12)  to node[el,anchor=east]  {\m{a}} (11);
	\draw[gfa]  (14)  to node[el,anchor=west]  {\m{b}} (11);

	\node[gttn] (12a)  [above = 1cm of 12]    {\m{(a)}};
	\node[gttn] (14a)  [above = 1cm of 14]    {\m{(b)}};

	\draw[sgtt] (12a) to node[el,anchor=east] {0} (12);
	\draw[sgtt] (14a) to node[el,anchor=west] {0} (14);

	\node[gtn]  (16) [above = 3cm of 11] {\tiny$\faB{f}{a}{b}$};
	\draw[gfa]  (16) to node[el,anchor=east] {\m{f}} (12a);
	\draw[gfa]  (16) to node[el,anchor=west] {\m{f}} (14a);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\node[gttn] (21)  [below right= 3.0cm and 0cm of 1] {$()$};
	\node[gl]   (21l) [below = 0 of 21]   {\m{p_1}};

	\node[gtn]  (22) [above left  = 1cm and 0.5cm of 21] {\s{a}};
	\node[gtn]  (24) [above right = 1cm and 0.5cm of 21] {\s{c}};
	
	\draw[gfa]  (22)  to node[el,anchor=east]  {\m{a}} (21);
	\draw[gfa]  (24)  to node[el,anchor=west]  {\m{c}} (21);

	\node[gttn] (22a)  [above = 1cm of 22]    {\m{(a)}};
	\node[gttn] (24a)  [above = 1cm of 24]    {\m{(c)}};

	\draw[sgtt] (22a) to node[el,anchor=east] {0} (22);
	\draw[sgtt] (24a) to node[el,anchor=west] {0} (24);

	\node[gtn]  (26) [above = 3cm of 21] {\tiny$\faB{f}{a}{c}$};
	\draw[gfa]  (26) to node[el,anchor=east] {\m{f}} (22a);
	\draw[gfa]  (26) to node[el,anchor=west] {\m{f}} (24a);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \node[gttn] (31)  [right = 6.5cm of 1] {$()$};
	\node[gl]   (31l) [below = 0 of 31]   {\m{n}};

	\node[gtn]  (32) [above left  = 1cm and 0.5cm of 31] {\s{a}};
	\node[pgtn] (33) [above right = 2cm and 0.5cm of 31] {\s{[b,c]}};
	\node[gtn]  (34) [above right = 1cm and 0.5cm of 31] {\s{b,c}};
%	\node[gtn]  (35) [above right = 1cm and 1.5cm of 31] {\s{c}};
	
	\draw[gfa]  (32)  to node[el,anchor=east]  {\m{a}} (31);
	\draw[gfa]  (34)  to[bend right] node[el,anchor=west]  {\m{b}} (31);
	\draw[gfa]  (34)  to[bend left]  node[el,anchor=west]  {\m{c}} (31);

	\node[gttn] (32a)  [above = 1cm of 32]    {\m{(a)}};
	\node[pgttn](33a)  [above = 0.5cm of 33]    {\m{(b)}};

	\draw[sgtt] (32a) to node[el,anchor=east] {0} (32);
	\draw[psgtt] (33a) to node[pl,anchor=west] {0} (33);

	\node[gtn]  (36) [above = 3.5cm of 31] {\tiny$\m{f(a)}$};
%	\node[gtn]  (36) [above = 1cm of 32a] {\tiny$\m{f(a)}$};
	\draw[gfa]  (36) to node[el,anchor=east] {\m{f}} (32a);
	\draw[pgfa] (36) to node[pl,anchor=west] {\m{f}} (33a);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\node (32u) [above left = 0.2cm and 1.0cm of 32] {};
	\node (32d) [below left = 0.2cm and 1.0cm of 32] {};
%	\draw[se] (32) to (32u) to (12);
%	\draw[se] (32) to (32d) to (22);

	\node (34u) [above left = 0.2cm and 2.5cm of 34] {};
	\node (35d) [below left = 0.3cm and 1.5cm of 35] {};
	\node (34w) [left = 0.0 of 34] {};
%	\draw[se] (34) to (34u) to (14);
%	\draw[se] (35) to (35d) to (23);
	\draw[se] (34) to (34w) to (14);
	\draw[se] (34) to (34w) to (24);
%	\draw[se] (34.180) to[out=195] (24);

	\node (33w) [left = 0.9cm of 33] {};
	\draw[pe] (33) to (33w) to (14);
	\draw[pe] (33) to (33w) to (24);

	\node (32au) [above left = 2.0cm and 2.2cm of 32a] {};
%	\draw[se] (32a) to (32au) to (12a);

	\node (34au) [above left = 0.0cm and 2.0cm of 34a] {};
%	\draw[se] (34a) to (34au) to (14a);

	\node (36u) [above left = 0.2cm and 1.0cm of 35] {};
%	\draw[se] (36) to (16);

\draw[draw=none, use as bounding box] (current bounding box.north west) rectangle (current bounding box.south east);

\begin{pgfinterruptboundingbox}
	\draw[separator] (3.5cm,-3.3cm) to (3.5cm,6.5cm);
\end{pgfinterruptboundingbox}
\end{tikzpicture}
\caption{
Join source pairs incremental\\
before $\m{n}$.\lstinline{assume(b=c)}
}
\label{snippet3.23_graph2}
\end{figure}
Now we can see that the node \s{b,c} at \m{n} shares the potential source-pair \m{[b,c]} and so this source-pair becomes feasible.
With non-unary functions this does not have to mean that any new nodes or gfas are needed - for example, consider the following variation on the above:\\
\m{\s{f(a)=g(b,d)} \sqcup \s{f(a)=g(c,e)}}\\
Now if we \lstinline{assume(b=c)} at the join node, \m{[b,c]} has become feasible but the potential tuple \m{[(b,d),(c,e)]} is not yet feasible as the source-pair \m{[d,e]} is not feasible, so no new nodes are added (our algorithm would remove the source-pair \m{[b,c]} from the set of infeasible source-pairs). The complexity of the update, in this case, only depends on the size of the set of source-pairs that \emph{become feasible}. In a non-incremental setting we would have to recalculate the whole set of source-pairs and re-determine 
which ones are feasible in order to remain complete.\\
We will discuss the incremental complexity of the weak join using source-pairs, as compared to the non-incremental complexity when we discuss the algorithm. 

\subsubsection*{Strong Join}
Our weak join is missing some obvious cases, as can be seen easily if we look at ~\ref{snippet3.20_graph3}:\\
\m{\s{f(a)=f(b)} \sqcup \s{a=b}}, where we want to create the term \m{f(a)} at \m{g_n}.\\
Here there is no source-pair for \m{f(a)} as \m{\sources{n}{p_1}{[f(a)]_{g_n}}=\emptyset}.
However, \m{\sources{n}{p_0}{[f(a)]_{g_n}}=[f(a)]_{g_{p_0}}} where \\
\m{\GFAECs{[f(a)]_{g_{p_0}}} = \s{\fa{f}{[a]_{g_{p_0}}},\fa{f}{[b]_{g_{p_0}}}}} - so how can we can we observe that the joined graph is missing a gfa at that EC-node?\\
In order to be able to determine locally (in \m{g_n}) when such a case occurs, we add state to \m{g_n} to represent the difference between
the equalities provable from \m{\eqs{p_1} \cup \eqs{n}} and those provable (and hence represented) in \m{g_n}.\\
This additional state is represented by the green line (and label) at ~\ref{snippet3.20_graph3} - it means that the two EC-nodes (tuple nodes in this case, but similarly for term nodes) \m{[(a)]_{n}} and \m{[(b)]_{n}} can be proven equal from \m{\eqs{p_1} \cup \eqs{n}}.\\
For a predecessor \m{p}, we will denote the case where two nodes \m{s,t \in g_n} can be proven equal from \\
\m{\eqs{p} \cup \eqs{n}}  as \m{p,n \models s=t}.\\
The additional state is represented using equivalence classes relative to a specific predecessors:\\
For \m{s,t \in g_{p_0}}, we use \m{[s]_{g_n}^0 = [t]_{g_n}^0} to represent the additional state that signifies that \m{s,t} are in the same equivalence class at \m{g_n} - implying:\\
\m{\exists u \in \terms{s},v \in \terms{t} \cdot \eqs{p} \cup \eqs{n} \models u=v}.\\
In example ~\ref{snippet3.20_graph3} we establish the equality \m{f(a)=f(b)} from \m{\eqs{n} \cup \eqs{p_0}} directly from an axiom, 
and from \m{\eqs{n} \cup \eqs{p_1}} by congruence closure.\\
The difference from the cases that are covered by the weak join is that here we are missing the node \m{[b]_{g_n}} at \m{g_n}.
If \m{[b]_{g_n}} had already existed, we would have known that, as it shares the source \m{[a]_{g_{p_1}}} (from \m{g_{p_1}}) with \m{[a]_{g_n}}, the gfas \m{f([a]_{g_{n}})} and \m{f([b]_{g_{n}})} are equal under \m{\eqs{n} \cup \eqs{p_1}} by congruence closure.\\
For the strong join we need to make sure we find all such missing nodes. \\
As before, we have two options for approaching this search - either bottom up, inspecting all potential missing nodes, but only feasible ones, or top down, inspecting only potential missing nodes that would be part of a gfa, but also including infeasible ones.\\
\textbf{Bottom up:}\\
In our example, inspecting bottom up we would need to generate all feasible source-pairs of relevant terms - in our case that means
we would create the source-pair \gta{[b]_{g_{p_0}}}{[b]_{g_{p_1}}} (as each member of the source pair appears in the downward closure of source nodes of the nodes of \m{g_n}), we know that the potential \m{g_n} node that belongs to this source-pair - which would be \m{[b]_{g_n}} if we were to add it - is equal in \m{\eqs{n} \cup \eqs{p_1}} to \m{[a]_{g_n}}, and so by congruence closure the gfas 
\m{f([a]_{g_n})} and \m{f([b]_{g_n})} are also equal in \m{\eqs{n} \cup \eqs{p_1}}.
We already know that \m{[f(a)]_{g_n})} is equal to \m{[f(b)]_{g_n})} in \m{\eqs{n} \cup \eqs{p_0}} because they share a source (\m{[f(a)]_{g_{p_0}}}), and so we know that \m{f([a]_{g_n}) = f([b]_{g_n})}.\\
In this case there are no other feasible potential source-pairs.
\begin{figure}[H]
\begin{tikzpicture}
  \node (1)  {};
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \node[gttn] (11)  [above right= 2.5cm and 0cm of 1] {$()$};
	\node[gl]   (11l) [below = 0 of 11]   {\m{p_0}};

	\node[gtn]  (12) [above left  = 1cm and 1cm of 11] {\s{a}};
	\node[gtn]  (14) [above right = 1cm and 1cm of 11] {\s{b}};
	
	\draw[gfa]  (12)  to node[el,anchor=east]  {\m{a}} (11);
	\draw[gfa]  (14)  to node[el,anchor=west]  {\m{b}} (11);

	\node[gttn] (12a)  [above = 1cm of 12]    {\m{(a)}};
	\node[gttn] (14a)  [above = 1cm of 14]    {\m{(b)}};

	\draw[sgtt] (12a) to node[el,anchor=east] {0} (12);
	\draw[sgtt] (14a) to node[el,anchor=west] {0} (14);

	\node[gtn]  (15) [above = 3cm of 11] {\tiny$\faB{f}{a}{b}$};
	\draw[gfa]  (15) to node[el,anchor=east] {\m{f}} (12a);
	\draw[gfa]  (15) to node[el,anchor=west] {\m{f}} (14a);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\node[gttn] (21)  [below right= 3.0cm and 0cm of 1] {$()$};
	\node[gl]   (21l) [below = 0 of 21]   {\m{p_1}};

  \node[gtn]  (22) [above  = 1.0cm of 21] {\s{a,b}};
	
  \draw[gfa] (22) to[bend right] node[el,anchor=east] {\m{a}} (21);
  \draw[gfa] (22) to[bend left]  node[el,anchor=west] {\m{b}} (21);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \node[gttn] (31)  [right = 6cm of 1] {$()$};
	\node[gl]   (31l) [below = 0 of 31]   {\m{n}};

	\node[gtn]   (32) [above left  = 1cm and 1cm of 31] {\s{a}};
	\node[pgtn]  (34) [above right = 1cm and 1cm of 31] {\gta{\s{b}}{\s{a,b}}};
	
	\draw[gfa]   (32)  to node[el,anchor=east]  {\m{a}} (31);
	\draw[pgfa]  (34)  to node[pl,anchor=west]  {\m{b}} (31);

	\node[gttn]  (32a)  [above = 1cm of 32]    {\m{(a)}};
	\node[pgttn] (34a)  [above = 1.1cm of 34]    {};

	\draw[sgtt]  (32a) to node[el,anchor=east] {0} (32);
	\draw[psgtt] (34a) to node[pl,anchor=west] {0} (34);

	\node[gtn]   (35) [above = 1cm of 32a] {\tiny$\m{f(a)}$};
	\draw[gfa]   (35) to node[el,anchor=east] {\m{f}} (32a);

	\node[pgtn]  (36) [above = 1.1cm of 34a] {\tiny$\m{f(b)}$};
	\draw[pgfa]  (36) to node[pl,anchor=west] {\m{f}} (34a);
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\node (32u) [above left = 0.2cm and 1.0cm of 32] {};
	\node (32d) [below left = 0.2cm and 1.0cm of 32] {};
	\draw[se] (32) to (32u) to (12);
	\draw[se] (32) to (32d) to (22);

	\node (34u) [above left = 0.2cm and 2.5cm of 34] {};
	\node (34d) [below left = 0.2cm and 2.5cm of 34] {};
	\draw[se] (34) to (34u) to (14);
	\draw[se] (34) to (34d) to (22);

%	\node (32au) [above left = 2.2cm and 2.5cm of 32a] {};
%	\draw[se] (32a) to[in=-10] (32au) to[out=170] (12a);

%	\node (34au) [above left = 0.0cm and 2.0cm of 34a] {};
%	\draw[se] (34a) to (34au) to (14a);


	\node (35u) [above left = 0.2cm and 1.0cm of 35] {};
	\draw[se] (35) to (15);

	\node (36u) [above left = 0.2cm and 1.0cm of 36] {};
	\draw[se] (36) to (15);

	\draw[green,dashed] (32.0) to node[pl,anchor=north,text=green,pos=0.3] {$\m{p_1}$} (34.180);
	\draw[green,dashed] (32a.0) to node[pl,anchor=north,text=green] {$\m{p_1}$} (34a.180);
	\draw[green,dashed] (35.0) to node[pl,anchor=north,text=green] {$\m{p_1}$} (36.180);
\draw[draw=none, use as bounding box] (current bounding box.north west) rectangle (current bounding box.south east);

\begin{pgfinterruptboundingbox}
	\draw[separator] (3.5cm,-3.3cm) to (3.5cm,6.5cm);
\end{pgfinterruptboundingbox}
\end{tikzpicture}
\caption{
Join gfa completeness missing paths\\
after $\m{n}$.\lstinline{add(f(a))}
}
\label{snippet3.20_graph4}
\end{figure}
We see in ~\ref{snippet3.20_graph4} that the two top nodes in \m{g_n} share a source in \m{p_0} and are marked equal in \m{p_1} by 
congruence closure, hence they are equal also at \m{n}.

\noindent
\textbf{Top down:}\\
In our example, we inspect \m{[f(a)]_{g_n}}, we find that the gfa \m{f([a]_{g_n})} has the same function symbol as \m{f([b]_{g_{p_0}})},
which appears in the source \m{[f(a)]_{g_{p_0}}}. Similar to source-pairs we inspect the pair \m{[a]_{g_n}} vs. \m{[b]_{g_{p_0}}} and
we find that \m{[a]_{g_{p_1}} \in \sources{n}{p_1}{[a]_{g_n}}}, and so we check for the feasibility of the (standard) source pair 
\gta{[b]_{g_{p_0}}}{[a]_{g_{p_1}}} as before - we find it is feasible, so create the corresponding \m{g_n} node \m{[b]_{g_n}} and add the gfa \m{f([b]_{g_n})} to \m{[f(b)]_{g_n}}.\\
Here the basic element we are dealing with, in addition to source pairs, is a pair of a node from \m{g_n} and a node from \m{g_{p_i}}.\\
We name these elements \emph{predecessor pairs} and denote them as \gtpa{s}{t}, where \m{s \in g_{p_0},t \in g_n},
and accordingly \gtpb{t}{s}, where \m{s \in g_{p_1},t \in g_n}.\\
In our example, we had \gtpa{[f(a)]_{g_{p_0}}}{[f(a)]_{g_n}} and we generated from it \\
\gtpa{[b]_{g_{p_0}}}{[a]_{g_n}}, 
from which we got \gta{[a]_{g_{p_0}}}{[b]_{g_{p_1}}} through \\
\m{{[b]_{g_{p_1}}} \in \sources{n}{p_1}{[a]_{g_n}}}.\\
Adding such a predecessor pair \gtpb{t}{s} to our data structure signifies that there is some sequence of functions,
s.t. applying that sequence to \m{t} in \m{g_n} reaches some term \m{u}, and applying it to \m{s} reaches \m{v} in \m{g_{p_i}},
and \m{v \in \sources{n}{p_i}{u}}. For non-unary functions, this only takes into account reachability thourough reverse gfa edges, 
regardless of other nodes that participate in the same tuple (we will discuss related optimizations later).\\
For our example the set of generated source-pairs and predecessor-pairs is depicted in ~\ref{snippet3.20_graph5}:

\begin{figure}[H]
\begin{tikzpicture}
  \node (1)  {};
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \node[gttn] (11)  [above right= 2.5cm and 0cm of 1] {$()$};
	\node[gl]   (11l) [below = 0 of 11]   {\m{p_1}};

	\node[gtn]  (12) [above left  = 1cm and 1cm of 11] {\s{a}};
	\node[gtn]  (14) [above right = 1cm and 1cm of 11] {\s{b}};
	
	\draw[gfa]  (12)  to node[el,anchor=east]  {\m{a}} (11);
	\draw[gfa]  (14)  to node[el,anchor=west]  {\m{b}} (11);

	\node[gttn] (12a)  [above = 1cm of 12]    {\m{(a)}};
	\node[gttn] (14a)  [above = 1cm of 14]    {\m{(b)}};

	\draw[sgtt] (12a) to node[el,anchor=east] {0} (12);
	\draw[sgtt] (14a) to node[el,anchor=west] {0} (14);

	\node[gtn]  (15) [above = 3cm of 11] {\tiny$\faB{f}{a}{b}$};
	\draw[gfa]  (15) to node[el,anchor=east] {\m{f}} (12a);
	\draw[gfa]  (15) to node[el,anchor=west] {\m{f}} (14a);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\node[gttn] (21)  [below right= 3.0cm and 0cm of 1] {$()$};
	\node[gl]   (21l) [below = 0 of 21]   {\m{p_2}};

  \node[gtn]  (22) [above  = 1.0cm of 21] {\s{a,b}};
	
  \draw[gfa] (22) to[bend right] node[el,anchor=east] {\m{a}} (21);
  \draw[gfa] (22) to[bend left]  node[el,anchor=west] {\m{b}} (21);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \node[gttn] (31)  [right = 6cm of 1] {$()$};
	\node[gl]   (31l) [below = 0 of 31]   {\m{n}};

	\node[gtn]  (32) [above left  = 1cm and 1cm of 31] {\s{a}};
	\node[pgtn] (34b)  [above right = 1cm and 1cm of 31]    {\m{\m{\gta{b}{a}}}};
	\node[pgtn]  (34) [above = 0.5cm of 34b] {\m{\gtpa{b}{a}}};
	
	\draw[gfa]  (32)  to node[el,anchor=east]  {\m{a}} (31);

	\node[gttn] (32a)  [above = 1.5cm of 32]    {\m{(a)}};
	\node[pgttn] (34a)  [above = 0.55cm of 34]    {\m{\gtpa{(b)}{(a)}}};

	\draw[pgfa]  (34b)  to node[pl,anchor=west]  {\m{b}} (31);
	

	\draw[sgtt] (32a) to node[el,anchor=east] {0} (32);
	\draw[psgtt] (34a) to node[pl,anchor=west] {0} (34);

	\node[gtn]  (35) [above = 1.5cm of 32a] {\tiny$\m{f(a)}$};
	\draw[gfa]  (35) to node[el,anchor=east] {\m{f}} (32a);

	\node[pgtn] (36) [above = 1.23cm of 34a] {\tiny$\m{\gtpa{f(a)}{\faB{f}{a}{b}}}$};
	\draw[pgfa] (36) to node[pl,anchor=west] {\m{f}} (34a);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\node (32u) [above left = 0.2cm and 1.0cm of 32] {};
	\node (32d) [below left = 0.2cm and 1.0cm of 32] {};
	\draw[se] (32) to (32u) to (12);
	\draw[se] (32) to (32d) to (22);

	\node (34u) [above left = 0.2cm and 2.5cm of 34] {};
	\node (34d) [below left = 0.2cm and 2.5cm of 34] {};
	\node (34bnw) [above left = 0.2cm and 1.8cm of 34b] {};
	\node (34bsw) [below left = 0.2cm and 1.8cm of 34b] {};
	\draw[se] (34b) to (34bnw) to (14);
	\draw[se] (34b) to (34bsw) to (22);
	\node (34nw) [above left = 0.2cm and 1.8cm of 34] {};
	\draw[se] (34) to (34nw) to (14);
%
	%%\node (32au) [above left = 2.2cm and 2.5cm of 32a] {};
	%%\draw[se] (32a) to[in=-10] (32au) to[out=170] (12a);
%%
	%%\node (34au) [above left = 0.0cm and 2.0cm of 34a] {};
	%%\draw[se] (34a) to (34au) to (14a);

	\node (35u) [above left = 0.2cm and 1.0cm of 35] {};
	\draw[se] (35) to (15);
	\node (36u) [above left = 0.2cm and 1.0cm of 36] {};
	\draw[se] (36) to (15);
	\draw[pe] (36.180) to (35.0);
	\draw[pe] (34.180) to (32.0);
%	\draw[pe,green] (34b.180) to (32.0);

	\draw[pe] (34.-90) to[out=-90,in=90] (34b.90);
%	\draw[pe] (34b) to (32);

	\draw[green,dashed] (34b) to node[pl,anchor=north,text=green] {$\m{p_1}$} (32);
%	\draw[green] (32a.0) to node[el,anchor=north,text=green] {$\m{p_1}$} (34a.180);
\draw[draw=none, use as bounding box] (current bounding box.north west) rectangle (current bounding box.south east);

\begin{pgfinterruptboundingbox}
	\draw[separator] (3.5cm,-3.3cm) to (3.5cm,6.5cm);
\end{pgfinterruptboundingbox}
\end{tikzpicture}
\caption{
Join gfa completeness missing paths\\
after $\m{n}$.\lstinline{add(f(a))}
}
\label{snippet3.20_graph5}
\end{figure}

We need to represent also when two \m{g_n} nodes are equal under \\
\m{\eqs{n} \cup \eqs{p_i}}  
(the horizontal green line in ~\ref{snippet3.20_graph3}) - we use the notation\\
\m{s =_n^{i} t} for this.

Our gfa completeness requirements for the top down approach include all rules for source-pairs we have used for the weak join, 
and the additional rules for predecessor pairs:

\begin{figure}
\begin{enumerate}
	\item All feasible source-pairs of existing nodes participate in the corresponding gfa:\\
	\m{\forall t \in g_n, \gta{s_0}{s_1} \in \sourcesB{n}{t},  \fa{f}{v_0} \in s_0, \fa{f}{v_1} \in s_1 \cdot}\\
	\m{\feasible{\gta{\tup{v_0}}{\tup{v_1}}} \Rightarrow \exists \fa{f}{u} \in t \cdot \gta{\tup{v_0}}{\tup{v_1}} \in \sourcesB{n}{\tup{u}}}
	\item All feasible predecessor-pairs of existing nodes participate in the corresponding gfa :\\
	\m{\forall t \in g_n, s_0 \in \sourcesB{n}{t}, \fa{f}{v_0} \in s_0, \fa{f}{u} \in t \cdot}\\
	\m{\feasible{\gtpa{\tup{v_0}}{\tup{u}}} \Rightarrow \exists \fa{f}{w} \in t \cdot \tup{v_0} \in \sources{n}{p_0}{\tup{w}}}
	And symmetrically for \m{p_1}.
	\item Feasibility for source-pairs:\\
	\m{\feasible{\gta{s_0}{s_1}} \triangleq }\\
	\m{(\exists t \in g_n \cdot \gta{s_0}{s_1} \in \sourcesB{n}{t}) \lor}\\
	\m{(\exists \fa{f}{u_0} \in s_0,\fa{f}{u_1} \in s_1 \cdot \feasible{\gta{\tup{u_0}}{\tup{u_1}}})}
	\item Feasibility for predecessor-pairs:\\
	\m{\feasible{\gtpa{s_0}{t}} \triangleq }\\
	\m{(\exists s_1 \in \sources{n}{p_1}{t} \cdot \feasible{\gta{s_0}{s_1}})}\\
	\m{\lor (\exists \fa{f}{u_0} \in s_0,\fa{f}{v} \in t \cdot \feasible{\gtpa{\tup{u_0}}{\tup{v}}})}\\
	\m{\lor (\exists u \in g_n \cdot s_0 \in \sources{n}{p_0}{u} \land u =_n^i t )}
	And symmetrically for \m{p_1}.
\end{enumerate}
\caption{strong join gfa completeness}
\label{strong_join_gfa_completeness}
\end{figure}

The third disjunct of 4 is needed if, for example, in ~\ref{snippet3.20_graph5} we had already added \m{b} to \m{g_n} before 
adding \m{f(a)} - we do not want to repeat the work of establishing \m{[a]_{g_n} =_n^1 [b]_{g_n}} (dashed green line in the digram), so we establish this equality (that is, place these two nodes in the same \m{p_1} equivalence class) when adding the node \m{[b]_{g_n}}, and use the result when adding term
\m{f(a)}.

Source completeness for the full join is as follows:
\begin{figure}[H]
\begin{enumerate}
	\item Weak source completeness:\\
	\m{\forall t \in g_n, i, \fa{f}{u} \in t, \tup{s_i} \in \sources{n}{p_i}{\tup{u}}, s \in g_{p_i} \cdot}\\
	\m{ \fa{f}{s_i} \in s \Rightarrow s \in \sources{n}{p_i}{t}}
	\item Per-predecessor equality base case:\\
	\m{\forall s,t \in g_n, i \cdot}\\
	\m{ (\sources{n}{p_i}{s} \cap \sources{n}{p_i}{t} \neq \emptyset) \Rightarrow s =_n^i t}
	\item Per-predecessor equality gruence closure:\\
	\m{\forall t \in g_n, i, \fa{f}{u} \in t, \tup{v} \in g_n, s \in g_n \cdot}\\
	\m{ (\tup{v} =_n^i \tup{u} \land \fa{f}{v} \in s) \Rightarrow s =_n^i t}
\end{enumerate}
\caption{strong join source completeness}
\label{strong_join_source_completeness}
\end{figure}


As in the weak join, there is no difference in the worst case behaviour between the top-down and bottom up approach.
We will discuss the exact complexity later, we just note here that the worst case size of all auxiliary data is 
\m{O(\size{g_{p_0}}\times\size{g_{p_1}} + \size{g_n} \times (\size{g_{p_0}} + \size{g_{p_1}}))} 
simply by counting all possible pairs of both kinds 
(the partitioning both of \m{g_{p_i}} and \m{g_n} can be maintained as mutually disjoint sets, hence do not affect asymptotic complexity).

%\m{p,n \vdash_k s=t}.\\
%(Strictly speaking, we mean \\
%\m{\forall s,t \in g_n,p \in \preds{n} \cdot}\\
%\m{n,p \vdash_k s=t \Leftrightarrow (\exists u \in \terms{s},v \in \terms{t} \cdot \eqs{p} \cup \eqs{n} \vdash_k u=v)} )\\
%Following our calculus, two such EC-nodes \m{s,t} at \m{g_n} can be proven equal from \m{\eqs{p} \cup \eqs{n}} by a proof of depth at most \m{k} iff one of the following holds:
%\begin{enumerate}
	%\item Axiom from \m{n}, or provable from \m{n}: \m{s\equiv t} 
	%\item Axiom from \m{p}: \m{\sources{n}{p}{s} \cap \sources{n}{p}{t} \neq \emptyset}
	%\item Transitivity: \m{\exists u \in g_n \cdot p,n \vdash_{k-1} s=u \land p,n \vdash_{k-1} u=t} (this is not a direct outcome from the definition of transitivity - in theory it could be that such \m{u} does not exist, we will show in the completeness proof that such a \m{u} must exist)
	%\item Congruence closure: \m{\exists \fa{f}{x} \in s,\fa{f}{y} \in t \cdot p,n \vdash_{k-1} \tup{x}=\tup{y}}  - we distinct
		%\subitem 4a: \m{\forall p' \in \preds{n} \cdot p',n \vdash \tup{x}=\tup{y}}
		%\subitem 4b: \m{\exists p' \in \preds{n} \cdot p',n \not\vdash \tup{x}=\tup{y}}
%\end{enumerate}
%
%We use \m{p,n \vdash_{k-1} \tup{x}=\tup{y}} to mean that for each \m{i} where \m{x_i\not\equiv y_i}, \\
%\m{p,n \vdash_{k-1} x_i=y_i}.
%
%The graph \m{g_n} is gfa-complete iff, for each EC-node \m{s}, for each term \m{u} s.t. 
%\m{\forall p \in \preds{n} \exists v_p \in \terms{s} \cdot p,n \models v_p=u}, \m{u \in \terms{s}}.\\
%To phrase our graph-based, local version of this invariant, we need to consider every combination of the last step of the proof of 
%\m{u=v_p} for each \m{p}.\\
%We will show the full case analysis in the completeness proof, here we only discuss the interesting cases:\\
%The various combinations with transitivity we will discuss when presenting the completeness proof, basically they do not add much complication as all EC-graphs are transitive closed by construction.\\
%If the last step for both predecessors is predecessor specific congruence closure (4b), 
%then we would reach a state where we have the equivalent of the above mentioned green line between \m{s,t} with both labels \m{p_0,p_1},
%and then we know we should merge \m{s} and \m{t}.\\
%If the last step for both predecessors is a predecessor specific axiom (2), then our completeness criterion by source-pairs suffices.\\
%If the last step for both predecessors is (4a), then \m{g_n \models \tup{x}=\tup{y}}, and hence by construction \m{s\equiv t}.\\
%There cannot be a combination of (4a) and (4b), be definition.\\
%In ~\ref{snippet3.20_graph3}, the last step in proving \m{f(a)=f(b)} from \m{p_0} was an axiom(2), and from \m{p_1} it was congruence closure(4b).\\
%Essentially, in this case we need to show that \m{n,p_1 \models (a)=(b)} which means \m{n,p_1 \models a=b}.
%This means, essentially, that 

%which means that we need to match a gfa from \m{g_{p_0}} with a gfa from \m{g_n}, rather than from \m{g_{p_1}}.\\
%Overloading the notation for source-pairs we are traversing downwards on the gfa-pair 
%\gta{\fa{f}{[b]_{g_{p_0}}}}{\fa{f}{[a]_{g_n}}}, to get the term-pair \gta{[b]_{g_{p_0}}}{[a]_{g_n}}.\\
%Now we use transitivity - \m{[a]_{g_{p_1}} \in \sources{n}{p_1}{[a]_{g_n}}}, 
%we traverse \\
%from \gta{\fa{f}{[b]_{g_{p_0}}}}{\fa{f}{[a]_{g_n}}} to \gta{[b]_{g_{p_0}}}{[a]_{g_{p_1}}},
%that is, transitivity means that, as a traversal step in a source-pair, we can replace in a source-pair a \m{g_n} node with one of its sources (according to position), and vice versa.
%Traversing this source-pair down we see it is feasible (as $b() \in \GFAECs{[a]_{g_{p_1}}}$ and \m{b() \in \GFAECs{[b]_{g_{p_0}}}}),
%so we can create bottom up, as before, the node \m{[b]_{g_n}} with the source-pair \gta{[b]_{g_{p_1}}}{[a]_{g_{p_1}}}.\\
%Now we need another step we did not have before - we need to add the gfa \fa{f}{[b]_{g_n}} to \m{[f(a)]_{g_n}}.\\
%This gfa we have traversed downwards before as part of the gfa-source-pair \gta{\fa{f}{[b]_{g_{p_0}}}}{\fa{f}{[a]_{g_n}}},
%so we can create it once we have determined its tuple-source-pair is feasible.\\
%In order to be incremental as described above, we would need to add to the state at each CFG-node the set of 
%term,(possibly tuple) and gfa source-pairs that we have already checked, including those that have been found feasible (except those that actually produced a node at \m{g_n}) and infeasible.
%Note that we did not include source-pairs where both nodes are from \m{g_n} - 
%the reason is that the meaning of these is ambiguous, 
%different depending on whether we have reached 
%The green line in ~\ref{snippet3.20_graph3}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\subsubsection*{Variants of Source Completeness}
We will show now a few examples that exhibit how our specific choice of establishing the source and propagation invariants compares to other options.

In the next example, ensuring the global (non-graph-based) source and propagation invariants can be done in a different way:
\begin{figure}[H]
\begin{lstlisting}
$\node{n_1}:$
assume $\m{P(f(a))}$
if (*)
	$\node{n_{2a}}:$
	assume $\m{a=b}$
	//extra terms { $\m{f(\s{a,b}),P(f(\s{a,b}))}$ }
else
	$\node{n_{2b}}:$
	assume $\m{a=c}$
	//extra terms { $\m{f(\s{a,c}),P(f(\s{a,c}))}$ }
$\node{n_3}:$
//our        extra terms: $\s{\m{f(\s{a}),P(f(\s{a}))}}$
//                 rgfas: $\s{\m{b,c,d}}$
//sufficient extra terms: $\s{\m{f(\s{b}),f(\s{c}),P(f(\s{b})),P(f(\s{c}))}}$
$\node{n_4}:$
assume $\m{a=b=c=d}$
assert $\m{P(f(d))}$ //negated $\m{\lnot P(f(\s{a,b,c,d}))}$
\end{lstlisting}
\caption{propagation sources}
\label{snippet3.16d}
\end{figure}
In ~\ref{snippet3.16d}, if we just want to ensure all equalities are propagated, we have two options for extra terms at \node{n_2}, both of which allow source completeness, but the second option adds more terms. 

The next example shows that we can achieve source completeness globally, without achieving it per path:
\begin{figure}[H]
\begin{lstlisting}
$\node{n_1}:$
assume $\m{P(f(a))}$
if (*)
	$\node{n_{2a}}:$
	assume $\m{a=b}$
	//extra terms { $\m{f(\s{a,b}),P(f(\s{a,b}))}$ }
else
	$\node{n_{2b}}:$
	assume $\m{c=b}$
$\node{n_3}:$
assume $\m{a=c}$
assert $\m{P(f(b))}$ //negated $\m{\lnot P(f(b))}$
\end{lstlisting}
\caption{propagation sources}
\label{snippet3.16e}
\end{figure}

In  ~\ref{snippet3.16e} on the path \m{\sourcesB{n_1.n_{2a}.n_3}{\s{f(\s{a,b,c})}}=\s{f(a)}}, \\
so the program (with the added terms) is source complete as\\
\m{\sources{n_3}{n_1}{\s{f(\s{a,b,c})}}=\s{f(a)}}, but not every path is source complete:\\
\m{\sourcesB{n_1.n_{2b}.n_3}{\s{f(\s{a,b,c})}}=\emptyset}. 
We see that this does not allow propagation completeness, and the assertion will not be proven.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%As a first approximation we might try to ensure source completeness by traversing the CFG in topological order and adding, at each node, the equivalence class of each term that appears in any of the predecessors.\\
%\textbf{Tree CFG source completeness:}\\
%If the CFG is a tree that would work, because of the following property:\\
%In a sequential node, each equality that holds at the predecessor holds also at the node, so each equivalence class of 
%\m{\terms{\Sigma}/\Eqs{n}} is a (disjoint) union of one or more ECs from \m{\terms{\Sigma}/\Eqs{p}}, where \m{p} is the direct predecessor of \m{n}.
%This property ensures that we have to add at most \size{g_p} EC nodes to \size{g_n} in order to ensure source completeness with the process described above.
%Assuming each node has at least one statement, the total complexity is then \m{O((\sum_n \size{g_n})^2)}, but could be expected to be nearer to \m{\sum_n \size{g_n}} in most DSA programs unless each node has a completely unrelated set of terms 
%(if the number of nodes \m{c} is more dominant than the number of function symbol occurrences then we would get \m{O(c \times (\sum_n \size{g_n}))} as each term can appear at each node).\\
%Note that in this case (topological order traversal), time complexity can be calculated from the space complexity:\\
%Assuming we construct the graph initially as in the verification algorithm above, each node would have a graph that includes the transitive sub-term closure of the terms that appear in the clauses of that node, under all equalities that hold at the node and predecessors (again assuming the graph has no joins).\\
%Under that assumption, when traversing the CFG in topological order, each node would have to add at most one EC (node) per predecessor EC (node), and so in the worst case , where the root has \m{k} EC nodes and the rest of the \m{c} CFG nodes have empty EC graphs, we would end up with \m{k \times c} total EC graph nodes.\\
%As described later, in our algorithm we would actually have less EC nodes, as identical sub-term closed EC sub-graphs are shared, but that does not change the asymptotic worst case.
%
%\subsubsection*{Join CFG source completeness:}
%At a join node \node{n} with two direct predecessors \m{p_1,p_2} 
%For a join node that was created using the verification algorithm above, the following property holds by construction:\\
%\m{\forall s \in \terms{g_{p_1}} \cap \terms{g_n} \cap \terms{g_{p_2}}, t \in \terms{g_{p_1} \cap{ g_{p_2}}} \cdot}\\ 
%\m{((g_{p_1} \models s=t \land g_{p_2} \models s=t) \Rightarrow (t \in \terms{g_n} \land g_n \models s=t))}\\
%That is, if two terms appear and are equal in both \m{p_1,p_2}, and at least one of them appears in \m{n} then so does the other and they are also equal in \m{n}.\\
%This property will be weakened once we add scoping and term-radius, and we will discuss that later.\\
%What this property means is that:\\
%Each equivalence class in \m{\terms{\Sigma}/\Eqs{n}} is a (disjoint) union of one or more elements from 
%\s{S_1 \cap S_2 \mid S_1 \in \terms{\Sigma}/\Eqs{p_1} \land S_2 \in \terms{\Sigma}/\Eqs{p_2}}.\\
%Given such \m{S_1 \cap S_2} we can define \m{[S_1 \cap S_2]_n} which is the equivalence class that includes all the elements of \m{S_1 \cap S_2}, as we know they will all appear in the same equivalence class at \m{n}.
%
%Using the above definition, given a node \m{n} with the predecessors \m{p_1,p_2} which are source complete, we can make \node{n} source complete by adding \\
%\s{[\terms{s} \cap \terms{t}]_n \mid t \in g_{p_1} \land s \in g_{p_2}} to \m{g_n}, where \m{t,s} are EC nodes.
%This adds at most \m{\size{g_{p_1}} \times \size{g_{p_2}}} nodes to \m{g_n}.\\
%The overall complexity is then at most double exponential in the number of function symbol occurrences (with the above assumption about CFG nodes). 
%We are only aware of an example for exponential lower bound (from ~\cite{GulwaniNecula07}, adjusted for \lstinline{assume} rather than assignments to get \m{O(2^n)} rather than \m{O(2^{\sqrt{n}})} as described later), and not aware of any double exponential lower bound.
%
%A double exponential algorithm is not practical, and the above algorithm adds many more terms than are needed, as it does not take into account at all the the terms present in successor nodes.
%
%We disregard, for now, the question of whether \m{\terms{s}} includes a maximal term in some clause at \m{p} and simply discuss sets of terms.\\
%We can phrase the original condition as:\\
%\m{\forall n,p \in cfg, s \in g_p, t \in g_n \cdot }\\
%\m{((\exists p.P.n \in cfg,s' \in \terms{s}, t' \in \terms{t} \cdot \Eqs{p.P.n} \models s'=t') \Rightarrow} \\
%\m{\exists p.P.n \in cfg \cdot s \in \sourcesB{p.P.n}{t}} \\
%However, this property is highly non-local, as "missing" sources on one branch can be compensated on another branch - for example:
%
%
%While this criterion is minimal, we have not found an obvious algorithm to establish minimal source completeness under this criterion that is local and can be calculated efficiently after source completeness is violated by arbitrary addition of equalities and terms (e.g. from a theory or quantifier instantiation).
%
%For this reason we strengthen our criterion:\\
%\m{\forall n,p \in cfg, s \in g_p, t \in g_n, p.P.n \in cfg \cdot }\\
%\m{((\exists s' \in \terms{s}, t' \in \terms{t} \cdot \Eqs{p.P.n} \models s'=t') \Rightarrow
%s \in \sourcesB{p.P.n}{t}} 
%
%So now each path must be source complete.
%
%However, if we translate this to the condition for any point on a path, we get:\\
%\m{\forall p.P.q.Q.n \in cfg, s \in g_p, t \in g_n \cdot }\\
%\m{(\exists s' \in \terms{s}, t' \in \terms{t} \cdot \Eqs{p.P.q.Q.n} \models s'=t') \Rightarrow}\\
%\m{\exists u \in g_q \cdot \cdot u \in \sourcesB{p.P.q}{t} \land s \in \sourcesB{q.Q.n}{t}}\\
%Meaning that for each term at the end of the path that is equivalent on the path (by \Eqs{} on the paths) to a term at the beginning of the path, for each CFG node on the path there must be an EC node that is equivalent to both terms along the path.\\
%This leaves some freedom in selecting the terms to add to internal nodes, which can effect efficiency - for example:

\subsubsection{Complexity}
Remember that our congruence closure only introduces new terms, consider ~\ref{snippet3.3},
\noindent
Here, \\ 
$
\begin{array}{lll}
	\precondIII{p_j}     & = & \s{\lnot \m{c_1} \lor \term{a=b}, \m{c_1} \lor \term{f(a)=f(b)}} \\
	\postcondIII{p_j}    & = & \s{\lnot \m{c_1} \lor \term{a=b}, \m{c_1} \lor \term{f(a)=f(b)}} \\
	\postcondIII{p_{ja}} & = & \s{\lnot \m{c_1} \lor \term{a=b}, \m{c_1} \lor \fau{f}{a}=\fau{f}{b},\fau{f}{a} \neq \fau{f}{b}}
\end{array}
$\\
which is sufficient to prove the assertion using a complete calculus, but the unit restricted version is:\\
$
\begin{array}{lll}
	\restrict{\precondIII{p_j}}{u}     & = & \s{} \\
	\restrict{\postcondIII{p_j}}{u}    & = & \s{} \\
	\restrict{\postcondIII{p_{ja}}}{u} & = & \s{\fau{f}{a} \neq \fau{f}{b}}
\end{array}
$\\
Which is insufficient.\\
If it were the case that $\fau{f}{a} \in \terms{\clauses{p_j}}$, for example if we added $\clauses{p_j} = \s{\fau{f}{a}=\term{d}}$, 
then $\fau{f}{a}=\fau{f}{b} \in \CC{\postcondIII{p_t} \cup \clauses{p_j}}$ and hence
$\fau{f}{a}=\fau{f}{b} \in \cprecondIII{p_j}$ and the pre and post-conditions would be:\\
$
\begin{array}{lll}
\precondIII{p_j}     & = & \s{\lnot \m{c_1} \lor \term{a=b}, \fau{f}{a}=\fau{f}{b}} \\
\postcondIII{p_j}    & = & \s{\lnot \m{c_1} \lor \term{a=b}, \fau{f}{a}=\fau{f}{b},\fau{f}{a}=\term{d}} \\
\postcondIII{p_{ja}} & = & \s{\lnot \m{c_1} \lor \term{a=b}, \fau{f}{a}=\fau{f}{b},\fau{f}{a}=\term{d},\fau{f}{a} \neq \fau{f}{b}}
\end{array}
$\\
And the unit version:\\
$
\begin{array}{lll}
\restrict{\precondIII{p_j}}{u}     & = & \s{\fau{f}{a}=\fau{f}{b}} \\
\restrict{\postcondIII{p_j}}{u}    & = & \s{\fau{f}{a}=\fau{f}{b}, \fau{f}{a}=\term{d}} \\
\restrict{\postcondIII{p_{ja}}}{u} & = & \s{\fau{f}{a}=\fau{f}{b}, \fau{f}{a}=\term{d},\fau{f}{a} \neq \fau{f}{b}} \\
\end{array}
$\\
And so we can derive the empty clause.
(we have omitted the equalities produced by reflexivity and transitivity, for clarity - they are built-in in our data structure).

This is undesirable for us as the addition of an unrelated and unused clause has put the program into our fragment - we want the fragment to be predictable to programmers.

We have explored three different approaches to attack this problem.\\
One idea would be to try to augment the set of terms of each side of a join with the terms on the other side (e.g. with reflexive equalities such as \term{f(a)=f(a)}, and then perform the join as above).
This would solve the above case, but consider:

\begin{lstlisting}[caption=join congruence closure co-propagation,label=snippet3.20]
$\node{p_b}:$
if ($\m{c_1}$)
	$\node{p_t}:$
	assume a=f(b)
else
	$\node{p_e}:$
	assume b=g(a)
$\node{p_j}:$
	$\node{p_ja}:$
	assert f(g(a))=f(b) || g(f(b))=g(a) 
	//negated $\fau{f}{\fau{g}{a}} \neq \fau{f}{b} \land \fau{g}{\fau{f}{b}} \neq \fau{g}{a}$
\end{lstlisting}

This program is not provable in the unit fragment which is reasonable, but the problem lies with the join, looking at the sets of terms:\\
$\begin{array}{lll}
	\terms{p_t} & = & \s{a,b,f(b)} \\
	\terms{p_e} & = & \s{a,b,g(a)} \\
\end{array}
$

If we were to try and complete each side with the other side's terms, we get, after one iteration and congruence closure:\\
$\begin{array}{lll}
	\terms{p_t} & = & \s{a,b,f(b),g(a),g(f(b))} \\
	\terms{p_e} & = & \s{a,b,g(a),f(b),f(g(a))} \\
\end{array}
$\\
And the next:\\
$\begin{array}{lll}
	\terms{p_t} & = & \s{a,b,f(b),g(a),g(f(b)),f(g(a)),f(g(f(a)))} \\
	\terms{p_e} & = & \s{a,b,g(a),f(b),f(g(a)),g(f(b)),g(f(g(b)))} \\
\end{array}
$\\
So this will diverge.\\
We would not want to limit congruence closure depth as we have seen that it does not add new equivalence classes in the sequential case.
We could mark terms as coming from completion and limit congruence closure only on these terms, however this is rather arbitrary and unrelated to the assertions we try to prove.
We have experimented with this approach but have found it to be not very efficient and unpredictable.

A variant on this approach would try to complete each side only as far as it could produce a new equality in the join, 
and relegate the rest to the non-unit fragment - however, going back to our previous example:
\begin{lstlisting}[caption=join congruence closure quadratic depth simple,label=snippet3.21]
$\node{p_b}:$
if ($\m{c_1}$)
	$\node{p_t}:$
	assume $\m{a=f^m(a)}$
else
	$\node{p_e}:$
	assume $\m{a=f^n(a)}$
$\node{p_j}:$
	$\node{p_{ja}}:$
	assert ......
\end{lstlisting}

Here we would need to complete each side to $\m{m \times n}$ terms in order to get all the possible equalities at the join.
The following example, taken from ~\cite{GulwaniTiwariNecula04} shows that the set of equalities at the join can be infinite for finite sets of clauses at the joined nodes:
\begin{lstlisting}[caption=join congruence closure infinite,label=snippet3.22]
$\node{p_b}:$
if ($\m{c_1}$)
	$\node{p_t}:$
	assume $\m{a=f(a)}$
	assume $\m{b=f(b)}$
	assume $\m{g(a)=g(b)}$
else
	$\node{p_e}:$
	assume $\m{a=b}$
$\node{p_j}:$
	$\node{p_{ja}}:$
	assert g(f(f(a)))=g(f(f(b)))
\end{lstlisting}

Here, the implied equalities at the join are $\m{g(f^k(a))=g(f^k(b))}$ for any non-negative k, and this is not finitely representable as a set of unit equalities. However, it seems clear which of these equalities are needed in order to prove the assertion, which leads us to the next approach:

We want the join to be sensitive not only to the terms and clauses at the join point but also those in all transitive successors.
We also want to keep the join calculation local in the sense that only the three involved nodes are needed to compute it.

For that, each node will ensure that each term that occurs in the node occurs also in all its predecessors - 
so in the above example:\\
$\terms{\clauses{p_{ja}}} = \s{a,b,f(a),f(b),f(f(a)),f(f(b)),g(f(f(a))),g(f(f(b)))}$\\
So all of these terms will be added (e.g. as reflexive self equality axioms) to all the nodes, and we would get(omitting reflexive axioms):\\
$
\begin{array}{lll}
	\restrict{\precondIII{p_j}}{u}     & = & \s{\term{g(a)=g(b),g(f(a))=g(f(b)),g(f(f(a)))=g(f(f(b)))}} \\
	\restrict{\postcondIII{p_j}}{u}    & = & \s{\term{g(a)=g(b),g(f(a))=g(f(b)),g(f(f(a)))=g(f(f(b)))}} \\
	\restrict{\postcondIII{p_{ja}}}{u} & = & \{\term{g(a)=g(b),g(f(a))=g(f(b)),g(f(f(a)))=g(f(f(b)))} \\
	                                   &   & \term{g(f(f(a))) \neq g(f(f(b)))}\} \\
\end{array}
$\\
So the program is now within our unit fragment.

To see how this works where scoping is involved, consider the following example that uses DSA variables:
\begin{lstlisting}[caption=join congruence closure DSA chain,label=snippet3.23]
$\node{p_b}:$
if ($\m{c_1}$)
	$\node{p_t}:$
	assume $\m{a=b}$
else
	$\node{p_e}:$
	assume $\m{f(a)=f(b)}$
	assume $\m{g(a)=g(b)}$
$\node{p_j}:$
...
$\node{p_1}:$
	assume $\m{a_1 = a}$
	assume $\m{b_1 = b}$
$\node{p_2}:$
	assume $\m{a_2 = a_1}$
	assume $\m{b_2 = b_1}$
	...
$\node{p_n}:$
	assume $\m{a_n = a_{n-1}}$
	assume $\m{b_n = b_{n-1}}$
	$\node{p_{na}}:$
	assert $\m{f(a_n)=f(b_n)}$ //negated $\m{f(a_n) \neq f(b_n)}$
\end{lstlisting}

Assuming that each variable is only in scope where it is alive, 
the node \node{p_{na}} cannot communicate directly with either of \node{p_t}, \node{p_e} or \node{p_j} as its scope contains only \s{a_n, b_n} whereas the other nodes only have \s{a,b}. Also, any of the nodes \node{p_1} to \node{p_{n-1}} could have equality information relevant to \term{a_n}, and so information has to flow through all these nodes.

We want all the terms that are \emph{potentially equivalent} to \m{f(a_n),f(b_n)} to occur at \node{p_j}.
As the above example shows, a term being potentially equivalent should have a broader meaning - roughly if a term \term{t} occurs at node \node{n}, for each transitive predecessor \node{p} of \node{n} the set of {potentially equivalent terms} to \term{t} are all the terms \term{s} in the scope of \node{p} for which there is a path from \node{p} to \node{n} where the unit ground equalities of all the nodes along the path imply that \term{t=s} (this definition works for paths with joins, but only for unit equalities).

In our example, for the term \term{a_n} at \node{p_{na}}, there is exactly one path from \node{p_j} to \node{p_{na}} and, although the set of \emph{equivalent terms} along this path is \s{a,a_1,...a_{n}}, the set at each node \node{p_i} along the path is \s{a_i,a_{i+1}} and at \node{p_j} it is \s{a}. 

At \node{p_j} we already have the term \term{a} so nothing further needs to be done.
We follow the same path also for the terms \term{f(a_n),b_n,f(b_n)}, and so the terms \term{f(a),f(b)} will be added to the nodes \node{p_j}, \node{p_t}. The node \node{p_e} already contains all the potentially equivalent terms and the node \node{p_b} does not have any potentially equivalent terms in scope as its scope does not contain either \term{a} or \term{b}.

The node \node{n_t} performs congruence closure to get \term{f(a)=f(b)} and so the join at \node{p_j} would also contain \term{f(a)=f(b)}, which would be propagated all the way to \node{p_{na}} as \term{f(a_n)=f(b_n)} - so the assertion will be proven.
Note that the unnecessary terms \term{g(a),g(b)} did not affect the set of terms at any node.
Note also that the no successor of any of the mentioned nodes that is not also a transitive predecessor of the assertion was affected, and neither was any node prior to the introduction of the terms \term{a,b}.

However, we have now introduced a complexity problem - consider:
\begin{lstlisting}[caption=congruence closure source polynomial,label=snippet3.24]
$\node{p_b}:$
	assume $\m{f(a,a)=d}$
if ($\m{c_1}$)
	$\node{p_t}:$
	assume $\m{a=b}$
	assume $\m{c=d}$
		$\node{p_{ta}}:$
		assert f(b,b)=c
else
	$\node{p_e}:$ ...
$\node{p_j}:$ ...
\end{lstlisting}

Now the set of terms that \node{p_{ta}} is interested in (after propagation and congruence closure):\\
$\terms{p_{ta}} = \s{a,b,c,d,f(a,a),f(a,b),f(b,a),f(b,b)}$

So from the one term \term{f(b,b)} we got four terms \term{f(a,a),f(a,b),f(b,a),f(b,b)} and obviously more equalities at \node{p_t} would entail more terms are needed at \term{p_t} to ensure that we have covered all possibilities.
For example, the term \term{f(f(a,a),f(a,a))} would require 16 options and another level would require 256 options.
In this case exactly one option is useful - \term{f(a,a)} for \term{f(b,b)} and \term{d} for \term{c}.
This kind of expansion is at most polynomial in the number of equalities where the degree of the polynomial is the largest function arity in the signature, which would already make the algorithm not very scalable, however consider the following:
\begin{lstlisting}[caption=congruence closure source loop,label=snippet3.25]
$\node{p_b}:$
	assume $\m{f(g(a),g(a))=c}$
if ($\m{c_1}$)
	$\node{p_t}:$
	assume $\m{a=g(a)}$
		$\node{p_{ta}}:$
		assert $\m{f(a,a)=c}$
else
	$\node{p_e}:$ ...
$\node{p_j}:$ ...
\end{lstlisting}

Here the set of potentially relevant terms at \node{p_b} is \s{\m{f(g^m(a),g^n(a))} } for any \m{m,n} - so an infinite set.

In both of the above examples it seems obvious which terms are needed for completeness: in ~\ref{snippet3.24} we see that out of all the potentially relevant terms, only the tuple \term{(a,a)} has a corresponding term \term{f(a,a)}.
For ~\ref{snippet3.25} we can try to determine this set bottom up: we start with the constant \term{a} and determine its equivalent terms in predecessors, then we look at each term for which all sub-terms have been processed, as \term{a=g(a)}, we need to check the terms \s{g(a),f(a,a)} - we only find \term{g(a)} which maps to the equivalence class for \term{a} at \node{p_{ta}} so now we need to consider: \\
\s{g(g(a)), f(a,g(a)), f(g(a),a), f(g(a),g(a))}\\
We only find \term{f(g(a),g(a))} which is (or its equivalents are) then added to all the nodes on the path between \node{p_{ta}} and \node{p_b}, which then suffices to prove the assertion. 
We present the end result, showing only a set of unit equalities sufficient to generate the congruence relation at each node, 
and the reflexive closure of a term if it does not appear in any other clause.
The end result is:\\
$
\begin{array}{llll}
	\clauses{p_b}    & = & \s{f(g(a),g(a))=c} \\
	\clauses{p_t}    & = & \s{f(g(a),g(a))=c,a=g(a)} \\
	\clauses{p_{ta}} & = & \s{f(g(a),g(a))=c,a=g(a),f(g(a),f(g(a))) \neq c} \\
\end{array}
$

As we will be representing terms by their equivalence classes, we measure the complexity of a node \node{n} as follows:\\
We use \clauseseq{n} for the set of unit equalities at \clauses{n}.
In general, for a sequential node \node{n} and its direct predecessor \node{p}, it does not hold that 
$\clauseseq{p} \subseteq \clauseseq{n}$.
However we claim that $\restrict{\clauseseq{p}}{\terms{n}} \subseteq \restrict{\clauseseq{n}}{\terms{n}}$.\\
The reason is that \terms{n} is subterm closed, and for any term in \terms{n} we would propagate all unit equalities on that term from \node{p} to \node{n} (as described in the process above), and so $\restrict{\clauses{p}}{\terms{n}} \subseteq \clauses{n}$. We will prove these claims formally later.
In the algorithm described above, a term can be added to \terms{n} only if it exists already in a direct predecessor of \node{n}, and an equivalent term exists already in \succst{n}. Each such added term will have all of its unit equalities from predecessors of \node{n} also added to \node{n}, so that the number of equivalence classes added to \node{n} is bounded by the size of $\ECs{\bigcup\limits_{\m{p} \in \predst{n}} \clauses{p}}$, which is in turn bounded by the size of $\terms{\bigcup\limits_{\m{p} \in \predst{n}} \clauses{p}}$, as no step in our algorithm can add a term to \node{n} unless there is already an equivalent term in $\terms{\bigcup\limits_{\m{p} \in \predst{n}} \clauses{p}}$.
We will discuss complexity further when we present our data structure.

Coming back to example ~\ref{snippet3.3}:

\noindent
Now, the terms \term{f(a),f(b)} are added to \terms{p_j} and so:\\
Here, \\ 
$
\begin{array}{lll}
	\precondIII{p_j}     & = & \s{\lnot \m{c_1} \lor \term{a=b}, \term{f(a)=f(b)}} \\
	\postcondIII{p_j}    & = & \s{\lnot \m{c_1} \lor \term{a=b}, \term{f(a)=f(b)}} \\
	\postcondIII{p_{ja}} & = & \s{\lnot \m{c_1} \lor \term{a=b}, \term{f(a)=f(b)}, \term{f(a) \neq f(b)}}
\end{array}
$\\
And the unit restriction is:\\
$
\begin{array}{lll}
	\restrict{\precondIII{p_j}}{u}     & = & \s{\term{f(a)=f(b)}} \\
	\restrict{\postcondIII{p_j}}{u}    & = & \s{\term{f(a)=f(b)}} \\
	\restrict{\postcondIII{p_{ja}}}{u} & = & \s{\term{f(a)=f(b)},\fau{f}{a} \neq \fau{f}{b}}
\end{array}
$\\
Which now lets us prove the assertion.

Consider also the following example:
\begin{lstlisting}[caption=join congruence closure,label=snippet3.26]
$\node{p_b}:$
if ($\m{c_1}$)
	$\node{p_{t1}}:$
	assume $\m{a=b}$
	assume $\m{P(f(a,b))=T}$
else
	$\node{p_{e1}}:$
	assume $\m{P(f(b,a))=T}$
$\node{p_{j1}}:$
if ($\m{c_2}$)
	$\node{p_{t2}}:$
	assume $\m{a=b}$
		$\node{p_{t2a}}:$
		assert $\m{P(f(a,a))=T}$
			//negated $\m{f(a) \neq f(b)}$
else
	....
\end{lstlisting}

Here, \node{p_{t2a}} would request from \node{p_{t2}} the equalities for the equivalence class for \\
\s{P(f(a,a))} (and for T, but we ignore that for now).\\
\node{p_{t2}} would request from \node{p_{j1}} the equivalence class first for 
\s{a,b}, \\
and then for \s{f(a,a),f(a,b),f(b,a),f(b,b)}.\\
When \node{p_{j1}} requests these from \node{p_{t1}}, the answer is \\
\s{f(a,a),f(a,b),f(b,a),f(b,b)}, \\
as they are all in the same equivalence class at \node{p_{t1}}.\\
In this case  \node{p_{t1}} can choose to create only \m{f(b,a)}, because it is the only member of the equivalence class that exists also at \node{p_{e1}}, so there could be no extra equality information about any of the others.

However, going back to the previous example ~\ref{snippet3.10}:\\
Now the query to $\node{p_{j1}}$ would actually consist of \\
$\{P(a,a),P(a,b),P(a,c),P(a,d),P(b,a),P(b,b),P(b,c),P(b,d), \\
P(c,a),P(c,b),P(c,c),P(c,d),P(d,a),P(d,b),P(d,c),P(d,d)\}$ \\
Or in short: \\
\s{P(\s{a,b,c,d},\s{a,b,c,d})}. \\
In fact, at the join point all of these terms equal \m{T}, and each single one of them would be sufficient in order to prove the assertion.
If we add any of the 16 equations in \s{P(\s{a,b,c,d},\s{a,b,c,d})=T} to $\node{p_{j1}}$ we would be able to prove the assertion.

Before we describe how we handle this example, consider again a variant of ~\ref{snippet3.11}:
\begin{lstlisting}[caption=join congruence closure quadratic branch,label=snippet3.27]
$\node{p_b}:$
if ($\m{c_1}$)
	$\node{p_{t1}}:$
	assume $f^{m}(a)=b$
	assume $f^{m}(b)=b$
else
	$\node{p_{e1}}:$
	assume $f^{n}(a)=b$
	assume $f^{n}(b)=b$
$\node{p_{j1}}:$
if ($\m{c_2}$)
	$\node{p_{t2}}:$
	assume a=f(a)
		$\node{p_{t2a}}:$
		assert $a = b$
			//negated $\m{a \neq b}$
else
	....
\end{lstlisting}
Here, if \m{m} and \m{n} are co-prime then at the join we would have only \m{f^{m \times n}(a)=b} and \m{f^{2(m \times n)}(a)=f^{(m \times n)}(a)}, 
so the size of the unit representation of the join is also quadratic as above.
In this case there is no choice of small join interpolant (that is, a conjunction of unit ground equalities)  linear in the size of the program that holds at $\node{p_{j1}}$ and is sufficient to prove the assertion.
As mentioned in the previous section, cascading joins with quadratic expansion in the term depth could potentially lead to double exponential expansion in the term depth, but we are not aware of a concrete example for this or even single exponential expansion.

Coming back to ~\ref{snippet3.11}:\\
We will discuss the exact complexity analysis in detail when we discuss the join algorithm.
For the purpose of the ground fragment, however, it is instructive to see how this issue manifests itself in DPLL and superposition:\\
For DPLL, if we first \lstinline{decide} on \term{c1} and then on \term{\lnot c1}, we would not need any join and the e-graph 
will not contain more representatives of \\
\s{P(\s{a,b,c,d},\s{a,b,c,d})} than those appearing on the path that we choose.

For superposition, if we assume some strict order e.g. \term{d>c>b>d>T}, assuming the input includes clauses of the form:\\
\term{\lnot c_1 \lor d=c} \\
\term{\lnot c_1 \lor P(d,d)=T} \\
We could get the following set of clauses (depending on which clauses are chosen for derivations):\\
\term{\lnot c_1 \lor P(d,d)=T} \\
\term{\lnot c_1 \lor P(d,c)=T} \\
\term{\lnot c_1 \lor P(c,d)=T} \\
\term{\lnot c_1 \lor P(c,c)=T} \\
...\\
in general, all 16 rewrite options on each side, depending on the chosen term ordering.
We could be luckier with a different ordering, or if the inequality in was chosen for negative superposition first and then the correct resolutions were performed, but we are looking at the worst case.
Note that if we allow the path condition literals to be higher in the ordering than the equalities, we automatically get a quadratic size by the resolution of each term from each joinee with each term from the other joinee.

There are several ways to handle this problem:\\
The simplest way is to allow all these 16 terms to be added to \node{p_{j1}}, and rely on the term radius limitations in order to ensure a bound on the global number of terms in the system - this is a last resort solution but the simplest to implement and analyze.

Another solution would be to choose, for each such query \\ \s{P(\s{a,b,c,d},\s{a,b,c,d})}, one representative.

Suppose that the one answer that was chosen for the first query was \term{P(c,d)}.
Now consider what could happen on the other side of the branch:
\begin{lstlisting}[caption=join congruence closure quadratic branch else,label=snippet3.11a]
...
$\node{p_{j1}}:$
if ($\m{c_2}$)
	$\node{p_{t2}}:$
	assume $\m{a=b}$
	assume $\m{b=c}$
	assume $\m{c=d}$
		$\node{p_{t2a}}:$
		assert P(b,d)=T
			//negated $\m{P(b,d) \neq T}$
else
	$\node{p_{t2}}:$
	assume $\m{a=b}$
	assume $\m{c=d}$
		$\node{p_{t2a}}:$
		assert $\m{P(b,d)=T}$
			//negated $\m{P(b,d) \neq T}$
\end{lstlisting}

Now \node{p_{j1}} will get a query for \s{P(\s{a,b},\s{c,d})}, while we remember that we have queried \s{P(\s{a,b,c,d},\s{a,b,c,d})} before.
This means we cannot trust the results of a previous query that covers our query, and must repeat each query that does not equal exactly a previous query.

Given a sub-term-closed set of terms \m{S}, and two finite sets of equalities \m{E_1,E_2}, ~\cite{GulwaniTiwariNecula04} calculate the \emph{relative complete join} of \m{E_1,E_2} with respect to \m{S} as:\\
$\m{J_1} = \s{t=s \mid t,s \in S \land E_1 \models t=s \land E_2 \models t=s }$\\
Where they show the result is in linear space in the size of \m{S}.\\
This means calculating all equalities that hold on members of \m{S} - essentially an 
\emph{eager} (potentially too strong), but sufficient, interpolant (if an interpolant as a conjunction of unit equalities exists) between \m{ E_1 \lor E_2 } and any disjunction of inequalities over \m{S}.
(by \m{ E_1 \lor E_2 } we mean \s{ l_1 \lor l_2 \mid l_1 \in E_1 \land l_2 \in E_2}


In our setting we need to refine this formulation somewhat:\\
If the set of clauses \clauses{n_j} at the join node \node{n_j} contains the unit equalities \m{E_j}, 
then for any sub-term-closed set of terms \m{S} such that $\terms{E_j} \subseteq \m{S}$ we can calculate:\\
$\m{J_2} = \s{t=s \mid t,s \in \m{S} \land E_1 \cup E_j \models t=s \land E_2 \cup E_j \models t=s }$\\
The size of \ECs{J_2} is \m{O(\size{S} + \size{\ECs{E_j}} + \size{\ECs{E_1}} + \size{\ECs{E_2}})} by a simple argument:\\
We can build \m{E_1' = E_1 \cup E_j \cup {t=t \mid t \in S}} and similarly for \m{E_2}, and then apply the result above.
$\size{E_1'} \le \size{\ECs{E_1}} + \size{\ECs{E_j}} + \size{S}$ because 
$\terms{E_1 \cup E_j} = \terms{E_1} \cup \terms{E_j}$ and $\m{{E_1'}_=} \subseteq \m{{E_1}_=}$ and $\m{{E_1'}_=} \subseteq \m{{E_j}_=}$ 
and because, as shown in ~\cite{GulwaniTiwariNecula04}, adding a term \m{t} to a set of equations adds at most \size{t} equations, and \m{S} is sub-term-closed.

We require $\terms{n_j} \subseteq \m{S}$ because this ensures that no information is lost when replacing \m{E_j} with \m{J_2}.

\vspace{1pt}

How do we choose \m{S}? \\
Our representation (described in the next section) for a set of equalities \m{E} is (roughly) a graph \m{G_E} with \size{\ECs{E}} \emph{term EC nodes} and, for each term $t=\fa{f}{si} \in \terms{E}$ \arity{f} ordered edges from \m{[t]_{E_=}} to each of \m{[s_i]_{E_=}} labeled \m{f_i} - where edges with the same label, source and target are merged.
By definition this means that \size{\m{G_E}} (sum of number of nodes and edges) is less than or equal to $2\size{E}$, as each node and edge correspond to at least one occurrence of a function symbol in \m{E}.

If we consider a CFG that is in fact just a sequence of \m{n} basic blocks, with a total of \m{c} flat (in)equalities in the whole program, we want to bound the total size of representing the equivalence classes in all nodes.
According to the definition of \postcondIII{n}, each CFG node \emph{imports} all the (in)equalities from its predecessors, so the last node includes the union of all (in)equalities in the program.
If each node imports (copies) all (in)equalities from its predecessor, adds these imported (in)equalities to its own set of equalities (\clauses{n}) and creates the equivalence class graph described above for the union of these equalities, the total size of the graph is at most the sum of the sizes of the graphs that would be generated for each \clauses{n} separately, so if the equalities are divided evenly between the CFG node, then at least half the nodes can have a graph whose size is half the number of equations - so we have a quadratic overall size of all the graphs in the CFG.

In general we cannot hope for better than quadratic minimal number of equations to represent the state at each program point, however we can refine the above in two ways:
\begin{itemize}
	\item Scoping - the size of the program that we are using as the input size is in fact the size of the DSA version of the program.
	The relation between the number of DSA variables \m{d} and the number of original program variables \m{v} is that each program variable has at least one DSA version, each assignment in the original program introduces one DSA version of a variable and is translated to at least one unit equality assume statement - so  \m{nv \geq d \geq v} for \m{n} basic blocks. 
	New DSA versions are also introduced for join points, and can also be introduced to model non-determinism, program external input, the output of a method call, loop internal variables and possibly other modeling needs. A join can introduce a new DSA version for several variables simultaneously.
	In terms of scope, each CFG node has at most two DSA versions of each program variable in scope, by the definition of DSA.
	As shown in ~\cite{McMillan05} and ~\cite{FuchsGoelGrundyKrsticTinelli2012}, the fragment of unit ground equality (conjunctions of unit ground equalities) supports interpolation, but not unit-only interpolants - for example (based on ~\cite{FuchsGoelGrundyKrsticTinelli2012}):\\
	An (reverse) interpolant of $\m{A}=\s{a=f(b,e) , c=f(d,e)}$ and \\
	\m{B=\s{a \neq c, b=d}} is \m{b \neq d \lor a=c}, but there is no interpolant as a conjunction of ground unit equalities (A conjunction non ground existential interpolant exists: \m{\exists x \cdot a=f(b,x) \land c=f(d,x)}).
	As discussed later, in such a case we might add \m{e} to the scope of \m{B} for completeness (we do not support existential interpolants).
	Given an equivalence class graph, by removing a constant we mean removing all terms that include that constant, and all equivalence classes that contains only terms with this constant, and the relevant edges.
	We only restrict the scope for constants. Removing a constant from an EC graph can leave the number of nodes unchanged and the number of edges reduced by 1, or it could leave the graph empty. Restricting the EC graph at each node to scope however, makes sense when we also limit the size of terms. We will discuss the term radius concept later, but generally given \m{f} functions of maximal arity \m{a}, and \m{c} constants, the number of terms \m{t} of depth up to \m{d} in this signature respects \m{t = O(f^{a^{d-1}}c^{a^d})}, so limiting the number of constants can affect the worst case space behaviour of the verifier significantly.
\end{itemize}

In the above example it would seem obvious that adding the terms \m{f(a),f(b)} to would allow the program to verify.
However, we have already seen examples, where any sub-term-closed set of terms which is sufficient to verify the program gives an exponential sized join.

In the rest of this section we will discuss a compromise between propagating all potentially useful information and having polynomial performance.

If the join node is an assertion node, which has just one ground unit inequality clause (which is the negated assertion), and 
\m{S} is the set of terms that appear in that inequality, then the above mentioned join is, in a sense, an \emph{eager} (potentially stronger than minimal, but sufficient if an interpolant of the form exists) form of an interpolant.

If the set of clauses \clauses{n_j} at the join node \node{n_j} contains the unit equalities \m{E_j}, then for any set of inequalities \m{NE_j}, we can refine the above definition to:\\
$\m{J_2} = \s{t=s \mid t,s \in \terms{NE_j} \land E_1 \cup E_j \models t=s \land E_2 \cup E_j \models t=s }$\\
And then \\
$(\CC{E_1 \cup E_j} \cap \CC{E_2 \cup E_j}) \cup \m{NE_j} \models \emptyClause \Leftrightarrow \m{ \exists l \in J_2 \cdot \lnot l \in \m{NE_j}}$\\
So \m{J_2} is an \emph{eager} (potentially too strong), but sufficient, interpolant (if an interpolant as a conjunction of unit equalities exists) between \m{ E_1 \lor E_2 } and \m{E_j \cup NE_j}.
(by \m{ E_1 \lor E_2 } we mean \s{ l_1 \lor l_2 \mid l_1 \in E_1 \land l_2 \in E_2}

The reason that we are interested in an eager interpolant is that the price of traversing the CFG in order to answer the question whether an (in)equality holds is relative to the number of nodes traversed (and also the size of the query, answer and data structures at each node). If most answers to such queries are negative - that is, the transitive predecessors of the querying node cannot prove or refute the query - then it is advantageous to answer as many such potential questions in one CFG traversal as possible, as long as the complexity of the answer and traversal can be bounded to be linear in the size of the original question.
As an example:
\begin{lstlisting}[caption=congruence closure eager interpolant,label=snippet3.28]
assume $\m{\forall x,y \cdot P(x,y) \rightarrow x=y}$
$\node{p_1}:$
assume $\m{d=e}$
$\node{p_2}:$
assume $\m{a=b}$
$\node{p_3}:$
assume $\m{c=d}$

....

$\node{p_4}:$
assume $\m{b=c}$

...

$\node{p_{5a}}:$
assert $\m{P(a,e)}$
\end{lstlisting}

If we assume here that the terms \m{a,e} only appear at \node{p_{5a}} after applying some theory reasoning or quantifier instantiation - that is, we first run the unit ground fragment, found no proof, then we apply one iteration of theory or quantifier instantiation at each node, and then try to saturate the unit ground fragment.
Here, at \node{p_4}, propagating only equality information for \m{b,c} would not produce any extra information.\\
Node \node{p_{5a}}, could request equality information for \m{a} and \m{e}, 
and then the question is how this request would be propagated from \node{p_4} - if we just query about \m{a,e} (as \m{b,c} were already queried), we would not get any extra information. If we query about \m{a,b,c,e}, then \m{p_3} 
would have to query again about \m{a,b,c,d,e}, which would return 


Ignoring scoping, we could try a variation on an existing approach inspired by IC3/PDR, in the style of :\\
\node{p_{5a}} would query its predecessors for a refutation of the cube (conjunction of literals) \m{a=e}\\
\node{p_4}

The algorithm, as presented there, begins by adding all the terms in \m{S} to both \m{E_1} and \m{E_2}

In our case, the join point \node{n_j} has a set of clauses already deduced there - \m{E_j} (initially \clauses{n_j}), and we are in fact interested in restricting the join \\
\s{t=s \mid E_1 \cup E_j \models t=s \land E_2 \cup E_j \models s=t} which in our terminology is:\\
\m{\CC{E_1 \cup E_j} \cap \CC{E_2 \cup E_j}}

We need a slightly stronger version of this property, however, as it does not take into account the set of clauses already deduced at the join - \m{E_j} (initially \clauses{n_j} for a join node\node{n_j}).
As stated above, we 

 - so we get a complete join for 
space the join of the sets \emph{relative} to \m{t}: \m{J_{S} = \restrict{E_1 \sqcup E_2}{\m{t}}} - that is, for each term \m{t \in S}, \\
each term in \m{S}, and furthermore, each such \m{t} is in \terms{S}.

Now the definition of the full join is:\\
\s{E_j = \CC{E_1 \cup E_j} \cap \CC{E_2 \cup E_j}}\\
However, as we have seen, this can be quadratic at each join, so we want to reduce it to the set of terms at \m{E_j} (as a first approximation), 
	
Here we want the following stronger formulation, if \m{J} is the join (set of equalities) we calculate:\\
\m{\forall t \in \terms{E_j} \cdot \forall s \in \Ts{\sig} \cdot} \\ 
\m{E_1 \cup E_j \models t=s \land E_2 \cup E_j \models t=s \Rightarrow J_{S} \models t=s \land t \in \terms{J} }

In this case the space complexity requirement is slightly different:\\
\m{\size{\ECs{J}} = O(\size{\ECs{E_1}} + \size{\ECs{E_2}} + \size{\ECs{E_j}})} - that is, the set of equivalence classes at the join is linear in the number of equivalence classes in the input. 
The reason this holds


To summarize:
We have defined pre- and post-conditions for the unit ground fragment that tries to maximize the set of provable programs while remaining at the unit ground level.


\subsubsection*{Minimizing CFG traversals:}
Once the ground unit equalities fragment has to interact with larger fragments, in theory a new ground equality for a given term can appear at a given node at any time we apply the larger fragment at that node. We want to avoid having to repeat all the queries a node has performed once we have applied a larger fragment at any transitive predecessor.

In order to reduce the number of CFG traversals, we apply increasing fragments in the following way:
\begin{itemize}
	\item First we perform \lstinline{saturate} for the unit equality fragment, but we import also non-unit ground clauses and simplify them accordingly
	\item We now choose the next fragment (e.g. one step of ground resolution/superposition, one step of quantifier instantiation) and traverse the CFG in topological order - for each node:
		\subitem First we synchronize the node with the predecessor - we import all relevant new clauses (including new equalities) from the predecessor and saturate the unit ground fragment. 		
		\subitem Now we apply one step of the current fragment and again saturate the unit ground fragment.
\end{itemize}

The idea of \emph{synchronization} is simple: at a given node we have a set of terms for which we have imported all relevant transitive predecessor clauses for all the previous fragments. 
The new fragment might have introduced more relevant clauses for our set of terms in any of the transitive predecessors, so we need to make sure that all these clauses are imported. 
In order to avoid requerying the CFG recursively, each node maintains a list of clauses added since the last synchronization operation, and when synchronizing a node would import all clauses from that list in direct predecessors that are relevant for our set of terms.
This way we are guaranteed all the our relevant clauses from all transitive predecessors of a node reach the direct predecessors of the node before we traverse that node.\\
This works as long as the \m{sources} function does not change - however, consider the following example:

\begin{lstlisting}[caption=propagation sources fragment interaction,label=snippet3.19]
$\node{n_1}:$
assume a=b
assume $\m{\forall x \cdot f(f(x))=g(x)}$
assume $\m{\forall x \cdot g(x)=c}$
$\node{n_2}:$
...
$\node{n_k}:$
	assume $\m{a=f(a)}$
	$\node{n_{ka}}:$
		assert $\m{a=c}$
\end{lstlisting}

In the first pass, with only unit ground equalities, we will not be able to prove the assertion.\\
\node{n_k} would have to query at least about the terms \s{a,c,f(a)} and would get \s{a=b} (assuming we do not propagate non-ground clauses for now - we will discuss that later).

In the second pass, \node{n_1} instantiates \m{\forall x \cdot f(f(x))=g(x)} to get \m{f(f(a))=g(a)} and
\m{\forall x \cdot g(x)=c} to get \m{g(a)=c}.\\
Now, if \m{sources(a)} at \node{n_k} had included \m{f(f(a))}, then in the second pass these two clauses will be imported in the synchronization stage (\m{f(f(a))=g(a)} causes \m{g(a)=c} to be imported by the sub-term condition) and so there will not be any further recursive traversal of the CFG before the assertion is discharged.\\
However, there is no obvious reason to include e.g. \m{f(f(a))} and not \m{f(f(f(a)))} when calculating \m{sources(a)} in the first pass - we do not have enough information about the next pass (we want to keep the flexibility of choosing the fragment for the next pass later).

The tradeoff is either larger queries vs. potentially more traversals of the CFG when importing at the next pass.

We just note here that one could argue that queries should be more involved than just finite sets of terms, and in the above case we could query for \m{a} \emph{assuming} \m{f(a)=a}, but in the general case the size of the query might grow to be as large as the set of equalities at the querying node - and joining queries or incremental queries become much more complicated. We will discuss this question in later sections. 

The strategy we have selected is as follows:\\
When adding a term \m{t} to the graph at a node \node{n}, we have to query all predecessors for equalities on the sources \m{s} of that term - when this query reaches a node \node{p}, it will be propagated down unless:
\begin{itemize}
	\item \node{p} is the root
	\item \node{p} has already queried about \m{t} (in fact, about transitive \m{sources(t)} applied on all paths between \node{n} and \node{p})
	\item \node{p} does not have some sub-term of \m{t} in scope - discussed in later sections
\end{itemize}

We can avoid a large number of these queries by adding a fourth stopping condition - if we know that some term \m{s} does not appear in any transitive predecessor of \m{p} then \m{p} need not query about any super-term of \m{s}, as it cannot appear in any transitive predecessor either.\\
So now, when first adding a term, when traversing down the CFG to find all equalities for that term, each node would add all the terms matching the query that appear in the predecessor, even if they do not participate in any equality. The query terms that have not been matched will also be remembered as a \emph{rejected} term - 
now we do not need to query about any term for which any sub-term is rejected.
This way, a node will never receive a query about a super-term of a rejected term.

This gives us a first clue on how to filter the potential \m{source(t)} - we can build the set bottom up (starting from constants), only adding terms in the equivalence class of \m{t}, and stopping whenever a term is rejected in the predecessor (we discuss joins later).
This way \m{source(t)} is guaranteed to include all and only terms \m{s} for which there is some path to some transitive predecessor so that there is a term \m{u} that appears in a clause in that predecessor and the equalities along the path imply \m{s=u}.

The rejected terms also help us reduce the amount of CFG traversals - in the above example, after the first pass, 
all nodes \node{n_1}..\node{n_{k-1}} will have the term \m{a}, but will have \m{f(a)} as a rejected term, 
and \m{f(f(a))} will not appear at all.\\
During the second pass, when we synchronize each of \node{n_2}..\node{n_{k}}, the synchronization process will detect that a rejected term \m{f(a)} has been added to a predecessor, and so will import all relevant clauses for that term and add the term to the set of terms of the node.
Synchronize at \node{n_k} will detect both \m{f(a)} has been added to the predecessor, and so will query about the next member of the equivalence class, \m{f(f(a))} that now could potentially have extra information at predecessors - this will cause one extra traversal of the CFG to retrieve the clauses \s{f(f(a))=g(a),g(a)=c} in order to discharge the assertion.

Obviously, we do not want to recalculate \m{sources(t)} at a node \node{n} whenever we query any super-term of \m{t}, so we cache this set once it is calculated, and use the cache to detect changes in predecessors when synchronizing.

For rejected terms the invariant is:\\
For each node \node{n} and direct predecessor \node{p}, 
for each term \m{\fa{f}{t} \in g_{n}}, 
for each tuple \m{\tup{s} \in sources(n,\tup{t})}, 
\m{\fa{f}{s} \notin g_p \Leftrightarrow \fa{f}{s} \in rejected(p)}.


\newpage
\section{Data Structure}
We describe a per-node congruence closure data structure along with its operations.
This data structure is quite similar to those described in ~\cite{NelsonOppen80}, ~\cite{DowneySethiTarjan}, ~\cite{Shostak84} (corrected and explained in ~\cite{Cyrluk96onshostak}, ~\cite{Ganzinger02} and ~\cite{RuessS01} among others) and compared in ~\cite{AbstractCongruenceClosure}, and joins are related to ~\cite{JoinUIF} and ~\cite{Vagvolgyi03b} and we also draw from ~\cite{SuperpositionModuloShostak}.

Our Data structure differs from some of the above in the following main ways:
\begin{itemize}
	\item We describe a system of communicating data structures, as opposed to a monolithic one in most of the above
	\item We support incremental meet and meet+join operations on the data structures, as new (in)equalities are discovered - the joins mentioned above are not incremental
	\item We try to minimize space and time by sharing as much as possible of the per-node data structures between nodes that share equivalence classes
	\item Our data structure is monotonic in the sense that it cannot forget learned (in)equalities (although we do garbage collect no longer useful terms)
	\item Our data structure has a unique normal form for each set of equalities and sub-term-closed set of represented terms, regardless of the order of operations used to construct it - useful for calculating joins
	\item Our data structure maintains information about previous queries by transitive successor nodes in order to avoid repeated queries (cache)
\end{itemize}

\subsection{Terminology}
We do not represent ground term equivalence classes using a representative but rather a dedicated object.
We also include an object per ground tuple equivalence class, although it is essentially redundant - we will discuss the reasoning behind this later.

We use the following sets and kinds of objects:
\begin{itemize}
	\item \GTEC : A ground term equivalence class
	\item \GTTEC : A ground tuple equivalence class
of a \GTTEC
	\item \sig{n} : The signature of node \node{n}, specifically \Fn{n} is the set of functions in \sig{n}
	\item \ECs{n} : The per node congruence closure data structure for node \node{n} that includes, among other details described later:
	\begin{itemize}
		\item \GTECs{n} : The set of ground term equivalence classes represented at the node \node{n}
		\item \GTTECs{n}: The set of ground term tuple equivalence classes represented at \node{n}
%		\item \GFAECs{n}: The set of ground function application equivalence classes represented at \node{n}
	\end{itemize}
	\item We use the following functions:
		\subitem \gts{n}: $\cup \GTECs{n}$ - \GTECs{n} are a partition of \gts{n}
		\subitem \Eqs{n} : The set of equalities that \GTECs{n} represents - that is
		$\s{\term{t1=t2} \mid t1 \not\equiv t2 \land \exists \term{gt} \in \GTECs{n} \cdot (\term{t1,t2 \in gt})}$ -
		this may be infinite if e.g. $\term(a=f(a)) \in \Eqs{n}$ which implies, for all k, $\term(a=f^k(a)) \in \Eqs{n}$
		\subitem \Eqst{n} : The set of equalities implied by \node{n} and its predecessors at \node{n} -
		defined recursively: \\
		\s{t1=t2 \mid t1,t2 \in \Ts{\sig{n}} \cap (\bigcap\limits_{p \in \preds{n}} ( \mathbf{CC}(\Eqs{n} \cup \Eqst{p}) )}
\end{itemize}

We represent the congruence closure of a set of equalities \term{E} by \CC{E} (implicitly on the signature of \term{E}) and the congruence closure of \term{E} restricted to the signature \sig as $\CC{E}{F}=\left.\CC{E}\right|_{\Ts{\sig}}$.\\
We sometimes treat each equivalence class object as a set of its members, for example, when we create a new term from a \GTTEC gtt and a function \function{f} we define the new equivalence class as \s{f(tt) \mid tt \in gtt}.
We say a term equivalence class \term{t} \emph{exists} at a node \node{n} if $\term{t} \in \GTECs{n}$

Our per-node data structure supports the following basic operations for the node \node{n}:
\begin{itemize}
	\item \lstinline{makeTerm(f : $\Fn{n}$,gtt : $\GTTECs{n}$)} : \GTEC \\
		Create the \GTEC \term{f(gtt)} from the existing \term{gtt} in \GTTECs{n} and add it to \GTECs{n}.
	\item \lstinline{makeTuple(gts : $\GTTECs{n}*$)} : \GTTEC
		Create the t\GTTEC \term{gts} from existing ground term ECs, and add it it to \GTTECs{n}
	\item \lstinline{merge(gt1,gt2 : \GTEC)} : \GTEC \\
		Merge the \GTEC{s} \term{gt1} and \term{gt2}, and perform congruence closure.
	\item \lstinline{synchronize()} \\
		Synchronize the node \node{n} with relevant information not yet propagated from predecessors.
\end{itemize}


\subsection{Sequential Nodes}
In figure \ref{ec_graph_example_sequential_1}  we show a merge operation on a node \node{n} with one predecessor \node{p}.
Note that any number of new nodes can be created in \node{n} but only nodes that are transitive superterms of the merged nodes can be affected.

\begin{figure}[!htp]
\centering
\begin{subfigure}[t]{\textwidth}
	\framebox[\textwidth]{
	\raisebox{0pt}[0.4\textheight][0pt]
	{
		\begin{tikzpicture}
			\node(O) at (0,0){};
			\node[gttn] (1)  at (2,2.5)                         {$()$};
			\node[gtn]  (2)  [above left =0.5cm and 0.7cm of 1] {\s{a}};
			\node[gtn]  (3)  [above right=0.5cm and 0.7cm of 1] {\s{b}};
			\node[gttn] (4)  [above      =0.5cm           of 2] {$\s{(a)}$};
			\node[gttn] (5)  [above      =0.5cm           of 3] {$\s{(b)}$};
			\node[gtn]  (6)  [above      =0.5cm           of 4] {\s{f(a)}};
			\node[gtn]  (7)  [above      =0.5cm           of 5] {\svb{f(b)}{g(f^n(f(a)))}};
			\node[gttn] (8)  [above      =0.5cm           of 6] {$\s{(f(a))}$};

			\node[gl,align=left] (1l) [below = 0cm of 1] {p};
						
			\draw[gfa] (2)     to node[el] {\term{a}} (1);
			\draw[gfa] (3)     to node[el] {\term{b}} (1);
			\draw[gfa] (6)     to node[el] {\term{f}} (4);
			\draw[gfa] (7)     to node[el] {\term{f}} (5);
			\draw[gfa] (6.225) to[out=225,in=135,looseness=2] node[el] {\term{f}} (8.135);
			\draw[gfa] (7.210) to[out=210,in=45 ,looseness=3] node[el] {\term{g}} (8.45);

			\draw[sgtt] (4) to node[el] {\term{0}} (2);
			\draw[sgtt] (5) to node[el] {\term{0}} (3);
			\draw[sgtt] (8) to node[el] {\term{0}} (6);

			\node[gttn] (11)  [right      =          5.0cm of  1]   {$()$};
			\node[gtn]  (13)  [above right=0.5cm and 0.5cm of 11]   {\s{b}};
			\node[gtn]  (19)  [above left =0.5cm and 0.5cm of 11]   {\s{c}};
			\node[gttn] (21)  [above      =0.5cm           of 19]   {$\s{(c)}$};
			\node[gtn]  (17)  [above      =0.5cm           of 21]   {\s{f(c)}};

			\node[gl,align=left] (11l) [below = 0cm of 11] {n};
						
			\draw[gfa] (13) to node[el] {\term{b}} (11);
			\draw[gfa] (19) to node[el] {\term{c}} (11);
			\draw[gfa] (17) to node[el] {\term{f}} (21);

			\draw[sgtt] (21) to node[el] {\term{0}} (19);

		\end{tikzpicture}
	}}
		\caption{before the \lstinline{merge} operation}
		\label{ec_graph_example_sequential_1a}
\end{subfigure}

\begin{subfigure}[t]{\textwidth}
	\framebox[\textwidth]{
	\raisebox{0pt}[0.4\textheight][0pt]
	{
		\begin{tikzpicture}
			\node(O) at (0,0){};
			\node[gttn] (1)  at (2,2.5)                       {$()$};
			\node[gtn]  (2)  [above left =0.5cm and 0.7cm of 1]   {\s{a}};
			\node[gtn]  (3)  [above right=0.5cm and 0.7cm of 1]   {\s{b}};
			\node[gttn] (4)  [above      =0.5cm           of 2]   {$\s{(a)}$};
			\node[gttn] (5)  [above      =0.5cm           of 3]   {$\s{(b)}$};
			\node[gtn]  (6)  [above      =0.5cm           of 4]   {\s{f(a)}};
			\node[gtn]  (7)  [above      =0.5cm           of 5]   {\svb{f(b)}{g(f^n(f(a)))}};
			\node[gttn] (8)  [above      =0.5cm           of 6]   {$\s{(f(a))}$};

			\node[gl,align=left] (1l) [below = 0cm of 1] {p};
						
			\draw[gfa] (2)     to node[el] {\term{a}} (1);
			\draw[gfa] (3)     to node[el] {\term{b}} (1);
			\draw[gfa] (6)     to node[el] {\term{f}} (4);
			\draw[gfa] (7)     to node[el] {\term{f}} (5);
			\draw[gfa] (6.225) to[out=225,in=135,looseness=2] node[el] {\term{f}} (8.135);
			\draw[gfa] (7.210) to[out=210,in=45 ,looseness=3] node[el] {\term{g}} (8.45);

			\draw[sgtt] (4) to node[el] {\term{0}} (2);
			\draw[sgtt] (5) to node[el] {\term{0}} (3);
			\draw[sgtt] (8) to node[el] {\term{0}} (6);

			\node[gttn] (11)  [right      =          5.0cm of  1]   {$()$};
			\node[gtn]  (12)  [above left =0.5cm and 0.5cm of 11]   {\s{a}};
			\node[gtn]  (13)  [above right=0.5cm and 0.5cm of 11]   {\s{b,c}};
			\node[gttn] (14)  [above      =0.5cm           of 12]   {$\s{(a)}$};
			\node[gttn] (15)  [above      =0.5cm           of 13]   {$\s{(b),(c)}$};
			\node[gtn]  (16)  [above      =0.5cm           of 14]   {\s{f(a)}};
			\node[gtn]  (17)  [above      =0.5cm           of 15]   {\svb{f(b),f(c)}{g(f^n(f(a)))}};
			\node[gttn] (18)  [above      =0.5cm           of 16]   {$\s{(f(a))}$};

			\node[gl,align=left] (11l) [below = 0cm of 11] {n};
						
			\draw[gfa] (12)     to[bend right]node[el] {\term{a}} (11);
			\draw[gfa] (13)     to            node[el] {\term{b}} (11);
			\draw[gfa] (13)     to[bend left] node[el] {\term{c}} (11);
			\draw[gfa] (16)     to            node[el] {\term{f}} (14);
			\draw[gfa] (17)     to            node[el] {\term{f}} (15);
			\draw[gfa] (17.210) to[out=210,in=45, looseness=2] node[el] {\term{g}} (18.45);
			\draw[gfa] (16.225) to[out=225,in=135,looseness=2] node[el] {\term{f}} (18.135);

			\draw[sgtt] (14) to node[el] {\term{0}} (12);
			\draw[sgtt] (15) to node[el] {\term{0}} (13);
			\draw[sgtt] (18) to node[el] {\term{0}} (16);

		\end{tikzpicture}
	}}
	\caption{after \lstinline{n.merge(\{b\},\{c\})}}
	\label{ec_graph_example_sequential_1b}
\end{subfigure}
\caption{Sequential \lstinline{merge}}
\label{ec_graph_example_sequential_1}
\end{figure}

In figure \ref{ec_graph_example_sequential_2} we show a \lstinline{makeTerm} operation on a node \node{n} with one predecessor \node{p}.
Note that no pre-existing node in \node{n} can be merged by the operation, but new merged (and cyclic) nodes can be created.
Note also that in order to determine which nodes in \node{p} are relevant, \node{n} had to lookup
a super-edge with label \term{f} of node \s{(c)} at \node{p}, then it would need to look at all sub-edges of \s{g(b),f(c)} at \node{p},
find the edge labled \term{g} and connect it to the corresponding \term{a,b}, and then again query \node{p} for the super-edge \term{g} of \term{a},
after which it would get the cyclic node from \node{p} and have to add the cyclic edge labeled \term{h}.
This up and down process (in the sense of the arrows in the diagram) shows that any number of edges and nodes may need to be added in this process.

\begin{figure}[!htp]
\centering
\begin{subfigure}[t]{\textwidth}
	\framebox[\textwidth]{
	\raisebox{0pt}[0.4\textheight][0pt]
	{
		\begin{tikzpicture}
			\node(O) at (0,0){};
			\node[gttn] (0)  at (-2,1)                           {$()$};
			\node[gtn]  (1)  [above left =1.0cm and 1.0cm of 0] {\s{a}};
			\node[gtn]  (3)  [above      =0.85cm          of 0] {\s{b}};
			\node[gtn]  (5)  [above right=1.0cm and 1.0cm of 0] {\s{c}};
			\node[gttn] (2)  [above      =0.5cm           of 1] {$\s{(a)}$};
			\node[gttn] (4)  [above      =0.5cm           of 3] {$\s{(b)}$};
			\node[gttn] (6)  [above      =0.5cm           of 5] {$\s{(c)}$};
			\node[gtn]  (7)  [above      =0.5cm           of 2] {\svb{g(a)}{h^n(g(a))}};
			\node[gtn]  (9)  [above      =0.5cm           of 6] {\s{g(b),f(c)}};
			\node[gttn] (8)  [above      =0.5cm           of 7] {$(\svb{g(a)}{h^n(g(a))})$};

			\node[gl,align=left] (0l) [below = 0cm of 0] {p};
						
			%\draw[gfa] (1) to node[el] {\term{a}} (0);
			%\draw[gfa] (3) to node[el] {\term{b}} (0);
			%\draw[gfa] (5) to node[el] {\term{c}} (0);
			%\draw[gfa] (7) to node[el] {\term{g}} (2);
			%\draw[gfa] (9) to node[el] {\term{g}} (4);
			%\draw[gfa] (9) to node[el] {\term{f}} (6);
			%\draw[gfa] (7.225) to[out=210,in=120,looseness=2] node[el,anchor=west] {\term{h}} (8.135);

			\draw[gfa] (1) to node[el] {\term{a}} (0)
			           (3) to node[el] {\term{b}} (0)
			           (5) to node[el] {\term{c}} (0)
			           (7) to node[el] {\term{g}} (2)
			           (9) to node[el] {\term{g}} (4)
			           (9) to node[el] {\term{f}} (6)
			           (7.225) to[out=210,in=120,looseness=2] node[el,anchor=west] {\term{h}} (8.135);

			\draw[sgtt] (2) to node[el] {\term{0}} (1);
			\draw[sgtt] (4) to node[el] {\term{0}} (3);
			\draw[sgtt] (6) to node[el] {\term{0}} (5);
			\draw[sgtt] (8) to node[el] {\term{0}} (7);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
			\node[gttn] (10)  [right      =          5.0cm of  0] {$()$};
			\node[gtn]  (11)  [above left =1.0cm and 0.7cm of 10] {\s{a,b}};
			\node[gtn]  (15)  [above right=1.0cm and 0.7cm of 10] {\s{c}};
			\node[gttn] (16)  [above      =0.5cm           of 15] {$\s{(c)}$};

			\node[gl,align=left] (10l) [below = 0cm of 10] {n};
						
			\draw[gfa] (11) to[bend right] node[el] {\term{a}} (10);
			\draw[gfa] (11) to[bend left]  node[el] {\term{b}} (10);
			\draw[gfa] (15) to             node[el] {\term{c}} (10);

			\draw (16) edge[sgtt] node[el] {\term{0}} (15);

		\end{tikzpicture}
	}}
		\caption{before the \lstinline{makeTerm} operation}
		\label{ec_graph_example_sequential_2a}
\end{subfigure}

\begin{subfigure}[t]{\textwidth}
	\framebox[\textwidth]{
	\raisebox{0pt}[0.4\textheight][0pt]
	{
		\begin{tikzpicture}
			\node(O) at (0,0){};
			\node[gttn] (0)  at (-2,1.5)                           {$()$};
			\node[gtn]  (1)  [above left =1.0cm and 1.0cm of 0] {\s{\term{a}}};
			\node[gtn]  (3)  [above      =0.85cm          of 0] {\s{\term{b}}};
			\node[gtn]  (5)  [above right=1.0cm and 1.0cm of 0] {\s{\term{c}}};
			\node[gttn] (2)  [above      =0.5cm           of 1] {$\s{\term{(a)}}$};
			\node[gttn] (4)  [above      =0.5cm           of 3] {$\s{\term{(b)}}$};
			\node[gttn] (6)  [above      =0.5cm           of 5] {$\s{\term{(c)}}$};
			\node[gtn]  (7)  [above      =0.5cm           of 2] {$\s{\term{h^n(g(a))}}$};
			\node[gtn]  (9)  [above      =0.5cm           of 6] {$\s{\term{g(b),f(c)}}$};
			\node[gttn] (8)  [above      =0.5cm           of 7] {$\s{\term{(h^n(g(a)))}}$};

			\node[gl,align=left] (0l) [below = 0cm of 0] {p};
						
			\draw[gfa] (1) to node[el] {\term{a}} (0);
			\draw[gfa] (3) to node[el] {\term{b}} (0);
			\draw[gfa] (5) to node[el] {\term{c}} (0);
			\draw[gfa] (7) to node[el] {\term{g}} (2);
			\draw[gfa] (9) to node[el] {\term{g}} (4);
			\draw[gfa] (9) to node[el] {\term{f}} (6);
			\draw[gfa] (7.210) edge[gfa,out=210,in=120,looseness=2.5] node[el] {\term{h}} (8.135);

			\draw[sgtt] (2) to node[el] {\term{0}} (1);
			\draw[sgtt] (4) to node[el] {\term{0}} (3);
			\draw[sgtt] (6) to node[el] {\term{0}} (5);
			\draw[sgtt] (8) to node[el] {\term{0}} (7);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
			\node[gttn] (10)  [right      =          5.0cm of  0] {$()$};
			\node[gtn]  (11)  [above left =1.0cm and 0.7cm of 10] {\s{a,b}};
			\node[gtn]  (15)  [above right=1.0cm and 0.7cm of 10] {\s{c}};
			\node[gttn] (14)  [above      =0.5cm           of 11] {$\s{({a},{b})}$};
			\node[gttn] (16)  [above      =0.5cm           of 15] {$\s{(c)}$};
			\node[gtn]  (17)  [above      =3.0cm           of 10] {$\svb{h^n(g({a,b}))}{h^n(f(c))}$};
			\node[gttn] (18)  [above      =0.5cm           of 17] {$\svb{(h^n(g({a,b})))}{(h^n(f(c)))}$};

			\node[gl,align=left] (10l) [below = 0cm of 10] {n};
						
			\draw (11) edge[gfa,bend right] node[el] {\term{a}} (10);
			\draw (11) edge[gfa,bend left]  node[el] {\term{b}} (10);
			\draw (15) edge[gfa]            node[el] {\term{c}} (10);
			\draw (17) edge[gfa]            node[el] {\term{f}} (16);
			\draw (17) edge[gfa]            node[el] {\term{g}} (14);
			\draw (17.330) edge[gfa,out=330,in=45,looseness=3] node[el] {\term{h}} (18.45);

			\draw (14) edge[sgtt] node[el] {\term{0}} (11);
			\draw (16) edge[sgtt] node[el] {\term{0}} (15);
			\draw (18) edge[sgtt] node[el] {\term{0}} (17);

		\end{tikzpicture}
	}}
	\caption{after the \lstinline{makeTerm(f,(\{c\}))} operation}
	\label{ec_graph_example_sequential_2b}
\end{subfigure}
\caption{Sequential \lstinline{makeTerm}}
\label{ec_graph_example_sequential_2}
\end{figure}


In figure \ref{ec_graph_example_sequential_3} we show a \lstinline{synchronize} operation on a node \node{n} with one predecessor \node{p}.
In figure \ref{ec_graph_example_sequential_3a} we see the state before \node{p} has performed a merge where the two nodes are synchronized.
In figure \ref{ec_graph_example_sequential_3b} \node{p} has performed a merge and now node \node{n} is out of sync - it does not contain all equality information for its terms that \node{p} has.
In figure \ref{ec_graph_example_sequential_3c} \node{n} has performed the synchronization operation and now it has all a merge and now node \node{n} is out of sync - it does not contain all equality information for its terms that \node{p} has.
Note how a cycle was formed that was not in either node before.

\begin{figure}[!htp]
\centering
\begin{subfigure}[t]{\textwidth}
	\framebox[\textwidth]{
	\raisebox{0pt}[0.2\textheight][0pt]
	{
		\begin{tikzpicture}
			\node(O) at (0,0){};
			\node[gttn] (0)  at (2,1)                           {$()$};
			\node[gtn]  (1)  [above left =0.5cm and 0.5cm of 0] {\s{a}};
			\node[gtn]  (3)  [above right=0.5cm and 0.5cm of 0] {\s{b}};
%			\node[gttn] (2)  [above      =0.5cm           of 1] {$\s{(a)}$};
%			\node[gttn] (4)  [above      =0.5cm           of 3] {$\s{(b)}$};

			\node[gl,align=left] (0l) [below = 0cm of 0] {p};
						
			\draw (1) edge[gfa] node[el] {\term{a}} (0);
			\draw (3) edge[gfa] node[el] {\term{b}} (0);
%			\draw (3.225) edge[gfa,out=210,in=120,looseness=2] node[el,anchor=west] {\term{g}} (2.135);

%			\draw (2) edge[sgtt] node[el] {\term{0}} (1);
%			\draw (4) edge[sgtt] node[el] {\term{0}} (3);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
			\node[gttn] (10)  [right      =          5.0cm of  0] {$()$};
			\node[gtn]  (11)  [above left =0.5cm and 0.5cm of 10] {\s{a}};
			\node[gtn]  (13)  [above right=0.5cm and 0.5cm of 10] {\s{b}};
			\node[gttn] (12)  [above      =0.5cm           of 11] {$\s{(a)}$};
%			\node[gttn] (14)  [above      =0.5cm           of 13] {$\s{(b)}$};

			\node[gl,align=left] (10l) [below = 0cm of 10] {n};
						
			\draw (11) edge[gfa] node[el] {\term{a}} (10);
			\draw (13) edge[gfa] node[el] {\term{b}} (10);
			\draw (13.215) edge[gfa,out=215,in=45,looseness=1] node[el,anchor=west] {\term{g}} (12.45);

			\draw (12) edge[sgtt] node[el] {\term{0}} (11);
%			\draw (14) edge[sgtt] node[el] {\term{0}} (13);

		\end{tikzpicture}
	}}
		\caption{before the \lstinline{p.merge} operation}
		\label{ec_graph_example_sequential_3a}
\end{subfigure}

\begin{subfigure}[t]{\textwidth}
	\framebox[\textwidth]{
	\raisebox{0pt}[0.2\textheight][0pt]
	{
		\begin{tikzpicture}
			\node(O) at (0,0){};
			\node[gttn] (0)  at (2,1)                           {$()$};
			\node[gtn]  (1)  [above left =0.5cm and 0.5cm of 0] {\s{a}};
			\node[gtn]  (3)  [above right=0.5cm and 0.5cm of 0] {\s{b}};
%			\node[gttn] (2)  [above      =0.5cm           of 1] {$\s{(a)}$};
			\node[gttn] (4)  [above      =0.5cm           of 3] {$\s{(b)}$};

			\node[gl,align=left] (0l) [below = 0cm of 0] {p};
						
			\draw (1) edge[gfa] node[el] {\term{a}} (0);
			\draw (3) edge[gfa] node[el] {\term{b}} (0);
			\draw (1.325) edge[gfa,out=325,in=135,looseness=2] node[el,anchor=west] {\term{f}} (4.135);

%			\draw (2) edge[sgtt] node[el] {\term{0}} (1);
			\draw (4) edge[sgtt] node[el] {\term{0}} (3);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
			\node[gttn] (10)  [right      =          5.0cm of  0] {$()$};
			\node[gtn]  (11)  [above left =0.5cm and 0.5cm of 10] {\s{a}};
			\node[gtn]  (13)  [above right=0.5cm and 0.5cm of 10] {\s{b}};
			\node[gttn] (12)  [above      =0.5cm           of 11] {$\s{(a)}$};
%			\node[gttn] (14)  [above      =0.5cm           of 13] {$\s{(b)}$};

			\node[gl,align=left] (10l) [below = 0cm of 10] {n};
						
			\draw (11) edge[gfa] node[el] {\term{a}} (10);
			\draw (13) edge[gfa] node[el] {\term{b}} (10);
			\draw (13.215) edge[gfa,out=215,in=45,looseness=1] node[el,anchor=west] {\term{g}} (12.45);

			\draw (12) edge[sgtt] node[el] {\term{0}} (11);
%			\draw (14) edge[sgtt] node[el] {\term{0}} (13);

		\end{tikzpicture}
	}}
		\caption{after the operations \lstinline{p.makeTuple((b)),p.makeTerm(f(b)),p.merge(a,f(b))}}
		\label{ec_graph_example_sequential_3b}
\end{subfigure}

\begin{subfigure}[t]{\textwidth}
	\framebox[\textwidth]{
	\raisebox{0pt}[0.2\textheight][0pt]
	{
		\begin{tikzpicture}
			\node(O) at (0,0){};
			\node[gttn] (0)  at (2,1)                           {$()$};
			\node[gtn]  (1)  [above left =0.5cm and 0.5cm of 0] {\s{a}};
			\node[gtn]  (3)  [above right=0.5cm and 0.5cm of 0] {\s{b}};
%			\node[gttn] (2)  [above      =0.5cm           of 1] {$\s{(a)}$};
			\node[gttn] (4)  [above      =0.5cm           of 3] {$\s{(b)}$};

			\node[gl,align=left] (0l) [below = 0cm of 0] {p};
						
			\draw (1) edge[gfa] node[el] {\term{a}} (0);
			\draw (3) edge[gfa] node[el] {\term{b}} (0);
			\draw (1.325) edge[gfa,out=325,in=135,looseness=2] node[el,anchor=west] {\term{f}} (4.135);

%			\draw (2) edge[sgtt] node[el] {\term{0}} (1);
			\draw (4) edge[sgtt] node[el] {\term{0}} (3);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
			\node[gttn] (10)  [right      =          5.0cm of  0] {$()$};
			\node[gtn]  (11)  [above left =0.5cm and 0.5cm of 10] {\s{a}};
			\node[gtn]  (13)  [above right=0.5cm and 0.5cm of 10] {\s{b}};
			\node[gttn] (12)  [above      =0.5cm           of 11] {$\s{(a)}$};
			\node[gttn] (14)  [above      =0.5cm           of 13] {$\s{(b)}$};

			\node[gl,align=left] (10l) [below = 0cm of 10] {n};
						
			\draw (11) edge[gfa] node[el] {\term{a}} (10);
			\draw (13) edge[gfa] node[el] {\term{b}} (10);
			\draw (11.325) edge[gfa,out=325,in=135,looseness=1] node[el,anchor=west] {\term{f}} (14.135);
			\draw (13.215) edge[gfa,out=215,in= 45,looseness=1] node[el,anchor=east] {\term{g}} (12.45);

			\draw (12) edge[sgtt] node[el] {\term{0}} (11);
			\draw (14) edge[sgtt] node[el] {\term{0}} (13);

		\end{tikzpicture}
	}}
		\caption{after the \lstinline{n.synchronize} operation}
		\label{ec_graph_example_sequential_3c}
\end{subfigure}

\caption{Sequential \lstinline{synchronize}}
\label{ec_graph_example_sequential_3}
\end{figure}

The \lstinline{makeTuple} operation cannot create any more term and tuples than the one tuple that is created (if it does not already exist).
However, it can modify the caches of several predecessors.


\subsection{Join Nodes}
For binary join nodes the
\newpage
\subsection{Formal Operations}
\begin{itemize}
	\item \lstinline{makeTerm(f : $\Fn{n}$,gtt : $\GTTECs{n}$)} : \GTEC \\
	Create the \GTEC \term{f(gtt)} from the existing \term{gtt} in \GTTECs{n} and add it to \GTECs{n}.
	We define $\term{gfa} = \s{f(tt) \mid tt \in gtt}$ and then the result represents the minimal equivalence class that includes all of \term{gfa} and respects all the equalities in \ECs{n} (and in \node{n}'s predecessors).
	If such \GTEC exists in the prestate then nothing is modified.
	If such a \GTEC does not exist in the prestate, the result equivalence class may include more than just \term{gfa} - if this is implied by the some equalities at predecessors of \node{n}, which may imply the creation of more terms and tuples.
	Regardless of the arguments, no new equality information is added to existing terms in \gts{n} and globally no new equality information is added to any existing term in any node.
	Note that by construction, for any \GTEC \term{t} in \GTECs{n},
	$\s{f(tt) \mid tt \in gtt} \subseteq \term{t} \lor \s{f(tt) \mid tt \in gtt} \cap \term{t} = \emptyset$
	%\requires \inSync{\predst{n}} \\
	%\requires $\term{f} \in \scope{n}$ \\
	%\requires $\term{gtt} \in \terms{n}$ \\
	%\ensures  $\term{f(gtt)} \in \termsp{n}$ \\
	%\ensures  $\forall m \cdot \inSync{m} \Rightarrow \inSyncp{m}$
	
	\item \lstinline{makeTuple(gts : $\GTTECs{n}*$} : \GTTEC \\
	Create the tuple EC \term{gts} from existing ground term ECs. \\
	As before, if this \GTTEC exists it is simply returned, otherwise it is created. No new information is added for existing terms or tuples locally or globally (although some caches are modified - described later).
	\s{tt \in \Ts{n}^n \mid \forall i \cdot tt[i] \in gts[i]}
	%\requires \inSync{\predst{n}} \\
	%\requires $\dom{\term{gts}} \subseteq \terms{n}$ \\
	%\ensures  $\term{gts} \in \termsp{n}$ \\
	%\ensures  $\forall m \cdot \inSync{m} \Rightarrow \inSyncp{m}$

	\item \lstinline{merge(gt1,gt2 : \GTEC)} : \GTEC \\
	Merge the \GTEC \term{gt1} and \term{gt2}, and perform congruence closure.\\
	This operation adds equality information and, depending on the current state, may cause the creation of new \GTECs and so extend \gts{n}.
	In the poststate \ECs{n}' we get the minimal set of equalities that are implied by the prestate \ECs{n} and \term{gt1=gt2} (and the prestates of all transitive predecessors of \node{n}). No new equality information is added to any predecessor.
	The new equality information might be relevant to some successors, and these will have to synchronize (see below) before they can perform any other operation.
	%\requires \inSync{\predst{n}} \\
	%\requires $\term{t1,t2} \in \terms{n}$ \\
	%\ensures  $\term{t1=t2} \in \Eqsp{n}$ \\
	%\ensures  $\forall m \notin \succsto{n} \cdot \inSync{m} \Rightarrow \inSyncp{m}$

	\item \lstinline{synchronize()} \\
		Synchronize the node \node{n} with information not yet propagated from predecessors.\\
		In the poststate each of \GTECs{n} have all the members implied by the transitive predecessors.
%	\requires \inSync{\predsto{n}} \\
%	\ensures  \inSync{\predst{n}} \\
%	\ensures  $\forall m \notin \succsto{n} \cdot \inSync{m} \Rightarrow \inSyncp{m}$
\end{itemize}

In addition, all operations satisfy the following monotonicity requirements:\\
\begin{tabular}{ll}
No terms deleted:        & $\forall \node{m} \cdot \terms{m} \subseteq \termsp{m}$ \\
No equalities forgotten: & $\forall \node{m} \cdot \Eqs{m}   \subseteq \Eqsp{m}$ \\
\end{tabular}

In addition, for all nodes at all times, \terms{n} is always subterm-closed (and subtuple-closed)
 and \Eqs{n} is congruence closed for \terms{n}.

It is based on the following algorithmic choices:
\begin{itemize}
	\item Each node maintains a set of \emph{relevant terms} (subterm closed), for which it maintains full congruence information (up to scope and radius/size limitations) - including inequalities
	\item When a term becomes relevant in a node, the node would \emph{query} its predecessors (recursively) to get all known (in)equality information in its transitive predecessors - this might, in turn, \emph{enable derivations} in some transitive predecessors. The result is that each node on each path between the node where the (in)equality was established and where the (in)equality is used will cache the (in)equality
	\item In order to speed up propagation, each node maintains, for each relevant term, the set of \emph{corresponding terms} in its predecessors and the set of \emph{failed successor queries} that found no new information - so that transitive queries can often be avoided
	\item When a node discovers a new (in)equality as a result of a derivation (e.g. resolution), it does not update its successors immediately, rather, before a node can perform any operation it must synchronize with its (transitive) predecessors - hence many such updates can be bunched up in one operation
\end{itemize}


Our data structure represents terms as equivalence classes, rather than the widely used union-find data structure - the reason is that we do not need to be able to backtrack (monotone), and that it simplifies the propagation, sharing and caching of information.

Another divergence from the standard structure is that our equivalence class graph is heterogeneous - it contains nodes both for term equivalence classes and for term-tuple equivalence classes. The reason is that this simplifies the communication between nodes and the caching of queries.

We have actually gone a step further, and represent also atoms, literals and clauses as equivalence classes - this has the benefit of much faster unification and easier caching and communication between nodes, but at the prices of more expensive updates when a new equality is discovered - hence we try to collect several new ground equalities before updating the data structure to account for all those equalities in one step.

Formally, a k-\emph{tuple-node} $\term{ttn} \in \mathbf{tts}(G)$ in the graph has $\|\mathrm{ttn}\|=\arity{ttn}=k$ ordered outgoing edges to $k$ \emph{term-nodes}, represented by \term{tt[0]}..\term{tt[k-1]}.
A \emph{term-node} $\term{tn}\in \mathbf{ts}(G)$ has one or more outgoing \emph{function-application} edges each targeted at a tuple-node and labeled with a function symbol with matching arity.
We represent these edges as $\mathbf{fas}(\term{tn}) \subseteq \mathbf{ts} \times \mathbf{F} \times \mathbf{tts}$, with the label as $\fnc{fa}$ and the source,target as $\src{fa}$, $\trg{fa}$, respectively. The set of all function-application-edges of $\mathrm{G}$ is $\fas{G}$.

For a tuple-node \term{ttn} we denote by $\incoming{n}{ttn}$ the set of edges targeted at it: $\incoming{n}{ttn} = \{\mathrm{fa} \in \fas{G(n)} \mid \trg{fa}=\term{ttn} \}$.

We define a \emph{term-path} in the graph $\mathrm{G}$, that represents one member of an equivalence class, as a tree where each node \term{t} in the tree is labeled with a function-application edge $\mathrm{fa}(\term{t})=\term{e}$, and each such node has $\mathrm{n_t}=\arity{\func{e}}$ ordered edges \term{t_0..t_{n_t-1}} where, for $i \in 0..n_t-1$, $\trg{e}[i]=\src{\mathrm{fa}(\mathrm{target}(\mathrm{t_i}))}$ - that is, each node label represents a choice of one of the function application edges of the corresponding equivalence class, and each edge connects to the corresponding term-node for the tuple of that function application. All leaves are nodes where $\trg{\term{e}}=()$ - the empty tuple.
The term that is represented by such a tree can be defined recursively: each leaf node \node{t} represents the constant $\mathbf{term}(\mathrm{t})=\fnc{\mathrm{fa}(\term{t})}$ and each non-leaf node \node{t} represents the term $\mathbf{term}(\mathrm{t})=\fnc{\mathrm{fa}(\term{t})}(\mathbf{term}(\mathbf{target}(t_0))...\mathbf{term}(\mathbf{target}(t_{t_n-1})))$.

We designate all term paths of the graph $\mathrm{G}$ as $\mathrm{tps(G)}$.

For each term-node \term{t} in the equivalence class graph $\mathrm{G}$ we denote by $\mathbf{terms}(\term{tn})$ the set of terms it represents - $\mathbf{terms}(\term{tn})=\{ \mathbf{term}(\mathrm{T}) \mid \mathrm{T} \in \mathrm{tps(G)} \land \src{\mathrm{fa(root(T))}}=\term{tn}$.\\
Accordingly we define, for a tuple-node \term{ttn},\\
 $\mathbf{tuples}(\term{ttn})=\{ \mathrm{tt} \in \mathbf{T(\Sigma)}^{\|\term{tt}\|} \mid \forall \mathrm{i} \in 0..\|\term{tt}\|-1 \mid \mathrm{tt}[\mathrm{i}] \in \mathbf{terms}(\mathrm{ttn}[\mathrm{i}]) \}$.


We maintain several invariants on the above equivalence class graph $\mathrm{G}$:
\begin{itemize}
	\item The only leaf of the graph is the empty tuple $\mathbf{()}$
	\item Each term-node in the graph represents one or more terms, and hence has at least one term-path
	\item The graph is fully congruence closed: $\forall \mathrm{e_1,e_2} \in \mathrm{fas(G)} \mid ((\fnc{e_1}=\fnc{e_2} \land \trg{e_1}=\trg{e_2} ) \Rightarrow e_1=e_2)$ (each tuple has at most one incoming edge for each function symbol)
	\item Each tuple is represented by exactly one tuple-node: $\forall \mathrm{ttn_1,ttn_2} \in \mathrm{tts(G)} \mid ((\|\term{ttn_1}\|=\|\term{ttn_2}\| \land (\forall \mathrm{i} \in 0..\|\term{ttn_1}\|-1 \mid \term{ttn_1}[\mathrm{i}]=\term{ttn_2}[\mathrm{i}])) \Rightarrow \term{ttn_1}=\term{ttn_2})$
\end{itemize}

This implies that the set of terms (resp. tuples) represented by each pair of term-nodes (resp. tuple-nodes) of $\mathrm{G}$ is disjoint.

We also maintain some invariants between the equivalence class graph $\mathrm{G(n)}$ of node \node{n} and that of its predecessors. These invariants require some extra state - namely the cache for equality queries:\\
For a node \node{n}, for each tuple-node $\term{ttn} \in \tts{G(n)}$, we maintain a set of function symbols $\rfs{n}{ttn}$ (rejected function applications) of the correct arity (applicable to the tuples represented by the equivalence class).
This allows us to encode three mutually exclusive possible options for each such function \term{f} and tuple-equivalence-class \term{ttn}:
\begin{itemize}
	\item There is a known term-equivalence-class for this function application -
	$\mathrm{f} \in \incoming{n}{ttn}$
	\item There is no known term-equivalence-class for the function application in \node{n} or any of its transitive predecessors - $\mathrm{f} \in \rfs{n}{ttn}$
	\item It is unknown whether this function application has any term-equivalence class in \node{n}'s transitive predecessors - $\mathrm{f} \notin \rfs{n}{ttn} \cup \incoming{n}{ttn}$
\end{itemize}

We will later refine this definition to account for term-radius and scope.

The invariants that hold between nodes are:
\begin{itemize}
	\item Each node \node{n} has all the equivalence information from its predecessors for each term in its graph:
	$\forall \term{t} \in \terms{G(n)} \mid [\term{t}]_{\node{n}} \supseteq \cap_{\node{p} \in \preds{n}} [\term{t}]_{\node{p}} $
\end{itemize}

In general, for a node \node{n}, the knowledge about the equality relation between two terms $\term{t},\term{t'} \in \sScope{n}$ has several options:
\begin{itemize}
	\item $\term{t},\term{t'} \in \terms{n}$ and $[\term{t}]_{\node{n}}=[\term{t'}]_{\node{n}}$ and not $\term{t} \neq_{\node{n}} \term{t'}$- the terms are known to be equal at \node{n}
	\item $\term{t},\term{t'} \in \terms{n}$ and $[\term{t}]_{\node{n}} \neq [\term{t'}]_{\node{n}}$ and not $\term{t} \neq_{\node{n}} \term{t'}$ - the terms are not known to be equal or unequal at \node{n} and at any transitive predecessor cut of \node{n}
	\item $\term{t},\term{t'} \in \terms{n}$ and $[\term{t}]_{\node{n}} \neq [\term{t'}]_{\node{n}}$ and $\term{t} \neq_{\node{n}} \term{t'}$ - the terms are known to be unequal at \node{n}
	\item $\term{t},\term{t'} \in \terms{n}$ and $[\term{t}]_{\node{n}} = [\term{t'}]_{\node{n}}$ and $\term{t} \neq_{\node{n}} \term{t'}$ - the terms are known to be equal and unequal at \node{n} - the node is infeasible
	\item $\term{t} \in \terms{n}$, $\term{t'} \notin \terms{n}$ - the terms are not known to be equal at \node{n} or any transitive predecessor cut, but may be known to be unequal at some such cut
	\item $\term{t},\term{t'} \notin \terms{n}$ - it is not known at \node{n} whether the terms are equal or not, but it may be known in some transitive predecessor cut
\end{itemize}

We will first discuss the propagation of (in)equality information among nodes.
We will present several refinements of a system for the propagation of \\
(in)equality information along the CFG.

We refer first to propagating unit (in)equalities , that could come either directly from the encoding of the original program, or could be derived using e.g. resolution  - a unit (in)equality can, in turn, allow the derivation of new clauses which could derive new
(in)equalities and so on - in this section we only handle derivations within the fragment of unit
(in)equalities .

We denote by \relevantTerms{n} the set of terms that are deemed potentially relevant at node \node{n} at a given time during verification, this includes terms that are relevant only because of transitive successors of \node{n} - the exact definition of relevancy will be given later.
We denote by \terms{n} the set of terms \emph{represented} at a given time at node \node{n} - this would always a superset of (or equal to) \relevantTerms{n}.

For a term \term{t} represented at node \node{n}, we denote by $[\term{t}]_{\node{n}} \subseteq \terms{n}$ the currently \emph{known} equivalence class of \term{t} at node \node{n} and for another term $\term{t'} \in \terms{n}$ we denote by $\term{t} =_{\node{n}} \term{t'}$, $\term{t} \neq_{\node{n}} \term{t'}$ that at \node{n} it is known that \term{t} is equal, not equal to \term{t'}.

A transitive predecessor cut of a node \node{n} is a cut in the CFG between the \node{root} and \node{n} - a clause that holds in such a cut also holds at \node{n} - this is somewhat of a generalization of the notion of a dominator of \node{n}, which would preclude the case where, e.g. an assertion does not hold in any dominator of \node{n} but holds in two direct predecessors of \node{n} joined at \node{n}.

We use the following definitions to describe the stage of deriving an
(in) equality (or any other clause) at a given node:
\begin{itemize}
	\item A clause \clause{C} \emph{holds at} node \node{n} if $\postcond{n} \vDash \clause{C}$
	\item A clause \clause{C} is \emph{known at} node \node{n} if $\exists \clause{D} \in \clauses{n} \mid \clause{D} \subseteq \clause{C}$
	\item A clause \clause{C} is \emph{derived for} node \node{n} if there is a cut $\mathrm{T}$ in the CFG dominating \node {n}, such that $\forall \node{p} \in \mathrm{T} \mid \clause{C} \in \clauses{p}$ (this definition would need some refinement to account for scoping etc) - this basically means that only propagation is needed for \clause{C} to be known at \node{n}
	\item A clause \clause{C} is \emph{propagated for} node \node{n} if $\clauses{n} \vdash \clause{C}$ but $\clause{C} \notin \clauses{n}$ - that is, sufficient information has been propagated to \node{n} in order to derive \clause{C} in our calculus, but it has not yet been derived
\end{itemize}

\newpage

\noindent
Example 3:
\begin{lstlisting}[caption=congruence closure eager interpolant arity,label=snippet3.29]
$p_i$:
assume P($a_0$,$a_6$,...,$a_{6n}$)=T
....

$p_b$:
if (*)
	$p_t$:
	assume $a_0$=$a_2$
	assume $a_2$=$a_4$
	...
	assume $a_{6m-2}$=$a_{6m}$
	$p_{ta}$:
		assert P($a_0$,$a_0$,...,$a_0$)=T
else
	$p_e$:
	assume $a_0$=$a_3$
	assume $a_3$=$a_6$
	...
	assume $a_{6m-3}$=$a_{6m}$
	$p_{ea}$:
		assert P($a_0$,$a_0$,...,$a_0$)=T
\end{lstlisting}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Related Work}
We shall first look briefly at existing techniques:\\
\textbf{IC3/PDR} based techniques, as for example in ~\cite{BjornerGurfinkelKorovinLahav2013}, would try to refute or find a model at the assertion using DPLL - e.g. at \node{p_{ja}}, if refuted we are done, otherwise we have a model (counter example) - in our example that could be \s{} (that is, the model is the Herbrand model with the equivalence relation generated by the empty set of equalities - ground terms are equal iff they are identical).
For the counter example we find a pre-image of the transition relation in the predecessor node - here this is the identity - so now \node{p_j} would try to refute this model - as there is no extra information at \node{p_j} this would fail and we remain with the same counterexample. 
Now \node{p_j} sends this model (again, through the identity transition relation), to both \node{p_t} and \node{p_e}.
Now \node{p_e} finds a contradiction - as in the model \m{f(a) \neq f(b)} - and so it has to return a clause that shows the contradiction - here there is one minimal option, the clause \m{f(a) = f(b)}.
\node{p_t} also has to return a clause that is sufficient to show that this model is invalid, and the minimal such clause is \m{a=b}.
\node{p_j} would need to join these clauses - plausibly giving \m{f(a)=f(b)}, which would be propagated to \node{p_{ja}} and the program would be verified as \node{p_{ja}} would have no models anymore.

This method is used mostly for finding invariants automatically, initially for propositional programs (e.g. ~\cite{Bradley12}), but also extended to EPR (~\cite{BjornerGurfinkelKorovinLahav2013}, linear arithmetic (e.g. ~\cite{BjornerGurfinkel2015} - combined with interpolation and polyhedra abstract interpretation) and others.

This approach is, however, less suitable for our goals, for the following reasons:
\begin{itemize}
	\item A basic step of PDR is calling an SAT/SMT solver (or any solver that can return a counter-example) in order to check whether a given model is feasible, and generating a clause from the unsatisfiable core if it is not. 
	While often efficient in practice, this approach suffers from the same problem that drove us originally to search for an alternative to using an SMT solver - even for propositional programs the worst case runtime of each such step is exponential (although commonly the prover calls for PDR are much smaller than those for the whole program VC). When quantifiers are involved, the runtime is unbounded and highly unpredictable with current SMT solvers. 
	A partial result (time-out) does not give us much information (although the prover log could potentially be mined for some learned clauses) - so again, even if the run-time is predictable, the actual set of programs that this method can verify is highly unpredictable.
	\item While representing propositional models is efficient, the representation of general FOL models is not obvious - some theories admit only infinite models. 
	An interesting possibility would be to exploit the  model evolution calculus with equality (~\cite{BaumgartnerPelzerTinelli12}), that extends DPLL to FOLE and so has a representation for intermediate models in general FOL with equality - we have not explored this possibility as it also suffers from the other problems.
	\item In PDR, if a model is found all the way from an assertion node to the root node then the program failed to verify and we have a counterexample trace. Our aim is to have a gradual verifier that applies gradually stronger (and costlier) tools in an attempt to verify the program - if we have failed to verify because we have found a counter-example, we do not know where stronger tools need to be applied - it could be that one quantifier instantiation at the assertion node would suffice, or it could be at any node on the CEX-path or a combination of several nodes. 
	PDR guarantees progress and eventual termination by ensuring that, at each step, either a counter example is propagated towards the root or a clause blocking some existing counter-example is propagated towards the assertion. If we want to ensure progress while gradually strengthening the logic fragment in which we work, we would need to remember many counter-examples, which would affect the space complexity of even the propositional stage (remember, we want to prove, for each fragment, all assertion that are provable in that fragment).
	\item When a cube (state) is not infeasible at node in propositional PDR, and the transition relation is many-to-one, the cube could have exponentially many sources in the node's predecessor. 
	In the worst case, when lemma generation/generalization fails (or more advanced methods e.g. interpolation as in ~\cite{VizelGurfinkel2014}), we may need to refute exponentially many predecessor cubes in the predecessor order to refute the cube at the node. 
\end{itemize}

Another existing technique is based on modular sat solving (~\cite{BaylessValBallHoosHu2013}) - here (in our terminology) each node gets its own SAT solver, each assertion leaf node searches for a model, which is then communicated to its predecessor (in the paper it is described for a sequence, rather than tree or DAG, CFG), each SAT solver is incremental and can receive new assignments from successors and new lemmas (learned clauses) from predecessors.
This approach is appealing as it is local and potentially each solver could face a much smaller problem than that of a whole VCG solver.
It would be interesting to see how this approach fares when extended to SMT and DAGs (in the paper it is described as a method to implement IC3, so in fact loops are supported, but acyclic sub-CFG are converted to one SAT instance - there is no provision for joins).
However, it faces some of the problems mentioned for IC3 above - each SAT instance could potentially run for exponential time, and a model has to be completely refuted (with an explaining lemma/interpolant) in order to continue verification.

A third existing technique is based on interpolation, again usually focused on invariant finding rather than proof search.

\begin{lstlisting}[caption=congruence closure propagation DSA,label=snippet3.6.1]
$p_i$:
assume $\term{P(a_0,a_1,...,a_n)=T}$
....

$p_b$:
if (*)
	$p_t$:
	assume $\term{a_0=a_1}$
	assume $\term{a_1=a_2}$
	...
	assume $\term{a_{m-1}=a_{m}}$
	$p_{ta}$:
		assert $\term{P(a_0,a_0,...,a_0)=T}$
\end{lstlisting}
\noindent

It is interesting to understand how this problem manifests itself in the case of running the full program VC in an SMT solver, superposition prover or IC3 style solver:
\begin{itemize}
	\item An SMT solver would evaluate the term \term{P(a_0,a_0,...,a_0)} only in the context of $p_{ta}$, where it holds that
	$\term{[P(a_0,a_0,...,a_0)]_{p_{ta}}}=\term{[P(a_0,a_1,...,a_n)]_{p_{ta}}}$ and so the problem is avoided, however, if there is more than one CFG path that reaches $p_{ta}$, and if some of the equalities on the way are not given but rather need to be derived, this derivation could be duplicated.
	\item A superposition based prover would rewrite $\term{P(a_0,a_1,...,a_n)}$ to \\ $\term{P(a_0,a_0,...,a_0)}$ in the relevant clause in a polynomial (in \term{n}) number of steps (assuming \term{a_0<a_1<...<a_n}), and so in essence would "skip" most of the potential tuples that we handle, without losing completeness (in any term-order both terms would be rewritten to the same normal form in at most a polynomial number of steps).
	
	We have experimented with a system that rewrites to normal form, rather than maintaining equivalence classes, as detailed in chapter x.
	This works in several cases as a lightweight analysis, but it has a fundamental problem with joins - constructing a convergent rewrite system from the join of two such systems seems more complicated than handling ECs, especially as we need to be able to add a (Derived) unit ground equality to any node at an arbitrary time. In the example above, the normal form for \term{a_0} at $p_t$ is arbitrary - it could be any of \term{a_0...a_m} (or \term{a_0...a_n} if we use scoping to direct it), but we have not found an obvious way to use the rewrite system in order to avoid the exponential explosion above.
		
	\item An IC3/PDR style engine - assuming our variables are e.g. bitvectors and that the equalities at $p_t$ form the transition relation, would essentially try to block either the cube \\
	\clause{P(a_0,a_0,...,a_0) = T \land a_0 = a_1 \land ... \land a_{m-1} = a_m} or the cube \\
	\clause{P(a_0,a_0,...,a_0) = T \land P(a_0,a_0,...,a_1) = T \land ... \land P(a_n,a_n,...,a_n) = T} \\
	or some cube in between, under \term{P(a_0,a_1,...,a_n)=T} :\\
	in the first case it would not encounter the exponential explosion - essentially it imports the whole problem from $p_{ta}$ to the context of $p_i$ and tries to solve it there - that mostly means that the effort in solving the problem would not be shareable with any query from e.g. the else branch, unless it is very similar (the blocked cube is pushed forward), in the second case it encounters the same exponential problem, but results may be more shareable.
\end{itemize}

Here the query by $p_t$ for the equivalence classes of \\
$\term{P(\s{a_1,a_3,..a_{6m}},...,\s{a_1,a_3,..a_{6m}})}$ would entail $(3m)^n$ queries. \\
Effective caching at $p_b$, except by enumeration, is still unclear as it should block all queries from $p_e$ except for those instances that are not shared with $p_t$ (tuples over $a_{3+6i}$).

Here the query from $p_t$ (and $p_e$) would have to be infinite in order to be complete, and their shared query is also infinite.

%\subsubsection{disagreement sets}

%We will show that \m{\size{dai_u^{max}(s,t)} \leq 1}.\\
%
%\noindent
%We will show now how to calculate \m{dai_u^{max}} and its uniqueness:\\
%\begin{lstlisting}
%$\m{dai^{max}_u(\fa{f}{s},\fa{g}{t})}$
	%if ($\m{\fa{f}{s}\equiv\fa{g}{t}} \lor \m{f \not\equiv g \lor \size{s} = 0}$)
		%return $\emptyset$
	%for (i:=0 to $\m{\size{s}-1}$)
		%if ($\m{s_i \not\equiv t_i}$)
			%return $\m{dai_2(s_i \neq t_i,i+1,\tup{s},\tup{t})}$
	%return $\emptyset$
%
%$\m{dai_2(u \neq v,i,\tup{s},\tup{t})}$
	%if ($\m{i\geq\size{\tup{s}}}$)
		%return $\m{u \neq v}$
	%while (true)
		%if ($\m{\forall j>i \cdot dai_3(u \neq v,s_j,t_j)}$)
			%return $\m{u \neq v}$
		%S = $\m{dai^{max}_u(u,v)}$
		%if (S = $\m{u' \neq v'}$)
			%u:=$\m{u'}$
			%v:=$\m{v'}$
		%else
			%return $\emptyset$
	%
%$\m{dai_3(u \neq v,\fa{f}{s},\fa{g}{t})}$
	%if ($\m{\fa{f}{s} \equiv \fa{g}{t}}$)
		%return true
	%if ($\m{u \neq v \equiv \fa{f}{s} \neq \fa{g}{t}}$)
		%return true
	%if ($\m{f \not\equiv g}$)
		%return false
	%for (i in 0..$\size{\tup{s}}$)
		%if ($\m{\s{u,v} \not\subseteq subterms{\s{s_i,t_i}}}$ or $\m{ \lnot dai_3(u \neq v,s_i,t_i)}$)
			%return false
	%return true
%\end{lstlisting}
%
%\begin{theorem}
%Assuming \m{\fa{f}{s}\not\equiv\fa{g}{t}},
%if there is a maximal unit disagreement set for \m{\fa{f}{s}\neq\fa{g}{t}} then it is unique and 
%the procedure \m{dai^{max}_u(\fa{f}{s},\fa{g}{t})} above returns \m{u \neq v}.\\
%Otherwise the procedure returns $\emptyset$.
%
%\noindent
%\textbf{Proof}\\
%We know that \m{\fa{f}{s}\not\equiv\fa{g}{t}}, hence either \m{f\not\equiv g} or \m{\tup{s}\not\equiv\tup{t}}.\\
%If \m{f\not\equiv g} then for any \m{u,v \in \mathbf{neqs}(\subterms{\s{s,t}})}, \m{u=v,\fa{f}{s}\neq\fa{g}{t} \not\models \emptyClause} because:\\
%Given a derivation of \m{u=v \vdash_{\mathbf{CC_G}} \fa{f}{s}=\fa{g}{t}}, we look at the derivation tree.\\
%As there are no inequalities, non can be generated, so we ignore the rules \m{dai,res,tra_{\neq}}.\\
%We assume w.l.o.g that \m{u} is at least as deep as \m{v}.\\
%If \m{v\equiv u} then only tautologies can be derived.\\
%If \m{v} is not a strict sub-term of \m{u}, then we claim that for any \m{x=y} derivable from \m{u=v} s.t. \m{x=y \not\equiv u=v}, \m{x \not\equiv y}, it holds that both \m{x,y} have at least one strict sub-term that is either of \m{u,v}, and the leading function symbols of \m{x,y} are the same.\\
%Proof by induction on the derivation tree of \m{x=y}:\\
%At the leaves we have either a tautology \m{t=t} or \m{u=v}.\\
%For \m{ref_G} we only get tautologies.\\
%For \m{con_G} if all the premises are tautologies then we get a tautology, otherwise the leading function symbol is the same and each premise can be either \m{u=v} or some \m{x'=y'} for which i.h. holds, so we know that both sides of the conclusion have at least one of \m{u,v} as a strict sub-term.\\
%For \m{tra}, if one side is a tautology then the other premise is the conclusion, otherwise:\\
%If both premises are both not \m{u=v} then both premises have the same leading function symbol and both have at least one strict sub-term from \s{u,v} by i.h. .\\
%If both premises are \m{u=v} then the conclusion is a tautology.\\
%If one premise is \m{u=v} and the other is \m{w=z} then w.l.o.g \m{z\equiv u} but \m{z} must have a sub-term from \m{u,v} which cannot be as \m{v} is not a sub-term of \m{u}.\\
%This shows that \m{\fa{f}{s}=\fa{g}{t}} cannot be derived from \m{u=v}.\\
%If \m{v} is a strict sub-term of \m{u}, then for any derived non tautological \m{x=y} s.t. \m{x} is at least as deep as \m{y}, it holds that:\\
%Either \m{y\equiv v} and \m{v} is a strict sub-term of \m{x} and the leading function symbol of \m{x} is that of \m{u} \\
%or both \m{x,y} have \m{v} as a strict sub-term and the same leading function symbol.\\
%Again by induction on the derivation tree:\\
%At the leaves we have either a tautology \m{t=t} or \m{u=v}.\\
%For \m{ref_G} we only get tautologies.\\
%For \m{con_G} if all the premises are tautologies then we get a tautology, otherwise the leading function symbol is the same and each premise can be either \m{u=v} or some \m{x'=y'} for which i.h. holds, so we know that both sides of the conclusion have at least one of \m{u,v} as a strict sub-term and hence both have \m{v} as a strict sub-term.\\
%For \m{tra}, if one side is a tautology then the other premise is the conclusion, otherwise:\\
%If the premises are both not \m{u=v} then both premises have the same leading function symbol and both have at least one strict sub-term from \s{u,v} by i.h. .\\
%If both premises are \m{u=v} then the conclusion is a tautology.\\
%If one premise is \m{u=v} and the other is \m{w=z} then either:\\
%\m{z\equiv u} and \m{w} has the same leading function symbol as \m{u} by i.h., in which case the conclusion \m{w=v} satisfies the condition.\\
%Or \m{z\equiv v} and then \m{w} must have the same leading function symbol as \m{z} by i.h. and hence the same as \m{u}, and in the conclusion \m{u=w} both must have \m{v} as a sub-term.\\
%Now, if \m{\fa{f}{s}=\fa{g}{t}} was derived from \m{u=v} where \m{v} is a strict sub-term of \m{u}, 
%it would mean by the lemma that \m{v \equiv \fa{g}{t}} and \m{f} is the leading function symbol of \m{u}.\\
%But that means that \m{u} must be a strict sub-term of \fa{f}{s}
%
%
%
%By \m{f\not\equiv g} we know that the last derivation must have been \m{tra_{=}}
%By contradiction suppose we have a refutation in $\mathbf{CC_R}$ from \m{\fa{f}{s}\neq\fa{g}{t},\m{u=v}}.\\
%Assume, w.l.o.g that \fa{f}{s} is at least as deep as \fa{g}{t}, hence it is strictly deeper than both \m{u,v} as they are both strict sub-terms.\\
%Now we claim that for any equality \m{x=y} s.t. \m{u=v \vdash_{\mathbf{CC_R}} x=y}, either \fa{f}{s} is strictly deeper than both \m{x,y} or \m{x,y} have the same leading function symbol.\\
%
%
%If \m{u,v} have the the leading function symbols \m{h_u,h_v} respectively, then for any equality \m{x=y} derived by $\mathbf{CC_R}$ from \m{u=v} with the leading function symbols \m{h_x,h_y}, either \m{h_x\equiv h_y} or \m{\s{h_x,h_y}=\s{h_u,h_v}}, by induction on the derivation tree:\\
%There is only one axiom, the leading function symbols are equal in the conclusions of reflexivity and congruence closure, and for transitivity either all leading function symbols in the premises are equal or both are \s{h_u,h_v} in which case in the conclusion it is either \m{h_u} or \m{h_v}, or one side has \s{h_u,h_v} while the other has w.l.o.g \m{h_u} - hence the conclusion has \s{h_u,h_v}.\\
%
%
%and transitivity produces preserves this .\\
%We denote \m{u\equiv\fa{m}{x}} and \m{v\equiv\fa{n}{y}}.\\
%If \m{m\equiv n} then all derivations of equalities produce equalities with the same leading function symbol
%The only rule that can generate \m{\fa{f}{s}=\fa{g}{t}} where \m{f\not\equiv g} is the transitivity rule, and it requires that there is some \fa{h}{w} s.t. we have already derived \m{\fa{f}{s}=\fa{h}{w}} abd \m{\fa{h}{w}=\fa{g}{t}}.\\
%On any path in the 
%
%
%We assume, then,\m{f \equiv g} and \m{\tup{s}\not\equiv\tup{t}} and w.l.o.g \m{i} is the minimal index s.t. \m{s_i\not\equiv t_i}.\\
%Now we claim that \m{u \neq v} is a unit disagreement set of \m{\fa{f}{s}\neq\fa{f}{t}} iff for all j either \m{s_j\equiv t_j} or 
%\m{u \neq v} is a unit disagreement set of \m{s_j \neq t_j}.\\
%
%To prove this lemma, first consider only if direction:\\
%We assume for all j either \m{s_j\equiv t_j} or \m{u \neq v} is a unit disagreement set of \m{s_j \neq t_j}.\\
%By definition that means that for all \m{j} \m{s_j \neq t_j \models u \neq v} which implies \m{u=v \models s_j = t_j}.\\
%But then \m{u=v \models \bigwedge\limits_j s_j=t_j} and hence \m{u=v \models \fa{f}{s}=\fa{f}{t}} so \m{\fa{f}{s}\neq\fa{f}{t} \models u \neq v}.\\
%
%\bigskip
%In the other direction, assume \m{\fa{f}{s}\neq\fa{f}{t} \models u \neq v} but for some \m{j} \m{s_j \neq t_j \not\models u \neq v}.\\
%Now we claim that \m{ u=v \not\vdash_\mathbf{CC_R} \fa{f}{s}=\fa{f}{t}} - \\
%it cannot be derived by \m{ref} because \m{\fa{f}{s}\not\equiv\fa{f}{t}}\\
%It cannot be derived by congruence closure because \m{u=v \not\models s_j=t_j }\\
%In order to derive it by transitivity, we must have derived, w.l.o.g, \m{\fa{f}{s}=w'} and \m{w'=\fa{f}{t}}, 
%we take the minimal derivation (sub-derivation order) in the derivation tree s.t. the conclusion is \m{\fa{f}{s}=w} for some w.\\
%We know \m{w \not\equiv \fa{f}{t}}, and the derivation cannot have been an instance of \m{tra} because that would contradict minimality.\\
%This means that \m{\fa{f}{s}=w} was derived by congruence closure and hence \m{w\equiv\fa{f}{s'}} and \m{u=v \vdash_\mathbf{CC_R} \tup{s} = \tup{s'}}.\\
%A similar argument shows that, for some \tup{t'}, \m{u=v \vdash_\mathbf{CC_R} \tup{t} = \tup{t'}}.\\
%We also know that there is a 
%
%
%The procedure finds such \m{i}
%If the tuples  are equal then \m{dai^{max}_u} returns $\emptyset$, otherwise it finds the lowest \m{i} s.t. \m{s_i \neq t_i} 
%and calls $\m{dai_2}$ to find the maximal inequality in \m{s_i \neq t_i} or any of its unit disagreement sets are a disagreement set of \m{\fa{f}{s} \neq \fa{g}{t}}.\\
%The function \m{dai_2(u \neq v,i,\tup{s},\tup{t})} searches among the unit inequalities derivable from \m{u \neq v} (including \m{u \neq v}) in descending (sub-term) order, that is also derivable from each of \m{s_j \neq t_j} for \m{j>i}.
%The function \m{dai_3(u \neq v,s,t)} return true iff \m{u=v,s \neq t \models \emptyClause}.\\
%This check returns false (that is \s{u=v,s \neq t} is consistent) if \m{u,v} are not subterms of \m{s \neq t} (by the refutational completeness of \m{\mathbf{CC^R}}).\\
%If the \m{s=t} or \m{u=s \land v=t} or \m{u=t \land v=s} then the set is immediately inconsistent.\\
%If both \m{u,v} are strict sub-terms of \m{s,t} and \m{s=\fa{f}{s}, t=\fa{f}{t}} then \m{u=v,\fa{f}{s} \neq \fa{g}{t}} is inconsistent iff \m{\forall i \cdot u=v,s_i\neq t_i \models \emptyClause} by induction on the structure of \m{s,t}:\\
%The base case is as above.\\
%For the induction step, if, for some \m{i}, \m{u=v,s_i \neq t_i} is consistent, then there
%\end{theorem}

%$
%\m{dai^{max}(\fa{f}{s},\fa{g}{t})} = 
	%\begin{cases} 
			%\m{u \neq v}  & \m{f \equiv g \land \size{s}>0 \land \s{u \neq v} = dai_2(0,\tup{s},\tup{t})} \\
			%\emptyset     & \mbox{otherwise}\\
	 %\end{cases}
%$\\
%$ 
%\m{dai_2(i,\tup{s},\tup{t})} = 
	%\begin{cases} 
			%\m{dai_2(i+1,\tup{s},\tup{t})}          & \m{i < \size{s} \land s_i \equiv t_i} \\
			%\m{dai_3(u \neq v,i+1,\tup{s},\tup{t})} & \m{i < \size{s} \land s_i \not\equiv t_i \land dai^{max}(s_i,t_i) = \s{u \neq v}}\\
			%\emptyset                               & \mbox{otherwise}\\
	 %\end{cases}
%$\\
%$ 
%\m{dai3(u \neq v,i,\tup{s},\tup{t})} = 
	%\begin{cases} 
		%\s{u \neq v}                            & \m{i \geq \size{s} \lor dai4(u \neq v,i+1,\tup{s},\tup{t})} \\
		%\m{dai_3(u' \neq v',i,\tup{s},\tup{t})} & \m{i<\size{s} \land \lnot dai4(u \neq v,i+1,\tup{s},\tup{t} \land \s{u' \neq v'} = dai^{max}(u,v)} \\
		%\emptyset                               & \m{otherwise} \\
	 %\end{cases}
%$\\
%$ 
%\m{dai4(u \neq v,i,\tup{s},\tup{t})} = 
	%\begin{cases} 
		%\s{u \neq v}                                       & \m{i \geq \size{s}} \\
		%\s{u \neq v}                                       & \m{i < \size{s} \land u \neq v \equiv s_i \neq t_i \land dai4(u \neq v,i+1,\tup{s},\tup{t})} \\
		%\m{dai5(u \neq v,s_i \neq v_i,i+1,\tup{s},\tup{t})} & \m{i < \size{s} \land u \neq v \not\equiv s_i \neq t_i} \\
		%\emptyset                                          & \m{otherwise} \\
	 %\end{cases}
%$\\
%$ 
%\m{dai5(u \neq v,u' \neq v',i,\tup{s},\tup{t})} = 
	%\begin{cases} 
		%\s{u \neq v}                                  & \m{u \neq v \equiv u' \neq v' \land dai4(u \neq v,i,\tup{s},\tup{t}} \\
		%dai5(u \neq v,u' \neq v',i+1,\tup{s},\tup{t}) & \m{i < \size{s} \land \size{s_i \neq t_i}>\size{u \neq v} \land \s{u' \neq v'} = dai^{max}(s_i,t_i)} \\
		%\emptyset                               & \m{otherwise} \\
	 %\end{cases}
%$\\
%$ 
%\m{dais(i,\tup{s},\tup{t})} = 
	%\begin{cases} 
			%\s{\emptyset}                                                  & \m{i \geq \size{s}}\\
			%\s{\bigcup_i P_i \mid P \in \prod\limits_{j>i} dais_2(s_j,t_j) } & \mbox{otherwise} \\
	 %\end{cases}
%$\\
%$ 
%\m{dais_2(\fa{f}{s},\fa{g}{t})} = 
	%\begin{cases} 
			%\s{\emptyset}                                                                                    & \m{\fa{f}{s} \equiv \fa{g}{t}}\\
			%\s{\fa{f}{s} \neq \fa{g}{t}}                                                                     & \m{f \not\equiv g}\\
			%\s{\fa{f}{s} \neq \fa{g}{t}} \cup \m{\bigcup_i P_i \mid P \in \prod\limits_{i} dais_2(s_i,t_i) } & \mbox{otherwise} \\
	 %\end{cases}
%$

%\subsubsection{Recursive import}
%
%Recursive import traverses the CFG in reverse topological order, from the importing node to the root.\\
%At each branch node, we have to \emph{join the queries} from both sides (which might differ because of the \m{sources} function) - for example:
%
%
%Here, when we import recursively from \node{n_{ja}}, \node{n_t} must query \node{n_1} for \s{f(b),g(b),f(a),g(a)} while 
%\node{n_e} must query for \s{f(b),g(b),f(c),g(c)} - the algorithm collects all the queries as a set of terms,
%and when \node{n_1} answers the combined query each of \node{n_t,n_e} selects the relevant clauses from the answer to import.
%Note that even without combining queries, the total query time is polynomial because the number of possible queries to each node is polynomial (number of terms, and later number of equivalence classes) and the results are cached at all nodes on the path, 
%but we have found the query time as one of the main bottlenecks and so joining queries improves performance significantly.
%
%The implementation basically maintains a queue sorted by reverse topological order to traverse the CFG up (backwards), stopping at the root and at nodes which have already cached a super-set of the query, and then traverse the CFG from these nodes down in topological order, importing clauses and performing simplifications and saturation.
%
%The important property of the simplification fragment is that it cannot introduce new equalities to \m{g} - if simplifying a non-unit-ground clauses produces a unit ground clause, it is kept as clauses in the \lstinline{nextTodo} queue and not \lstinline{assume}d in \m{g} - otherwise the import condition of successor nodes might change and it is very hard to define saturation.
%
%\begin{lstlisting}
%Node.importRecursive(ts:Set<Term>)	
	%dq = new PriorityQueue //reverse topological-order
	%uq = new Queue
	%requestMap = new Map
	%foreach $\m{p \in \preds{this}}$
		%requestMap[p] = ts
		%dq.enqueue(p)
		%
	%while (!dq.isEmpty)
		%n = dq.dequeue
		%nts = $(\bigcup\limits_{\m{t \in requestMap[n]}} \m{EC(t)}) \setminus$ n.importedTerms
		%n.importedTerms = n.importedTerms \cup nts
		%if (nts = $\emptyset$ or $\preds{n}$=$\emptyset$)
			%uq.enqueue(n)
		%else
			%foreach p in $\preds{n}$
				%requestMap[p].add($\m{sources(n,p,nts)) }$)
				%//Unify request from all successors
	%
	%while (!uq.isEmpty)
		%n = uq.dequeue
		%ncs = $\bigcap\limits_{\m{p \in \preds{n}}}$ p.relevantClauses(requestMap[n])
		%n.importedClauses.add(ncs)
		%n.nextTodo.enqueue(ncs $\setminus$ n.done)
		%n.saturate
		%requestMap.remove(n)
		%foreach ($\m{s \in \succs{n}}$)
			%if ($\m{\preds{s} \cap requestMap.keys=\emptyset}$)
				%uq.enqueue(s)
				%
%Node.relevantClauses(ts : Set<Term>)
	%return $\s{c \in done \mid c.maxLiteral.maxTerm \in requestMap[n]})$
		     %$\cup \s{c \in done \mid \exists s,t,p \cdot c.maxLiteral =s \neq t \land l=\termAt{s}{p}}$
%\end{lstlisting}
%
%\lstinline{p.relevantClauses(ts)} chooses clauses from \lstinline{p.done,p.nextTodo} where the maximal term is in \lstinline{ts}, all simplified according to \lstinline{p.g}.\\
%\lstinline{importRecursive} first descends the CFG in reverse topological order, where each node queries its predecessors for all terms it knows as equivalent to terms it was queries about. A node does not query backwards if it has no predecessors or has already imported clauses for all relevant terms. Branch nodes collect the queries from both sides, otherwise we would need a potentially exponential query time for a DAG (e.g. DAG of size 3n+1 with n diamonds in sequence).
%Once done traversing backwards, we traverse forward in topological order, starting from the nodes which created no further queries.
%Each node imports the clauses from predecessors, simplifies them and adds them to the saturation queue.
%Note that the import code (assignment to \lstinline{ncs}) above implements a very limited join, we discuss joins in the next section.
%
%\begin{lstlisting}[caption=propagation sources,label=snippet3.17]
%$\node{n_1}:$
%assume C $\lor$ f(c)=f(a)
%$\node{n_2}:$
%assume d=c
%assume b=a
%$\node{n_3}:$
%assume $\lnot$C
%$\node{n_4}:$
%assert $\m{f(d)=f(b)}$ //negated $\m{f(d) \neq f(b)}$
%\end{lstlisting}
%
%Assuming \m{a,b,c,d} do not occur in \m{C}.\\
%Here \node{n_4} and \node{n_1} have no terms in common.\\
%The graph \m{g_{n_4}}, however, will include nodes for \m{a,c} because of the sub-term transitive closure, so it will include the following equalities \m{d=c,b=a} and nodes for the following equivalence classes \\
%\s{\s{a,b},\s{f(a),f(b)},\s{c,d}, \s{f(c),f(d)}}.\\
%In fact, \m{g_{n_4}}, \m{g_{n_3}}, \m{g_{n_2}} will share all the sub-graph that includes these equivalence classes - so the sources function would map each term to its singleton set - e.g. \m{sources(n_4,n_3,g_{n_4}(a))=\s{g_{n_3}(a)} (=\s{g_{n_4}(a)})}.\\
%For \node{n_1} the situation is different:\\
%The graph \m{g_{n_1}} includes only a singleton set at each node - so\\
%\m{sources(n_2,n_1,g_{n_2}(a)) = \s{g_{n_1}(a),g_{n_1}(b)}}, and\\
%\m{sources(n_2,n_1,g_{n_2}(f(a))) = \s{g_{n_1}(f(a)),g_{n_1}(f(b))}}.
%
%Thus, when \node{n_4} recursively imports the term \m{f(d)}, which means the graph node \s{g_{n_4}(f(d))} that represents the equivalence class \s{f(\s{c,d})}, when the query reaches \node{n_1} it will become \s{g_{n_1}(f(c))} which represents the equivalence class \s{f(c)}.
%
%Only, in fact, with the current machinery this would not work, because \m{f(d),f(b) \notin g_{n_3}} - 
%these terms do not occur in \clauses{n_3} and are not imported by the graph operations because \m{sources(n_4,n_3,g_{n_4}(f(b))=\emptyset}.
%So there is a clause at \node{n_1} that is relevant at \node{n_4} under the currently known equalities, but is not imported because there is a \emph{disconnect} in the \m{sources} chain between 
%\m{g_{n_4}(f(d))} and \m{g_{n_1}(f(c))}, although, there are enough known equalities along the path from \node{n_1} to \node{n_4} to know that these terms are equivalent.
%
%This means that, in order to ensure that all relevant clauses are imported, we need to make sure that there are no disconnects in the \m{sources} chain - especially once we use scoping, in the above example \node{n_4} will not have \m{c} in scope at all, so it cannot get the relevant clause even by directly querying \node{n_1}.
%
%The invariant that needs to be maintained by the sources function, at the end of a \lstinline{saturate} pass, is roughly as follows:\\
%For each CFG path \m{P = p.P_1.q,P_2.n},  (\m{P,P_1,P_2} paths, \m{p,q,n} nodes)\\
%for all terms \m{t \in g_n}, \m{s \in g_p} s.t. \m{ eqs(P) \models s=t}, \\
%for all terms \m{u} s.t. \m{ eqs(g_p.P_1.g_q) \models s=u \land eqs(g_q.P_2.g_n) \models u=t},\\
%it holds that \m{u \in g_q}.\\
%This implies, along with the definition of sources, that \\
%\m{g_q(u) \in sources(q.P_2.n, g_n(t))} and \m{g_p(s) \in sources(p.P_1.q, g_q(u))} - hence\\
%\m{g_p(s) \in sources(p.P_1.q.P_2.n, g_n(t))}.
%
%Unfortunately, maintaining this invariant in the presence of joins is not always possible - for example:
%\begin{lstlisting}[caption=propagation sources infinite,label=snippet3.18]
%if (*)
	%$\node{t1}:$
	%assume a=f(a)
	%assume b=f(b)
	%assume a=b
%else
	%$\node{e1}:$
	%assume f(f(a))=f(b)
%$\node{j}:$
%if (*)
	%$\node{t2}:$
	%assume a=f(a)
	%assume b=f(b)
		%$\node{a}:$
		%assert a=b
%\end{lstlisting}
%
%
%For \node{t1}, for all \m{i}, \m{g_{t1}(f^i(a)) = g_{t1}(f^i(b)) = g_{t1}(a) = g_{t1}(b)} and the graph \m{g_a} has only one node.
%Also, \m{eqs(g_{t2}) \models \forall i \cdot f^i(a)=a \land f^i(b)=b}, so the graph can have at most two nodes.\\
%However, at \node{j}, for \m{i \neq j}, it does not hold that \m{eqs(g_j) \models f^i(a)=f^j(a)}, so if we were to maintain the invariant above then \m{g_j} could not be a finite graph.
%
%In the above example it seems that it would suffice if the (sub-term closure of) the terms \s{f(f(a)),f(b)} existed at \m{g_j} - the minimal requirement for completeness is in fact that a \m{u} as above \emph{exists} at \node{g_q}, as then we have a \m{sources} chain between each pair of equivalent terms.
%
%We could modify the above invariant so that, instead of for all \m{u}, we would have exists \m{u} - that is:\\
%\m{\forall p.P_1.q.P_2.n \in paths(CFG),t \in g_n,s \in g_p \cdot }\\
%\m{eqs(p.P_1.q.P_2.n) \models s=t \Rightarrow }\\
%\m{\exists u \cdot ((eqs(p.P_1.q) \models s=u \land eqs(q.P_2.n) \models u=t) \Rightarrow u \in g_q)}
%
%Here we guarantee that we only need a finite number of equivalence classes at each graph, but it is not immediately clear how to choose which ones, and we need to analyze carefully the worst case space complexity of such join nodes.
%
%How do we go about choosing such a \m{u}?\\
%The sets of equivalence classes grow and merge throughout the verification process and it would not be efficient if we need a global analysis of the program after each change to some node, so we need a criterion that is somewhat local and robust to the addition and merging of equivalence classes.\\
%In the above case we want \s{f(f(a)),f(b)} at the join, so a criterion that suggests itself is is to choose, at a node \node{j}, all such \m{u} that exist in the transitive predecessors of \emph{all} direct predecessors of \node{j}, and whichever term is not covered (that is - only appears in the transitive predecessors of one predecessor), we can choose arbitrarily, or choose the minimal one by our term ordering or by absolute size (number of graph nodes that would be added).\\
%This strategy ensures completeness and ensures that we do not add more EC nodes to the graph of each CFG node than there are EC nodes in all graphs in its transitive predecessors, which is in total exponential, but a more careful analysis .\\
%It ensures further that 
%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%
%\subsection{Fragment verification algorithm}
%Integrating the above discussed modification, we present a modified version of our algorithm, which handles clauses (not necessarily ground) relative to some calculus, but uses the graph structure to handle unit ground equality clauses.
%\begin{lstlisting}
%CFG.verify(fragment : Fragment,initial : Bool)
	%if (initial)
		%build()
	%else
		%foreach (n in nodes)
			%n.nextTodo.enqueue(n.done)
			%n.done.clear()
			%
	%while (any node has a non-empty nextTodo list)
		%CFG.saturateForward(fragment)
%
%CFG.build()
	%foreach n in cfg.nodes in topological order
		%n.g = empty congruence closure graph
		%n.done = $\emptyset$
		%n.imported = $\emptyset$
		%n.nextTodo.enqueue($\clauses{n}$)
%
%CFG.saturateForward(fragment)
	%foreach n in cfg.nodes in topological order
		%n.saturate(fragment)
%
%Node.saturate(fragment : Fragment)
	%while !nextTodo.isEmpty
		%todo = nextTodo
		%nextTodo = emptyQueue
		%
		%g.add(todo)
		%
		%eqs = todo.unit ground (in)equalities
		%todo = todo \setminus eqs
		%g.assume(eqs)
		%
		%importClauses(todo)
		%foreach (c in todo)
			%done.add(c)
			%for $\m{c{'} \in inferences(fragment,c,done)}$
				%if $\m{c{'} \notin done \cup todo}$
					%nextTodo.enqueue($\m{c'}$)
%\end{lstlisting}
%
%The clauses in \lstinline{done,todo,nextTodo} are always kept simplified with respect to \lstinline{g} and one another.\\
%We will discuss the eager simplification calculus later, we just note it includes simplification by equalities, tautology elimination, literal factoring, unit clause propagation and several others.
%A simplified clause goes from \lstinline{done,todo} to \lstinline{nextTodo} if simplification has potentially changed the import condition on the clause - in the current case the maximal term and literal.
%
%As described before, we try to import the clauses for as many terms as possible in one query, and we cache queries and simplify results.
%Unit ground clause import is handled by the graph data structure, where each \lstinline{add} or \lstinline{assume} operation takes care of importing and integrating predecessor unit ground \\ (in)equalities until all invariants are satisfied - all described in the next section.
%
%The pseudo-code for clause import is:
%\begin{lstlisting}
%Node.importClauses(cs:Set<Clause>)
		%ncs = cs $\setminus$ importedClauses
		%terms = $\bigcup\limits_{\m{c \in ncs}} \s{t \mid \exists l,p \cdot t=\termAt{l}{p} \land l = c.maxTerm}$
		%terms = terms $\setminus$ importedTerms
		%importedTerms = importedTerms $\cup$ terms
		%ncs = importRecursive(terms)
		%foreach ($\m{nc \in ncs}$)
			%$\m{c'}$ = simplify(g,nc)
			%if ($\m{c'}$ is not a tautology)
				%importedClauses.add($\m{c'}$)
				%if $\m{c{'} \notin done \cup todo}$
					%nextTodo.enqueue($\m{c'}$)
%\end{lstlisting}
%
%
%
%Given a node \node{n} and a direct predecessor \m{p \in \preds{n}}, 
%for each term EC \m{t \in g_n} we need to know which term ECs \m{s \in g_p} satisfy \m{\Eqst{n} \models s \cap t \neq \emptyset}.\\
%This is needed both for assembling the query from \node{n} to \node{p} and for translating, in the query response, 
%each clause over \m{\ECs{p}} to an equivalent (set of) clause(s) over \m{\ECs{n}}.\\
%A simple example:
%\begin{lstlisting}[caption=propagation sources,label=snippet3.16a]
%$\node{n_1}:$
%assume $\m{f(a)=g(a)}$
%$\node{n_2}:$
%assume $\m{a=b}$
%$\node{n_3}:$
%assert $\m{f(b)=g(b)}$
%\end{lstlisting}
%Here \node{n_3} cannot directly query \node{n_1} for \m{f(b),g(b)} as \m{b} is not defined there.\\
%Using scoping the equivalence class of the term \m{b} at \m{n_3} would be \s{b} and the equivalence class of \m{a} at \m{n_1} would be \m{a}, so we need to translate the query\\
 %\m{f(\s{b})} at \m{n_3} to \\
%\m{f(\s{a,b})} at \m{n_2} to \\
%\m{f(\s{a})} at \m{n_1}.\\
%Likewise, the result is translated from \\
%\m{f(\s{a})=g(\s{a})} at \m{n_1} to \\
%\m{f(\s{a,b})=g(\s{a,b})} at \m{n_2} to \\
%\m{f(\s{b})=g(\s{b})} at \m{n_3}.
%
%To see that the problem does not stem only from scoping:
%\begin{lstlisting}[caption=propagation sources,label=snippet3.16b]
%$\node{n_1}:$
%assume $\m{f(a)=g(a)}$
%assume $\m{f(c)=g(c)}$
%if (*)
	%$\node{n_{2a}}:$
	%assume $\m{a=b}$
%else
	%$\node{n_{2b}}:$
	%assume $\m{c=b}$
%$\node{n_3}:$
%assert $\m{f(b)=g(b)}$ //negated $\m{f(b) \neq g(b)}$
%\end{lstlisting}
%Here, even without scoping, \m{\Eqs{n_3} \not\models a=b} and \m{\Eqs{n_3} \not\models c=b}, and so the query and response have to be translated through \m{n_{2a},n_{2b}}.
%
%As is evident from the example ~\ref{snippet3.16a}, the term \m{f(\s{b})} at \m{n_3} has no corresponding term at \m{n_2}, although it has the corresponding term \m{f(\s{a})} at \m{n_1}
%
