%\newpage
\section{Related Work}


\subsection{Congruence closure}
The earlier papers to discuss congruence closure algorithms are ~\cite{DowneySethiTarjan} (efficient algorithms, complexity bounds and alternative implementations), ~\cite{Shostak84} and ~\cite{NelsonOppen80} (combination with other theories). 

A comprehensive analysis of the join of two EC-graphs is given in ~\cite{GulwaniTiwariNecula04}, including a join algorithm that determines the equality of two terms at a join by adding the terms to the EC-graphs of both joinees. 
The algorithm is eager in the sense that it represents in the join all terms that occur in both joinees, 
and works bottom up from constants as opposed to our algorithm that works top-down and hence avoids considering irrelevant joinee terms.
Their algorithm works for one join and does not help determine which terms are relevant at which CFG-node.
The paper includes several examples, some of which we have repeated here, that show limitations of the congruence closure approach.

In ~\cite{GulwaniNecula07} the problem of global value numbering is discussed, 
which concerns the analysis of programs that may contain loops, but include only assignments (i.e. no assume statements).
For loop-less programs this is a strict subset of our problem, as essentially it means that each EC-graph node has exactly one non-constant gfa, and also no cycles. The paper gives an example loop-less program that would require an exponentially sized EC-graph at one program point in order to prove, which we have mentioned.

In ~\cite{NieuwenhuisOliveras03} the authors give a congruence closure algorithm, mostly similar to previous ones, 
except that they eliminate all functions and replace them by the curry function $\cdot$ of arity two, rewriting all the equations accordingly. They also name sub-terms by constants, for which we simply use the graph nodes. 
We have seen that some operations, especially at join points, are sensitive to function arity, and so this transformation has some attraction, however it has some important disadvantages in our setting:
the first disadvantage is that the transformation is arbitrarily non-symmetric, as we can curryfy an n-ary function to either a left or right chain of n $apply$ instances, a tree of applications of depth $log(n)$ or any other form. 
This makes it harder to keep other fragments predictable to users, and harder to enforce size limitations. In our setting it may also make our algorithm propagate much more equality information than is needed, 
as the original function symbol is not used in filtering most of the terms requested from predecessors (e.g. the \GFA{} f(a,b,c) will be rewritten to $\cdot(f,\cdot(a,\cdot(b,c)))$, and so may propagate $\cdot(b,c)$ even if $\cdot(a,\cdot(b,c))$ will not be propagated, while in our algorithm propagation will only happen if a term with the symbol $f$ occurs).

In ~\cite{ChangLeino2005} the authors describe an abstract interpretation framework that includes the domains of unit ground equalities and heaps (or generally other base domains). A join operation is described on EC-graphs which is works bottom up and does not use information from successor nodes to determine which terms to represent at the join.
The authors note the potential for sharing sub-graphs that are equal on both sides. The authors also note the incompleteness of the weak join, and in general the fact that information will be missing for terms that do not occur on both sides of the join, and suggest adding these terms to the graph on both sides without giving a strategy for selecting which terms to add. The reason is mostly that they apply abstract interpretation as a forward analysis, which is essentially goal insensitive, while our algorithm propagates information across joins as needed by later assertions. The algorithm in the paper is also not incremental, as in abstract interpretation the intermediate states represent an under approximation of the set of states, rather than an over approximation (until widening is applied).
%Hierarchical Superposition / Shostak / Sat mod Sat

\subsection{Information propagation}
Information propagation in a restricted fragment is the main theme of abstract interpretation (AI) (~\cite{CousotCousot77} and many others).
The main difference is that abstract interpretation works on a combination of under-approximation and over-approximation of the set of states in order to verify program properties, and can infer invariants, while we only try to verify a given program by calculating over-approximations, and cannot handle invariants with loops or recursion.
In spite of these differences, there is strong correlation between the join operation of AI and our join operation (although in AI it is usually not incremental - the value at the join node is recalculated), and some of the completeness issues are similar. 
Mainly, AI domains are analyzed as a fixed domain or combination of domains in a fixed order, either forwards or backwards (in program flow sense). 

As mentioned above (\cite{ChangLeino2005}) has developed an AI domain for congruence closure.
Several domains have been suggested for the problem of global value numbering - where only assignments are allowed (essentially, for acyclic programs).  This means in our setting that the only assume statements allowed are an equality \m{v_i = t_{i-1}}, 
where \m{v_i} is the ith DSA version of the variable \m{v} and \m{t_{i-1}} is a term only including constants and variables of the previous DSA version - essentially this means that EC-graphs cannot have loops. This is an early problem coming from compiler optimizations that has an exponential complete solution in \cite{Kildall73} and several other results are compared in \cite{GulwaniTiwariNecula04}.  \cite{Vagvolgyi03b} gives a decision procedure to detect when a join of two sets of equations is finitely generated and gives an algorithm to calculate the join, which stands in accuracy between our strong join and weak join.

For programs with loops, \cite{MullerOlmSeidl04} shows that allowing positive equality assume statements (positive guards) makes the fragment undecidable in the presence of loops, using an encoding of PCP. \cite{GulwaniTiwari07} discuss complexity issues and the relation to unification.

The \textbf{IC3/PDR} (\cite{Bradley12}) is used to infer propositional invariants of programs, essentially by looking at bounded unrollings of the loop and strengthening the invariant for the nth iteration by searching for a pre-image in the transition relation in the n-1 iteration, and if the found pre-image is infeasible, the algorithm tries to strengthen it and propagate it to later iterations.
IC3 has been extended to EPR (\cite{BjornerGurfinkelKorovinLahav2013}, linear arithmetic (e.g. \cite{BjornerGurfinkel2015} - combined with interpolation and polyhedra abstract interpretation) and others.
The technique and its further developments offer several ways to propagate and generalize the clause in order to reduce the number of iterations.
IC3 has proved very effective and has several extensions and generalization strategies, including a combination with interpolation in ~\cite{VizelGurfinkel2014}.\\
Compared to our work, IC3 can infer invariants and each step of IC3 requires a SAT call (or SMT call in some works) in order to find a counter example, and another call in order to calculate the pre-image, the first call only considers one program point and the second two program points, so that the SAT/SMT problem is much smaller than whole program VC.
Compared to our information propagation technique, 
IC3 requests to predecessors are a conjunction of ground literals (a set of models) while we request either a single literal or one ground term. In terms of complexity, IC3 ensures progress for each step, but the worst case cost of each SAT/SMT call is exponential, and even within one unrolling, the number of counter-examples that may be sent as requests can be exponential as well (although it might be that some clause generalization method can prevent this - we are not aware of such a result), and the choice of counter-examples is not easily predictable. As in other SAT/SMT based techniques, it is not immediately clear how to ensure a polynomial run-time for a sub-fragment and how to ensure progress in the presence of quantifiers.\\
A direct comparison when trying to prove an assertion \m{s=t} is that we try to propagate the whole equivalence classes of \m{s,t} and then compare, while IC3 directly asks whether the pre-image of a specific state where \m{s=t} holds. 
For propositional queries we request one literal and the reply is a set of clauses, while IC3 requests a conjunction of literals and the reply is one clause. Hence, IC3 asks more specific questions and propagates much less unneeded information (which is necessary in order for invariants to converge), while we ask less specific questions but can bound the number of answers needed for saturation. It would be interesting to see how we can, in some cases, utilize more directed queries as in IC3, while maintaining polynomial bounds.
In order to handle quantifiers, an efficient representation for infinite counter-examples is needed, we suspect that the representation used in \cite{BaumgartnerPelzerTinelli12} (which extends DPLL to FOL - hence has a representation for partial models with quantifiers) could be a potential, although as above, the problem is that no prover run is guaranteed to even terminate, and no progress is guaranteed for a prover time-out.

Another existing technique is based on modular sat solving (\cite{BaylessValBallHoosHu2013}) - here (in our terminology) each CFG-node gets its own SAT solver, each assertion leaf node searches for a model, which is then communicated to its predecessor (in the paper it is described for a sequence, rather than tree or DAG, CFG), each SAT solver is incremental and can receive new assignments from successors and new lemmas (learned clauses) from predecessors.
This approach is appealing as it is local and potentially each solver could face a much smaller problem than that of a whole VCG solver.
It would be interesting to see how this approach fares when extended to SMT and DAGs (in the paper it is described as a method to implement IC3, so in fact loops are supported, but acyclic sub-CFG are converted to one SAT instance - there is no provision for joins).
However, it faces some of the problems mentioned for IC3 above - each SAT instance could potentially run for exponential time, and a model has to be completely refuted (with an explaining lemma/interpolant) in order to continue verification.
